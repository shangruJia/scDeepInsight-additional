{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee4b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import torch.optim.lr_scheduler as lr_scheduler \n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e429ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = pd.read_csv(\"./pretrained/trainy_pre.csv\")\n",
    "valy = pd.read_csv(\"./pretrained/valy_pre.csv\")\n",
    "#labels to categorical matrix\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainy['celltype'])\n",
    "classes = len(np.unique(trainy['celltype']))\n",
    "with open(\"./pretrained/label_encoder_pre.obj\",\"wb\") as f:\n",
    "   pickle.dump(le, f)\n",
    "\n",
    "y_train = pd.DataFrame(le.transform(trainy['celltype']))\n",
    "y_val = pd.DataFrame(le.transform(valy['celltype']))\n",
    "np.save('./pretrained/train_pre_label.npy', y_train)\n",
    "np.save('./pretrained/val_pre_label.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47eefb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(torch.nn.Module):\n",
    "    def __init__(self, eps=0.1, reduction='mean'):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = torch.nn.functional.log_softmax(output, dim=-1)\n",
    "        if self.reduction=='sum':\n",
    "            loss = -log_preds.sum()\n",
    "        else:\n",
    "            loss = -log_preds.sum(dim=-1)\n",
    "            if self.reduction=='mean':\n",
    "                loss = loss.mean()\n",
    "        return loss*self.eps/c + (1-self.eps) * torch.nn.functional.nll_loss(log_preds, target, reduction=self.reduction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda3e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, path='./pretrained/checkpoint_model_pre.pth'):\n",
    "        self.patience = patience    \n",
    "        self.verbose = verbose      \n",
    "        self.counter = 0            \n",
    "        self.best_score = None      \n",
    "        self.early_stop = False     \n",
    "        self.val_acc_max = 0   \n",
    "        self.path = path             \n",
    "    def __call__(self, val_acc, model):\n",
    "        score = val_acc\n",
    "        if self.best_score is None: \n",
    "            self.best_score = score \n",
    "            self.checkpoint(val_acc, model)\n",
    "        elif score < self.best_score: \n",
    "            self.counter += 1 \n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: \n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.checkpoint(val_acc, model)\n",
    "            self.counter = 0  \n",
    "    def checkpoint(self, val_acc, model):\n",
    "        if self.verbose:  \n",
    "            print(f'Validation accuracy increased ({self.val_acc_max:.6f} --> {val_acc:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)  \n",
    "        self.val_acc_max = val_acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145fe140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, img, label):\n",
    "        self.img = np.load(img)\n",
    "        self.label = torch.tensor(np.load(label))\n",
    "        self.transforms = transforms.Compose([transforms.ToTensor(), ])\n",
    "    def __getitem__(self, index):\n",
    "        img = self.img[index, :, :, :] \n",
    "        img = np.squeeze(img)\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        img = self.transforms(img)\n",
    "        label = self.label[index]\n",
    "        label = np.squeeze(label)\n",
    "        return img,label\n",
    "    def __len__(self):\n",
    "        return self.img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d89cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(pre_epoch, EPOCH, early_patience, training_loader, validation_loader, net, optimizer, scheduler, criteria, device):\n",
    "    with open(\"./pretrained/acc.txt\", \"w\") as f:\n",
    "        with open(\"./pretrained/log.txt\", \"w\")as f2:\n",
    "            start = time.time()\n",
    "            earlystopping = EarlyStopping(patience=early_patience, verbose=True)\n",
    "            losses_train = []\n",
    "            accs_train = []\n",
    "            losses_val = []\n",
    "            accs_val = []\n",
    "            best_acc = 0\n",
    "            total_poches = 0\n",
    "            for epoch in range(pre_epoch, EPOCH):\n",
    "                print('\\nEpoch: %d' % (epoch + 1))\n",
    "                since = time.time()\n",
    "                net.train()\n",
    "                sum_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for i, data in enumerate(training_loader):\n",
    "                    length = len(training_loader)\n",
    "                    input, target = data\n",
    "                    input, target = input.to(device), target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    # forward + backward\n",
    "                    output = net(input)\n",
    "                    loss = criteria(output, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    sum_loss += loss.item()\n",
    "                    _, predicted = torch.max(output.data, 1)\n",
    "                    total += target.size(0)\n",
    "                    correct += predicted.eq(target.data).cpu().sum()\n",
    "                    loss_train = sum_loss / (i + 1)\n",
    "                    acc_train = 100. * float(correct) / float(total)\n",
    "                    print('[epoch:%d, iter:%d] Loss: %.03f | Accuracy: %.3f%% '\n",
    "                        % (epoch + 1, (i + 1 + epoch * length), loss_train, acc_train))\n",
    "                    f2.write('%03d  %05d |Loss: %.03f | Accuracy: %.3f%% '\n",
    "                        % (epoch + 1, (i + 1 + epoch * length), loss_train, acc_train))\n",
    "                    f2.write('\\n')\n",
    "                    f2.flush()\n",
    "                acc_train = 100. * float(correct) / float(total)\n",
    "                accs_train.append(acc_train)\n",
    "                losses_train.append(loss_train)\n",
    "                print(\"Waiting Test!\")\n",
    "                with torch.no_grad():\n",
    "                    sum_loss_val = 0\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    loss_val = 0\n",
    "                    for i, data in enumerate(validation_loader):\n",
    "                        net.eval()\n",
    "                        images, labels = data\n",
    "                        images, labels = images.to(device), labels.to(device)\n",
    "                        outputs = net(images)\n",
    "                        loss = criteria(outputs, labels)\n",
    "                        sum_loss_val += loss.item()\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += predicted.eq(labels.data).cpu().sum()\n",
    "                        loss_val = sum_loss_val / (i + 1)\n",
    "                    acc_val = 100. * float(correct) / float(total)\n",
    "                    losses_val.append(loss_val)\n",
    "                    accs_val.append(acc_val)\n",
    "                    print(\"EPOCH=%03d, Loss: %.03f, Accuracy= %.3f%%\" % (epoch + 1, loss_val ,acc_val))\n",
    "                    scheduler.step(acc_val)\n",
    "                    if acc_val > best_acc:\n",
    "                        f3 = open(\"./pretrained/best_acc.txt\", \"w\")\n",
    "                        f3.write(\"EPOCH=%d,best_acc= %.3f%%\" % (epoch + 1, acc_val))\n",
    "                        f3.close()\n",
    "                        best_acc = acc_val\n",
    "                    time_elapsed = time.time() - since\n",
    "                    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "                    earlystopping(acc_val, net)\n",
    "                    if earlystopping.early_stop: \n",
    "                        print(\"Early Stopping!\")\n",
    "                        total_poches = epoch + 1\n",
    "                        break\n",
    "            print(\"Training Finished, TotalEPOCH=%d\" % total_poches)\n",
    "            time_total = time.time() - start\n",
    "            print('The whole training process complete in {:.0f}m {:.0f}s'.format(time_total // 60, time_total % 60))\n",
    "    return losses_train, accs_train, losses_val, accs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101b2a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 8000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "batch_size = 32\n",
    "net = EfficientNet.from_pretrained('efficientnet-b3', num_classes=classes)\n",
    "net._fc.out_features = classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489763c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62716211",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MyDataset(\"./pretrained/train_pre.npy\", \"./pretrained/train_pre_label.npy\")\n",
    "training_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val = MyDataset(\"./pretrained/val_pre.npy\", \"./pretrained/val_pre_label.npy\")\n",
    "validation_loader = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7197f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 3e-4 \n",
    "# optimizer\n",
    "params_to_update = net.parameters()\n",
    "optimizer = optim.NAdam(params_to_update, lr=LR, betas=(0.9, 0.999), eps=1e-9)\n",
    "# scheduler\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3, verbose=True)\n",
    "criteria = LabelSmoothingCrossEntropy(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e317905",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8faca313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "[epoch:1, iter:1] Loss: 2.232 | Accuracy: 6.250% \n",
      "[epoch:1, iter:2] Loss: 2.189 | Accuracy: 14.062% \n",
      "[epoch:1, iter:3] Loss: 2.161 | Accuracy: 17.708% \n",
      "[epoch:1, iter:4] Loss: 2.135 | Accuracy: 22.656% \n",
      "[epoch:1, iter:5] Loss: 2.108 | Accuracy: 27.500% \n",
      "[epoch:1, iter:6] Loss: 2.083 | Accuracy: 29.688% \n",
      "[epoch:1, iter:7] Loss: 2.052 | Accuracy: 33.482% \n",
      "[epoch:1, iter:8] Loss: 2.014 | Accuracy: 37.500% \n",
      "[epoch:1, iter:9] Loss: 1.977 | Accuracy: 39.931% \n",
      "[epoch:1, iter:10] Loss: 1.936 | Accuracy: 41.875% \n",
      "[epoch:1, iter:11] Loss: 1.894 | Accuracy: 44.318% \n",
      "[epoch:1, iter:12] Loss: 1.847 | Accuracy: 47.656% \n",
      "[epoch:1, iter:13] Loss: 1.808 | Accuracy: 49.038% \n",
      "[epoch:1, iter:14] Loss: 1.776 | Accuracy: 50.670% \n",
      "[epoch:1, iter:15] Loss: 1.744 | Accuracy: 52.500% \n",
      "[epoch:1, iter:16] Loss: 1.710 | Accuracy: 53.906% \n",
      "[epoch:1, iter:17] Loss: 1.673 | Accuracy: 55.699% \n",
      "[epoch:1, iter:18] Loss: 1.641 | Accuracy: 57.292% \n",
      "[epoch:1, iter:19] Loss: 1.602 | Accuracy: 59.211% \n",
      "[epoch:1, iter:20] Loss: 1.567 | Accuracy: 60.312% \n",
      "[epoch:1, iter:21] Loss: 1.546 | Accuracy: 60.565% \n",
      "[epoch:1, iter:22] Loss: 1.526 | Accuracy: 61.222% \n",
      "[epoch:1, iter:23] Loss: 1.491 | Accuracy: 62.772% \n",
      "[epoch:1, iter:24] Loss: 1.473 | Accuracy: 63.411% \n",
      "[epoch:1, iter:25] Loss: 1.455 | Accuracy: 64.125% \n",
      "[epoch:1, iter:26] Loss: 1.436 | Accuracy: 64.784% \n",
      "[epoch:1, iter:27] Loss: 1.410 | Accuracy: 65.741% \n",
      "[epoch:1, iter:28] Loss: 1.386 | Accuracy: 66.406% \n",
      "[epoch:1, iter:29] Loss: 1.372 | Accuracy: 66.703% \n",
      "[epoch:1, iter:30] Loss: 1.349 | Accuracy: 67.604% \n",
      "[epoch:1, iter:31] Loss: 1.330 | Accuracy: 68.246% \n",
      "[epoch:1, iter:32] Loss: 1.315 | Accuracy: 68.945% \n",
      "[epoch:1, iter:33] Loss: 1.298 | Accuracy: 69.508% \n",
      "[epoch:1, iter:34] Loss: 1.284 | Accuracy: 70.129% \n",
      "[epoch:1, iter:35] Loss: 1.272 | Accuracy: 70.446% \n",
      "[epoch:1, iter:36] Loss: 1.257 | Accuracy: 71.007% \n",
      "[epoch:1, iter:37] Loss: 1.242 | Accuracy: 71.622% \n",
      "[epoch:1, iter:38] Loss: 1.233 | Accuracy: 71.875% \n",
      "[epoch:1, iter:39] Loss: 1.216 | Accuracy: 72.596% \n",
      "[epoch:1, iter:40] Loss: 1.210 | Accuracy: 72.734% \n",
      "[epoch:1, iter:41] Loss: 1.197 | Accuracy: 73.171% \n",
      "[epoch:1, iter:42] Loss: 1.188 | Accuracy: 73.586% \n",
      "[epoch:1, iter:43] Loss: 1.177 | Accuracy: 74.055% \n",
      "[epoch:1, iter:44] Loss: 1.166 | Accuracy: 74.503% \n",
      "[epoch:1, iter:45] Loss: 1.153 | Accuracy: 75.000% \n",
      "[epoch:1, iter:46] Loss: 1.143 | Accuracy: 75.340% \n",
      "[epoch:1, iter:47] Loss: 1.132 | Accuracy: 75.731% \n",
      "[epoch:1, iter:48] Loss: 1.128 | Accuracy: 75.846% \n",
      "[epoch:1, iter:49] Loss: 1.120 | Accuracy: 76.148% \n",
      "[epoch:1, iter:50] Loss: 1.111 | Accuracy: 76.438% \n",
      "[epoch:1, iter:51] Loss: 1.103 | Accuracy: 76.716% \n",
      "[epoch:1, iter:52] Loss: 1.096 | Accuracy: 77.043% \n",
      "[epoch:1, iter:53] Loss: 1.088 | Accuracy: 77.358% \n",
      "[epoch:1, iter:54] Loss: 1.085 | Accuracy: 77.373% \n",
      "[epoch:1, iter:55] Loss: 1.080 | Accuracy: 77.557% \n",
      "[epoch:1, iter:56] Loss: 1.074 | Accuracy: 77.734% \n",
      "[epoch:1, iter:57] Loss: 1.068 | Accuracy: 77.906% \n",
      "[epoch:1, iter:58] Loss: 1.061 | Accuracy: 78.125% \n",
      "[epoch:1, iter:59] Loss: 1.058 | Accuracy: 78.284% \n",
      "[epoch:1, iter:60] Loss: 1.052 | Accuracy: 78.385% \n",
      "[epoch:1, iter:61] Loss: 1.048 | Accuracy: 78.586% \n",
      "[epoch:1, iter:62] Loss: 1.042 | Accuracy: 78.831% \n",
      "[epoch:1, iter:63] Loss: 1.040 | Accuracy: 78.919% \n",
      "[epoch:1, iter:64] Loss: 1.035 | Accuracy: 79.053% \n",
      "[epoch:1, iter:65] Loss: 1.029 | Accuracy: 79.327% \n",
      "[epoch:1, iter:66] Loss: 1.023 | Accuracy: 79.545% \n",
      "[epoch:1, iter:67] Loss: 1.020 | Accuracy: 79.618% \n",
      "[epoch:1, iter:68] Loss: 1.015 | Accuracy: 79.825% \n",
      "[epoch:1, iter:69] Loss: 1.012 | Accuracy: 80.027% \n",
      "[epoch:1, iter:70] Loss: 1.006 | Accuracy: 80.268% \n",
      "[epoch:1, iter:71] Loss: 1.001 | Accuracy: 80.458% \n",
      "[epoch:1, iter:72] Loss: 0.995 | Accuracy: 80.642% \n",
      "[epoch:1, iter:73] Loss: 0.992 | Accuracy: 80.822% \n",
      "[epoch:1, iter:74] Loss: 0.989 | Accuracy: 80.954% \n",
      "[epoch:1, iter:75] Loss: 1.003 | Accuracy: 80.920% \n",
      "Waiting Test!\n",
      "EPOCH=001, Loss: 2.112, Accuracy= 17.105%\n",
      "Training complete in 0m 15s\n",
      "Validation accuracy increased (0.000000 --> 17.105263).  Saving model ...\n",
      "\n",
      "Epoch: 2\n",
      "[epoch:2, iter:76] Loss: 0.588 | Accuracy: 96.875% \n",
      "[epoch:2, iter:77] Loss: 0.604 | Accuracy: 95.312% \n",
      "[epoch:2, iter:78] Loss: 0.602 | Accuracy: 96.875% \n",
      "[epoch:2, iter:79] Loss: 0.638 | Accuracy: 95.312% \n",
      "[epoch:2, iter:80] Loss: 0.647 | Accuracy: 94.375% \n",
      "[epoch:2, iter:81] Loss: 0.652 | Accuracy: 94.271% \n",
      "[epoch:2, iter:82] Loss: 0.651 | Accuracy: 93.750% \n",
      "[epoch:2, iter:83] Loss: 0.651 | Accuracy: 94.141% \n",
      "[epoch:2, iter:84] Loss: 0.654 | Accuracy: 94.097% \n",
      "[epoch:2, iter:85] Loss: 0.674 | Accuracy: 93.438% \n",
      "[epoch:2, iter:86] Loss: 0.675 | Accuracy: 93.182% \n",
      "[epoch:2, iter:87] Loss: 0.678 | Accuracy: 93.229% \n",
      "[epoch:2, iter:88] Loss: 0.676 | Accuracy: 93.510% \n",
      "[epoch:2, iter:89] Loss: 0.688 | Accuracy: 93.080% \n",
      "[epoch:2, iter:90] Loss: 0.687 | Accuracy: 92.917% \n",
      "[epoch:2, iter:91] Loss: 0.686 | Accuracy: 92.969% \n",
      "[epoch:2, iter:92] Loss: 0.682 | Accuracy: 93.199% \n",
      "[epoch:2, iter:93] Loss: 0.680 | Accuracy: 93.229% \n",
      "[epoch:2, iter:94] Loss: 0.675 | Accuracy: 93.421% \n",
      "[epoch:2, iter:95] Loss: 0.690 | Accuracy: 92.656% \n",
      "[epoch:2, iter:96] Loss: 0.684 | Accuracy: 92.857% \n",
      "[epoch:2, iter:97] Loss: 0.678 | Accuracy: 93.182% \n",
      "[epoch:2, iter:98] Loss: 0.679 | Accuracy: 93.207% \n",
      "[epoch:2, iter:99] Loss: 0.676 | Accuracy: 93.229% \n",
      "[epoch:2, iter:100] Loss: 0.674 | Accuracy: 93.250% \n",
      "[epoch:2, iter:101] Loss: 0.675 | Accuracy: 93.029% \n",
      "[epoch:2, iter:102] Loss: 0.675 | Accuracy: 92.824% \n",
      "[epoch:2, iter:103] Loss: 0.676 | Accuracy: 92.746% \n",
      "[epoch:2, iter:104] Loss: 0.672 | Accuracy: 92.780% \n",
      "[epoch:2, iter:105] Loss: 0.671 | Accuracy: 92.917% \n",
      "[epoch:2, iter:106] Loss: 0.672 | Accuracy: 92.843% \n",
      "[epoch:2, iter:107] Loss: 0.668 | Accuracy: 93.066% \n",
      "[epoch:2, iter:108] Loss: 0.668 | Accuracy: 93.087% \n",
      "[epoch:2, iter:109] Loss: 0.670 | Accuracy: 93.015% \n",
      "[epoch:2, iter:110] Loss: 0.666 | Accuracy: 93.214% \n",
      "[epoch:2, iter:111] Loss: 0.665 | Accuracy: 93.316% \n",
      "[epoch:2, iter:112] Loss: 0.666 | Accuracy: 93.159% \n",
      "[epoch:2, iter:113] Loss: 0.666 | Accuracy: 93.174% \n",
      "[epoch:2, iter:114] Loss: 0.667 | Accuracy: 93.189% \n",
      "[epoch:2, iter:115] Loss: 0.666 | Accuracy: 93.281% \n",
      "[epoch:2, iter:116] Loss: 0.664 | Accuracy: 93.369% \n",
      "[epoch:2, iter:117] Loss: 0.667 | Accuracy: 93.155% \n",
      "[epoch:2, iter:118] Loss: 0.666 | Accuracy: 93.169% \n",
      "[epoch:2, iter:119] Loss: 0.667 | Accuracy: 93.040% \n",
      "[epoch:2, iter:120] Loss: 0.666 | Accuracy: 92.986% \n",
      "[epoch:2, iter:121] Loss: 0.664 | Accuracy: 93.071% \n",
      "[epoch:2, iter:122] Loss: 0.664 | Accuracy: 92.952% \n",
      "[epoch:2, iter:123] Loss: 0.663 | Accuracy: 93.034% \n",
      "[epoch:2, iter:124] Loss: 0.664 | Accuracy: 92.921% \n",
      "[epoch:2, iter:125] Loss: 0.662 | Accuracy: 93.000% \n",
      "[epoch:2, iter:126] Loss: 0.659 | Accuracy: 93.137% \n",
      "[epoch:2, iter:127] Loss: 0.659 | Accuracy: 93.089% \n",
      "[epoch:2, iter:128] Loss: 0.659 | Accuracy: 93.101% \n",
      "[epoch:2, iter:129] Loss: 0.656 | Accuracy: 93.229% \n",
      "[epoch:2, iter:130] Loss: 0.657 | Accuracy: 93.239% \n",
      "[epoch:2, iter:131] Loss: 0.657 | Accuracy: 93.192% \n",
      "[epoch:2, iter:132] Loss: 0.660 | Accuracy: 93.037% \n",
      "[epoch:2, iter:133] Loss: 0.658 | Accuracy: 93.103% \n",
      "[epoch:2, iter:134] Loss: 0.658 | Accuracy: 93.114% \n",
      "[epoch:2, iter:135] Loss: 0.658 | Accuracy: 93.125% \n",
      "[epoch:2, iter:136] Loss: 0.657 | Accuracy: 93.135% \n",
      "[epoch:2, iter:137] Loss: 0.657 | Accuracy: 93.145% \n",
      "[epoch:2, iter:138] Loss: 0.659 | Accuracy: 93.105% \n",
      "[epoch:2, iter:139] Loss: 0.661 | Accuracy: 92.969% \n",
      "[epoch:2, iter:140] Loss: 0.662 | Accuracy: 92.933% \n",
      "[epoch:2, iter:141] Loss: 0.660 | Accuracy: 92.992% \n",
      "[epoch:2, iter:142] Loss: 0.659 | Accuracy: 93.004% \n",
      "[epoch:2, iter:143] Loss: 0.657 | Accuracy: 93.107% \n",
      "[epoch:2, iter:144] Loss: 0.657 | Accuracy: 93.161% \n",
      "[epoch:2, iter:145] Loss: 0.656 | Accuracy: 93.259% \n",
      "[epoch:2, iter:146] Loss: 0.656 | Accuracy: 93.178% \n",
      "[epoch:2, iter:147] Loss: 0.654 | Accuracy: 93.273% \n",
      "[epoch:2, iter:148] Loss: 0.653 | Accuracy: 93.365% \n",
      "[epoch:2, iter:149] Loss: 0.652 | Accuracy: 93.370% \n",
      "[epoch:2, iter:150] Loss: 0.653 | Accuracy: 93.373% \n",
      "Waiting Test!\n",
      "EPOCH=002, Loss: 1.949, Accuracy= 21.382%\n",
      "Training complete in 0m 13s\n",
      "Validation accuracy increased (17.105263 --> 21.381579).  Saving model ...\n",
      "\n",
      "Epoch: 3\n",
      "[epoch:3, iter:151] Loss: 0.548 | Accuracy: 96.875% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:3, iter:152] Loss: 0.583 | Accuracy: 95.312% \n",
      "[epoch:3, iter:153] Loss: 0.565 | Accuracy: 96.875% \n",
      "[epoch:3, iter:154] Loss: 0.571 | Accuracy: 96.875% \n",
      "[epoch:3, iter:155] Loss: 0.564 | Accuracy: 97.500% \n",
      "[epoch:3, iter:156] Loss: 0.565 | Accuracy: 97.396% \n",
      "[epoch:3, iter:157] Loss: 0.576 | Accuracy: 96.429% \n",
      "[epoch:3, iter:158] Loss: 0.576 | Accuracy: 96.484% \n",
      "[epoch:3, iter:159] Loss: 0.576 | Accuracy: 96.528% \n",
      "[epoch:3, iter:160] Loss: 0.578 | Accuracy: 96.562% \n",
      "[epoch:3, iter:161] Loss: 0.574 | Accuracy: 96.875% \n",
      "[epoch:3, iter:162] Loss: 0.584 | Accuracy: 96.615% \n",
      "[epoch:3, iter:163] Loss: 0.579 | Accuracy: 96.875% \n",
      "[epoch:3, iter:164] Loss: 0.581 | Accuracy: 96.875% \n",
      "[epoch:3, iter:165] Loss: 0.578 | Accuracy: 97.083% \n",
      "[epoch:3, iter:166] Loss: 0.573 | Accuracy: 97.266% \n",
      "[epoch:3, iter:167] Loss: 0.578 | Accuracy: 97.243% \n",
      "[epoch:3, iter:168] Loss: 0.584 | Accuracy: 97.049% \n",
      "[epoch:3, iter:169] Loss: 0.584 | Accuracy: 97.039% \n",
      "[epoch:3, iter:170] Loss: 0.590 | Accuracy: 96.562% \n",
      "[epoch:3, iter:171] Loss: 0.586 | Accuracy: 96.726% \n",
      "[epoch:3, iter:172] Loss: 0.585 | Accuracy: 96.733% \n",
      "[epoch:3, iter:173] Loss: 0.585 | Accuracy: 96.739% \n",
      "[epoch:3, iter:174] Loss: 0.582 | Accuracy: 96.875% \n",
      "[epoch:3, iter:175] Loss: 0.582 | Accuracy: 96.875% \n",
      "[epoch:3, iter:176] Loss: 0.583 | Accuracy: 96.635% \n",
      "[epoch:3, iter:177] Loss: 0.588 | Accuracy: 96.412% \n",
      "[epoch:3, iter:178] Loss: 0.592 | Accuracy: 96.317% \n",
      "[epoch:3, iter:179] Loss: 0.593 | Accuracy: 96.336% \n",
      "[epoch:3, iter:180] Loss: 0.592 | Accuracy: 96.354% \n",
      "[epoch:3, iter:181] Loss: 0.592 | Accuracy: 96.371% \n",
      "[epoch:3, iter:182] Loss: 0.591 | Accuracy: 96.484% \n",
      "[epoch:3, iter:183] Loss: 0.590 | Accuracy: 96.496% \n",
      "[epoch:3, iter:184] Loss: 0.591 | Accuracy: 96.415% \n",
      "[epoch:3, iter:185] Loss: 0.590 | Accuracy: 96.429% \n",
      "[epoch:3, iter:186] Loss: 0.591 | Accuracy: 96.354% \n",
      "[epoch:3, iter:187] Loss: 0.592 | Accuracy: 96.368% \n",
      "[epoch:3, iter:188] Loss: 0.591 | Accuracy: 96.382% \n",
      "[epoch:3, iter:189] Loss: 0.590 | Accuracy: 96.474% \n",
      "[epoch:3, iter:190] Loss: 0.590 | Accuracy: 96.484% \n",
      "[epoch:3, iter:191] Loss: 0.591 | Accuracy: 96.341% \n",
      "[epoch:3, iter:192] Loss: 0.590 | Accuracy: 96.354% \n",
      "[epoch:3, iter:193] Loss: 0.589 | Accuracy: 96.439% \n",
      "[epoch:3, iter:194] Loss: 0.593 | Accuracy: 96.307% \n",
      "[epoch:3, iter:195] Loss: 0.592 | Accuracy: 96.319% \n",
      "[epoch:3, iter:196] Loss: 0.593 | Accuracy: 96.264% \n",
      "[epoch:3, iter:197] Loss: 0.592 | Accuracy: 96.277% \n",
      "[epoch:3, iter:198] Loss: 0.593 | Accuracy: 96.224% \n",
      "[epoch:3, iter:199] Loss: 0.595 | Accuracy: 96.110% \n",
      "[epoch:3, iter:200] Loss: 0.594 | Accuracy: 96.125% \n",
      "[epoch:3, iter:201] Loss: 0.594 | Accuracy: 96.140% \n",
      "[epoch:3, iter:202] Loss: 0.594 | Accuracy: 96.154% \n",
      "[epoch:3, iter:203] Loss: 0.593 | Accuracy: 96.226% \n",
      "[epoch:3, iter:204] Loss: 0.592 | Accuracy: 96.296% \n",
      "[epoch:3, iter:205] Loss: 0.591 | Accuracy: 96.364% \n",
      "[epoch:3, iter:206] Loss: 0.591 | Accuracy: 96.373% \n",
      "[epoch:3, iter:207] Loss: 0.591 | Accuracy: 96.382% \n",
      "[epoch:3, iter:208] Loss: 0.591 | Accuracy: 96.390% \n",
      "[epoch:3, iter:209] Loss: 0.592 | Accuracy: 96.345% \n",
      "[epoch:3, iter:210] Loss: 0.592 | Accuracy: 96.302% \n",
      "[epoch:3, iter:211] Loss: 0.592 | Accuracy: 96.311% \n",
      "[epoch:3, iter:212] Loss: 0.592 | Accuracy: 96.321% \n",
      "[epoch:3, iter:213] Loss: 0.591 | Accuracy: 96.379% \n",
      "[epoch:3, iter:214] Loss: 0.591 | Accuracy: 96.338% \n",
      "[epoch:3, iter:215] Loss: 0.591 | Accuracy: 96.394% \n",
      "[epoch:3, iter:216] Loss: 0.590 | Accuracy: 96.402% \n",
      "[epoch:3, iter:217] Loss: 0.591 | Accuracy: 96.409% \n",
      "[epoch:3, iter:218] Loss: 0.589 | Accuracy: 96.461% \n",
      "[epoch:3, iter:219] Loss: 0.589 | Accuracy: 96.513% \n",
      "[epoch:3, iter:220] Loss: 0.587 | Accuracy: 96.562% \n",
      "[epoch:3, iter:221] Loss: 0.588 | Accuracy: 96.479% \n",
      "[epoch:3, iter:222] Loss: 0.589 | Accuracy: 96.484% \n",
      "[epoch:3, iter:223] Loss: 0.588 | Accuracy: 96.533% \n",
      "[epoch:3, iter:224] Loss: 0.588 | Accuracy: 96.537% \n",
      "[epoch:3, iter:225] Loss: 0.588 | Accuracy: 96.539% \n",
      "Waiting Test!\n",
      "EPOCH=003, Loss: 2.250, Accuracy= 17.434%\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 4\n",
      "[epoch:4, iter:226] Loss: 0.536 | Accuracy: 100.000% \n",
      "[epoch:4, iter:227] Loss: 0.524 | Accuracy: 100.000% \n",
      "[epoch:4, iter:228] Loss: 0.522 | Accuracy: 100.000% \n",
      "[epoch:4, iter:229] Loss: 0.534 | Accuracy: 98.438% \n",
      "[epoch:4, iter:230] Loss: 0.532 | Accuracy: 98.750% \n",
      "[epoch:4, iter:231] Loss: 0.529 | Accuracy: 98.958% \n",
      "[epoch:4, iter:232] Loss: 0.526 | Accuracy: 99.107% \n",
      "[epoch:4, iter:233] Loss: 0.528 | Accuracy: 98.828% \n",
      "[epoch:4, iter:234] Loss: 0.527 | Accuracy: 98.958% \n",
      "[epoch:4, iter:235] Loss: 0.526 | Accuracy: 99.062% \n",
      "[epoch:4, iter:236] Loss: 0.524 | Accuracy: 99.148% \n",
      "[epoch:4, iter:237] Loss: 0.525 | Accuracy: 99.219% \n",
      "[epoch:4, iter:238] Loss: 0.523 | Accuracy: 99.279% \n",
      "[epoch:4, iter:239] Loss: 0.521 | Accuracy: 99.330% \n",
      "[epoch:4, iter:240] Loss: 0.520 | Accuracy: 99.375% \n",
      "[epoch:4, iter:241] Loss: 0.521 | Accuracy: 99.219% \n",
      "[epoch:4, iter:242] Loss: 0.520 | Accuracy: 99.265% \n",
      "[epoch:4, iter:243] Loss: 0.520 | Accuracy: 99.306% \n",
      "[epoch:4, iter:244] Loss: 0.520 | Accuracy: 99.342% \n",
      "[epoch:4, iter:245] Loss: 0.523 | Accuracy: 99.219% \n",
      "[epoch:4, iter:246] Loss: 0.526 | Accuracy: 99.107% \n",
      "[epoch:4, iter:247] Loss: 0.528 | Accuracy: 99.006% \n",
      "[epoch:4, iter:248] Loss: 0.527 | Accuracy: 99.049% \n",
      "[epoch:4, iter:249] Loss: 0.529 | Accuracy: 98.958% \n",
      "[epoch:4, iter:250] Loss: 0.528 | Accuracy: 99.000% \n",
      "[epoch:4, iter:251] Loss: 0.529 | Accuracy: 98.918% \n",
      "[epoch:4, iter:252] Loss: 0.528 | Accuracy: 98.958% \n",
      "[epoch:4, iter:253] Loss: 0.528 | Accuracy: 98.996% \n",
      "[epoch:4, iter:254] Loss: 0.528 | Accuracy: 99.030% \n",
      "[epoch:4, iter:255] Loss: 0.531 | Accuracy: 98.854% \n",
      "[epoch:4, iter:256] Loss: 0.534 | Accuracy: 98.690% \n",
      "[epoch:4, iter:257] Loss: 0.533 | Accuracy: 98.730% \n",
      "[epoch:4, iter:258] Loss: 0.533 | Accuracy: 98.769% \n",
      "[epoch:4, iter:259] Loss: 0.535 | Accuracy: 98.713% \n",
      "[epoch:4, iter:260] Loss: 0.535 | Accuracy: 98.750% \n",
      "[epoch:4, iter:261] Loss: 0.535 | Accuracy: 98.785% \n",
      "[epoch:4, iter:262] Loss: 0.535 | Accuracy: 98.733% \n",
      "[epoch:4, iter:263] Loss: 0.534 | Accuracy: 98.766% \n",
      "[epoch:4, iter:264] Loss: 0.533 | Accuracy: 98.798% \n",
      "[epoch:4, iter:265] Loss: 0.533 | Accuracy: 98.750% \n",
      "[epoch:4, iter:266] Loss: 0.532 | Accuracy: 98.780% \n",
      "[epoch:4, iter:267] Loss: 0.532 | Accuracy: 98.810% \n",
      "[epoch:4, iter:268] Loss: 0.532 | Accuracy: 98.765% \n",
      "[epoch:4, iter:269] Loss: 0.532 | Accuracy: 98.793% \n",
      "[epoch:4, iter:270] Loss: 0.533 | Accuracy: 98.750% \n",
      "[epoch:4, iter:271] Loss: 0.534 | Accuracy: 98.641% \n",
      "[epoch:4, iter:272] Loss: 0.535 | Accuracy: 98.604% \n",
      "[epoch:4, iter:273] Loss: 0.536 | Accuracy: 98.568% \n",
      "[epoch:4, iter:274] Loss: 0.536 | Accuracy: 98.533% \n",
      "[epoch:4, iter:275] Loss: 0.535 | Accuracy: 98.562% \n",
      "[epoch:4, iter:276] Loss: 0.535 | Accuracy: 98.591% \n",
      "[epoch:4, iter:277] Loss: 0.537 | Accuracy: 98.498% \n",
      "[epoch:4, iter:278] Loss: 0.539 | Accuracy: 98.408% \n",
      "[epoch:4, iter:279] Loss: 0.540 | Accuracy: 98.380% \n",
      "[epoch:4, iter:280] Loss: 0.541 | Accuracy: 98.352% \n",
      "[epoch:4, iter:281] Loss: 0.542 | Accuracy: 98.326% \n",
      "[epoch:4, iter:282] Loss: 0.541 | Accuracy: 98.355% \n",
      "[epoch:4, iter:283] Loss: 0.541 | Accuracy: 98.384% \n",
      "[epoch:4, iter:284] Loss: 0.540 | Accuracy: 98.411% \n",
      "[epoch:4, iter:285] Loss: 0.540 | Accuracy: 98.438% \n",
      "[epoch:4, iter:286] Loss: 0.540 | Accuracy: 98.463% \n",
      "[epoch:4, iter:287] Loss: 0.542 | Accuracy: 98.387% \n",
      "[epoch:4, iter:288] Loss: 0.542 | Accuracy: 98.413% \n",
      "[epoch:4, iter:289] Loss: 0.543 | Accuracy: 98.340% \n",
      "[epoch:4, iter:290] Loss: 0.543 | Accuracy: 98.317% \n",
      "[epoch:4, iter:291] Loss: 0.542 | Accuracy: 98.343% \n",
      "[epoch:4, iter:292] Loss: 0.542 | Accuracy: 98.368% \n",
      "[epoch:4, iter:293] Loss: 0.541 | Accuracy: 98.392% \n",
      "[epoch:4, iter:294] Loss: 0.542 | Accuracy: 98.370% \n",
      "[epoch:4, iter:295] Loss: 0.541 | Accuracy: 98.393% \n",
      "[epoch:4, iter:296] Loss: 0.541 | Accuracy: 98.415% \n",
      "[epoch:4, iter:297] Loss: 0.540 | Accuracy: 98.438% \n",
      "[epoch:4, iter:298] Loss: 0.541 | Accuracy: 98.373% \n",
      "[epoch:4, iter:299] Loss: 0.541 | Accuracy: 98.353% \n",
      "[epoch:4, iter:300] Loss: 0.541 | Accuracy: 98.354% \n",
      "Waiting Test!\n",
      "EPOCH=004, Loss: 2.084, Accuracy= 21.053%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "\n",
      "Epoch: 5\n",
      "[epoch:5, iter:301] Loss: 0.517 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:5, iter:302] Loss: 0.515 | Accuracy: 100.000% \n",
      "[epoch:5, iter:303] Loss: 0.531 | Accuracy: 98.958% \n",
      "[epoch:5, iter:304] Loss: 0.525 | Accuracy: 99.219% \n",
      "[epoch:5, iter:305] Loss: 0.522 | Accuracy: 99.375% \n",
      "[epoch:5, iter:306] Loss: 0.533 | Accuracy: 97.917% \n",
      "[epoch:5, iter:307] Loss: 0.530 | Accuracy: 98.214% \n",
      "[epoch:5, iter:308] Loss: 0.532 | Accuracy: 98.047% \n",
      "[epoch:5, iter:309] Loss: 0.529 | Accuracy: 98.264% \n",
      "[epoch:5, iter:310] Loss: 0.530 | Accuracy: 98.125% \n",
      "[epoch:5, iter:311] Loss: 0.530 | Accuracy: 98.011% \n",
      "[epoch:5, iter:312] Loss: 0.530 | Accuracy: 98.177% \n",
      "[epoch:5, iter:313] Loss: 0.534 | Accuracy: 98.077% \n",
      "[epoch:5, iter:314] Loss: 0.533 | Accuracy: 98.214% \n",
      "[epoch:5, iter:315] Loss: 0.534 | Accuracy: 98.125% \n",
      "[epoch:5, iter:316] Loss: 0.532 | Accuracy: 98.047% \n",
      "[epoch:5, iter:317] Loss: 0.531 | Accuracy: 98.162% \n",
      "[epoch:5, iter:318] Loss: 0.530 | Accuracy: 98.264% \n",
      "[epoch:5, iter:319] Loss: 0.530 | Accuracy: 98.191% \n",
      "[epoch:5, iter:320] Loss: 0.529 | Accuracy: 98.281% \n",
      "[epoch:5, iter:321] Loss: 0.531 | Accuracy: 98.065% \n",
      "[epoch:5, iter:322] Loss: 0.539 | Accuracy: 97.869% \n",
      "[epoch:5, iter:323] Loss: 0.540 | Accuracy: 97.962% \n",
      "[epoch:5, iter:324] Loss: 0.538 | Accuracy: 98.047% \n",
      "[epoch:5, iter:325] Loss: 0.537 | Accuracy: 98.125% \n",
      "[epoch:5, iter:326] Loss: 0.537 | Accuracy: 98.077% \n",
      "[epoch:5, iter:327] Loss: 0.537 | Accuracy: 98.032% \n",
      "[epoch:5, iter:328] Loss: 0.537 | Accuracy: 98.103% \n",
      "[epoch:5, iter:329] Loss: 0.537 | Accuracy: 98.168% \n",
      "[epoch:5, iter:330] Loss: 0.538 | Accuracy: 98.021% \n",
      "[epoch:5, iter:331] Loss: 0.539 | Accuracy: 97.984% \n",
      "[epoch:5, iter:332] Loss: 0.540 | Accuracy: 97.949% \n",
      "[epoch:5, iter:333] Loss: 0.539 | Accuracy: 98.011% \n",
      "[epoch:5, iter:334] Loss: 0.541 | Accuracy: 97.978% \n",
      "[epoch:5, iter:335] Loss: 0.540 | Accuracy: 98.036% \n",
      "[epoch:5, iter:336] Loss: 0.540 | Accuracy: 97.917% \n",
      "[epoch:5, iter:337] Loss: 0.541 | Accuracy: 97.889% \n",
      "[epoch:5, iter:338] Loss: 0.540 | Accuracy: 97.944% \n",
      "[epoch:5, iter:339] Loss: 0.539 | Accuracy: 97.997% \n",
      "[epoch:5, iter:340] Loss: 0.539 | Accuracy: 97.969% \n",
      "[epoch:5, iter:341] Loss: 0.538 | Accuracy: 98.018% \n",
      "[epoch:5, iter:342] Loss: 0.537 | Accuracy: 98.065% \n",
      "[epoch:5, iter:343] Loss: 0.539 | Accuracy: 98.038% \n",
      "[epoch:5, iter:344] Loss: 0.541 | Accuracy: 97.869% \n",
      "[epoch:5, iter:345] Loss: 0.542 | Accuracy: 97.847% \n",
      "[epoch:5, iter:346] Loss: 0.542 | Accuracy: 97.894% \n",
      "[epoch:5, iter:347] Loss: 0.543 | Accuracy: 97.872% \n",
      "[epoch:5, iter:348] Loss: 0.542 | Accuracy: 97.917% \n",
      "[epoch:5, iter:349] Loss: 0.542 | Accuracy: 97.895% \n",
      "[epoch:5, iter:350] Loss: 0.541 | Accuracy: 97.938% \n",
      "[epoch:5, iter:351] Loss: 0.541 | Accuracy: 97.978% \n",
      "[epoch:5, iter:352] Loss: 0.540 | Accuracy: 98.017% \n",
      "[epoch:5, iter:353] Loss: 0.539 | Accuracy: 98.054% \n",
      "[epoch:5, iter:354] Loss: 0.539 | Accuracy: 98.090% \n",
      "[epoch:5, iter:355] Loss: 0.538 | Accuracy: 98.125% \n",
      "[epoch:5, iter:356] Loss: 0.538 | Accuracy: 98.158% \n",
      "[epoch:5, iter:357] Loss: 0.538 | Accuracy: 98.191% \n",
      "[epoch:5, iter:358] Loss: 0.537 | Accuracy: 98.222% \n",
      "[epoch:5, iter:359] Loss: 0.536 | Accuracy: 98.252% \n",
      "[epoch:5, iter:360] Loss: 0.536 | Accuracy: 98.281% \n",
      "[epoch:5, iter:361] Loss: 0.535 | Accuracy: 98.309% \n",
      "[epoch:5, iter:362] Loss: 0.536 | Accuracy: 98.286% \n",
      "[epoch:5, iter:363] Loss: 0.536 | Accuracy: 98.264% \n",
      "[epoch:5, iter:364] Loss: 0.537 | Accuracy: 98.242% \n",
      "[epoch:5, iter:365] Loss: 0.537 | Accuracy: 98.221% \n",
      "[epoch:5, iter:366] Loss: 0.537 | Accuracy: 98.201% \n",
      "[epoch:5, iter:367] Loss: 0.537 | Accuracy: 98.228% \n",
      "[epoch:5, iter:368] Loss: 0.537 | Accuracy: 98.254% \n",
      "[epoch:5, iter:369] Loss: 0.537 | Accuracy: 98.279% \n",
      "[epoch:5, iter:370] Loss: 0.537 | Accuracy: 98.259% \n",
      "[epoch:5, iter:371] Loss: 0.539 | Accuracy: 98.239% \n",
      "[epoch:5, iter:372] Loss: 0.538 | Accuracy: 98.220% \n",
      "[epoch:5, iter:373] Loss: 0.539 | Accuracy: 98.159% \n",
      "[epoch:5, iter:374] Loss: 0.539 | Accuracy: 98.142% \n",
      "[epoch:5, iter:375] Loss: 0.539 | Accuracy: 98.143% \n",
      "Waiting Test!\n",
      "EPOCH=005, Loss: 1.514, Accuracy= 54.934%\n",
      "Training complete in 0m 13s\n",
      "Validation accuracy increased (21.381579 --> 54.934211).  Saving model ...\n",
      "\n",
      "Epoch: 6\n",
      "[epoch:6, iter:376] Loss: 0.529 | Accuracy: 96.875% \n",
      "[epoch:6, iter:377] Loss: 0.536 | Accuracy: 96.875% \n",
      "[epoch:6, iter:378] Loss: 0.537 | Accuracy: 97.917% \n",
      "[epoch:6, iter:379] Loss: 0.533 | Accuracy: 98.438% \n",
      "[epoch:6, iter:380] Loss: 0.545 | Accuracy: 97.500% \n",
      "[epoch:6, iter:381] Loss: 0.541 | Accuracy: 97.917% \n",
      "[epoch:6, iter:382] Loss: 0.536 | Accuracy: 98.214% \n",
      "[epoch:6, iter:383] Loss: 0.534 | Accuracy: 98.438% \n",
      "[epoch:6, iter:384] Loss: 0.535 | Accuracy: 98.264% \n",
      "[epoch:6, iter:385] Loss: 0.534 | Accuracy: 98.438% \n",
      "[epoch:6, iter:386] Loss: 0.532 | Accuracy: 98.580% \n",
      "[epoch:6, iter:387] Loss: 0.532 | Accuracy: 98.698% \n",
      "[epoch:6, iter:388] Loss: 0.544 | Accuracy: 98.077% \n",
      "[epoch:6, iter:389] Loss: 0.545 | Accuracy: 98.214% \n",
      "[epoch:6, iter:390] Loss: 0.543 | Accuracy: 98.333% \n",
      "[epoch:6, iter:391] Loss: 0.542 | Accuracy: 98.242% \n",
      "[epoch:6, iter:392] Loss: 0.540 | Accuracy: 98.346% \n",
      "[epoch:6, iter:393] Loss: 0.538 | Accuracy: 98.438% \n",
      "[epoch:6, iter:394] Loss: 0.537 | Accuracy: 98.520% \n",
      "[epoch:6, iter:395] Loss: 0.536 | Accuracy: 98.438% \n",
      "[epoch:6, iter:396] Loss: 0.536 | Accuracy: 98.512% \n",
      "[epoch:6, iter:397] Loss: 0.546 | Accuracy: 98.153% \n",
      "[epoch:6, iter:398] Loss: 0.545 | Accuracy: 98.234% \n",
      "[epoch:6, iter:399] Loss: 0.543 | Accuracy: 98.307% \n",
      "[epoch:6, iter:400] Loss: 0.544 | Accuracy: 98.250% \n",
      "[epoch:6, iter:401] Loss: 0.542 | Accuracy: 98.317% \n",
      "[epoch:6, iter:402] Loss: 0.547 | Accuracy: 98.032% \n",
      "[epoch:6, iter:403] Loss: 0.546 | Accuracy: 98.103% \n",
      "[epoch:6, iter:404] Loss: 0.546 | Accuracy: 98.060% \n",
      "[epoch:6, iter:405] Loss: 0.548 | Accuracy: 98.021% \n",
      "[epoch:6, iter:406] Loss: 0.547 | Accuracy: 97.984% \n",
      "[epoch:6, iter:407] Loss: 0.546 | Accuracy: 98.047% \n",
      "[epoch:6, iter:408] Loss: 0.545 | Accuracy: 98.106% \n",
      "[epoch:6, iter:409] Loss: 0.543 | Accuracy: 98.162% \n",
      "[epoch:6, iter:410] Loss: 0.543 | Accuracy: 98.214% \n",
      "[epoch:6, iter:411] Loss: 0.543 | Accuracy: 98.177% \n",
      "[epoch:6, iter:412] Loss: 0.545 | Accuracy: 98.142% \n",
      "[epoch:6, iter:413] Loss: 0.545 | Accuracy: 98.109% \n",
      "[epoch:6, iter:414] Loss: 0.544 | Accuracy: 98.157% \n",
      "[epoch:6, iter:415] Loss: 0.544 | Accuracy: 98.203% \n",
      "[epoch:6, iter:416] Loss: 0.543 | Accuracy: 98.247% \n",
      "[epoch:6, iter:417] Loss: 0.542 | Accuracy: 98.289% \n",
      "[epoch:6, iter:418] Loss: 0.545 | Accuracy: 98.183% \n",
      "[epoch:6, iter:419] Loss: 0.544 | Accuracy: 98.153% \n",
      "[epoch:6, iter:420] Loss: 0.543 | Accuracy: 98.194% \n",
      "[epoch:6, iter:421] Loss: 0.542 | Accuracy: 98.234% \n",
      "[epoch:6, iter:422] Loss: 0.541 | Accuracy: 98.271% \n",
      "[epoch:6, iter:423] Loss: 0.541 | Accuracy: 98.307% \n",
      "[epoch:6, iter:424] Loss: 0.540 | Accuracy: 98.342% \n",
      "[epoch:6, iter:425] Loss: 0.539 | Accuracy: 98.375% \n",
      "[epoch:6, iter:426] Loss: 0.539 | Accuracy: 98.346% \n",
      "[epoch:6, iter:427] Loss: 0.539 | Accuracy: 98.257% \n",
      "[epoch:6, iter:428] Loss: 0.539 | Accuracy: 98.290% \n",
      "[epoch:6, iter:429] Loss: 0.538 | Accuracy: 98.322% \n",
      "[epoch:6, iter:430] Loss: 0.539 | Accuracy: 98.239% \n",
      "[epoch:6, iter:431] Loss: 0.539 | Accuracy: 98.214% \n",
      "[epoch:6, iter:432] Loss: 0.538 | Accuracy: 98.246% \n",
      "[epoch:6, iter:433] Loss: 0.538 | Accuracy: 98.276% \n",
      "[epoch:6, iter:434] Loss: 0.538 | Accuracy: 98.252% \n",
      "[epoch:6, iter:435] Loss: 0.538 | Accuracy: 98.229% \n",
      "[epoch:6, iter:436] Loss: 0.537 | Accuracy: 98.258% \n",
      "[epoch:6, iter:437] Loss: 0.537 | Accuracy: 98.286% \n",
      "[epoch:6, iter:438] Loss: 0.537 | Accuracy: 98.313% \n",
      "[epoch:6, iter:439] Loss: 0.536 | Accuracy: 98.340% \n",
      "[epoch:6, iter:440] Loss: 0.536 | Accuracy: 98.365% \n",
      "[epoch:6, iter:441] Loss: 0.537 | Accuracy: 98.343% \n",
      "[epoch:6, iter:442] Loss: 0.537 | Accuracy: 98.368% \n",
      "[epoch:6, iter:443] Loss: 0.536 | Accuracy: 98.392% \n",
      "[epoch:6, iter:444] Loss: 0.536 | Accuracy: 98.415% \n",
      "[epoch:6, iter:445] Loss: 0.535 | Accuracy: 98.438% \n",
      "[epoch:6, iter:446] Loss: 0.535 | Accuracy: 98.415% \n",
      "[epoch:6, iter:447] Loss: 0.536 | Accuracy: 98.394% \n",
      "[epoch:6, iter:448] Loss: 0.536 | Accuracy: 98.373% \n",
      "[epoch:6, iter:449] Loss: 0.536 | Accuracy: 98.395% \n",
      "[epoch:6, iter:450] Loss: 0.538 | Accuracy: 98.396% \n",
      "Waiting Test!\n",
      "EPOCH=006, Loss: 1.180, Accuracy= 75.658%\n",
      "Training complete in 0m 14s\n",
      "Validation accuracy increased (54.934211 --> 75.657895).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7\n",
      "[epoch:7, iter:451] Loss: 0.574 | Accuracy: 96.875% \n",
      "[epoch:7, iter:452] Loss: 0.583 | Accuracy: 95.312% \n",
      "[epoch:7, iter:453] Loss: 0.555 | Accuracy: 96.875% \n",
      "[epoch:7, iter:454] Loss: 0.548 | Accuracy: 96.875% \n",
      "[epoch:7, iter:455] Loss: 0.541 | Accuracy: 97.500% \n",
      "[epoch:7, iter:456] Loss: 0.536 | Accuracy: 97.917% \n",
      "[epoch:7, iter:457] Loss: 0.533 | Accuracy: 97.768% \n",
      "[epoch:7, iter:458] Loss: 0.534 | Accuracy: 98.047% \n",
      "[epoch:7, iter:459] Loss: 0.534 | Accuracy: 97.917% \n",
      "[epoch:7, iter:460] Loss: 0.531 | Accuracy: 98.125% \n",
      "[epoch:7, iter:461] Loss: 0.536 | Accuracy: 97.727% \n",
      "[epoch:7, iter:462] Loss: 0.541 | Accuracy: 97.656% \n",
      "[epoch:7, iter:463] Loss: 0.539 | Accuracy: 97.837% \n",
      "[epoch:7, iter:464] Loss: 0.548 | Accuracy: 97.321% \n",
      "[epoch:7, iter:465] Loss: 0.546 | Accuracy: 97.500% \n",
      "[epoch:7, iter:466] Loss: 0.548 | Accuracy: 97.461% \n",
      "[epoch:7, iter:467] Loss: 0.545 | Accuracy: 97.610% \n",
      "[epoch:7, iter:468] Loss: 0.543 | Accuracy: 97.743% \n",
      "[epoch:7, iter:469] Loss: 0.541 | Accuracy: 97.862% \n",
      "[epoch:7, iter:470] Loss: 0.539 | Accuracy: 97.969% \n",
      "[epoch:7, iter:471] Loss: 0.537 | Accuracy: 98.065% \n",
      "[epoch:7, iter:472] Loss: 0.537 | Accuracy: 98.153% \n",
      "[epoch:7, iter:473] Loss: 0.535 | Accuracy: 98.234% \n",
      "[epoch:7, iter:474] Loss: 0.533 | Accuracy: 98.307% \n",
      "[epoch:7, iter:475] Loss: 0.536 | Accuracy: 98.125% \n",
      "[epoch:7, iter:476] Loss: 0.534 | Accuracy: 98.197% \n",
      "[epoch:7, iter:477] Loss: 0.534 | Accuracy: 98.264% \n",
      "[epoch:7, iter:478] Loss: 0.533 | Accuracy: 98.326% \n",
      "[epoch:7, iter:479] Loss: 0.533 | Accuracy: 98.276% \n",
      "[epoch:7, iter:480] Loss: 0.533 | Accuracy: 98.229% \n",
      "[epoch:7, iter:481] Loss: 0.532 | Accuracy: 98.286% \n",
      "[epoch:7, iter:482] Loss: 0.531 | Accuracy: 98.340% \n",
      "[epoch:7, iter:483] Loss: 0.531 | Accuracy: 98.295% \n",
      "[epoch:7, iter:484] Loss: 0.530 | Accuracy: 98.346% \n",
      "[epoch:7, iter:485] Loss: 0.530 | Accuracy: 98.393% \n",
      "[epoch:7, iter:486] Loss: 0.530 | Accuracy: 98.351% \n",
      "[epoch:7, iter:487] Loss: 0.529 | Accuracy: 98.395% \n",
      "[epoch:7, iter:488] Loss: 0.529 | Accuracy: 98.438% \n",
      "[epoch:7, iter:489] Loss: 0.529 | Accuracy: 98.397% \n",
      "[epoch:7, iter:490] Loss: 0.528 | Accuracy: 98.438% \n",
      "[epoch:7, iter:491] Loss: 0.527 | Accuracy: 98.476% \n",
      "[epoch:7, iter:492] Loss: 0.527 | Accuracy: 98.512% \n",
      "[epoch:7, iter:493] Loss: 0.526 | Accuracy: 98.547% \n",
      "[epoch:7, iter:494] Loss: 0.526 | Accuracy: 98.580% \n",
      "[epoch:7, iter:495] Loss: 0.525 | Accuracy: 98.542% \n",
      "[epoch:7, iter:496] Loss: 0.525 | Accuracy: 98.573% \n",
      "[epoch:7, iter:497] Loss: 0.525 | Accuracy: 98.604% \n",
      "[epoch:7, iter:498] Loss: 0.525 | Accuracy: 98.568% \n",
      "[epoch:7, iter:499] Loss: 0.526 | Accuracy: 98.533% \n",
      "[epoch:7, iter:500] Loss: 0.525 | Accuracy: 98.562% \n",
      "[epoch:7, iter:501] Loss: 0.524 | Accuracy: 98.591% \n",
      "[epoch:7, iter:502] Loss: 0.525 | Accuracy: 98.558% \n",
      "[epoch:7, iter:503] Loss: 0.525 | Accuracy: 98.585% \n",
      "[epoch:7, iter:504] Loss: 0.524 | Accuracy: 98.611% \n",
      "[epoch:7, iter:505] Loss: 0.525 | Accuracy: 98.636% \n",
      "[epoch:7, iter:506] Loss: 0.524 | Accuracy: 98.661% \n",
      "[epoch:7, iter:507] Loss: 0.524 | Accuracy: 98.684% \n",
      "[epoch:7, iter:508] Loss: 0.524 | Accuracy: 98.707% \n",
      "[epoch:7, iter:509] Loss: 0.524 | Accuracy: 98.729% \n",
      "[epoch:7, iter:510] Loss: 0.523 | Accuracy: 98.750% \n",
      "[epoch:7, iter:511] Loss: 0.523 | Accuracy: 98.770% \n",
      "[epoch:7, iter:512] Loss: 0.522 | Accuracy: 98.790% \n",
      "[epoch:7, iter:513] Loss: 0.522 | Accuracy: 98.810% \n",
      "[epoch:7, iter:514] Loss: 0.522 | Accuracy: 98.779% \n",
      "[epoch:7, iter:515] Loss: 0.522 | Accuracy: 98.798% \n",
      "[epoch:7, iter:516] Loss: 0.522 | Accuracy: 98.769% \n",
      "[epoch:7, iter:517] Loss: 0.521 | Accuracy: 98.787% \n",
      "[epoch:7, iter:518] Loss: 0.521 | Accuracy: 98.805% \n",
      "[epoch:7, iter:519] Loss: 0.521 | Accuracy: 98.822% \n",
      "[epoch:7, iter:520] Loss: 0.520 | Accuracy: 98.839% \n",
      "[epoch:7, iter:521] Loss: 0.520 | Accuracy: 98.856% \n",
      "[epoch:7, iter:522] Loss: 0.520 | Accuracy: 98.872% \n",
      "[epoch:7, iter:523] Loss: 0.520 | Accuracy: 98.844% \n",
      "[epoch:7, iter:524] Loss: 0.520 | Accuracy: 98.860% \n",
      "[epoch:7, iter:525] Loss: 0.549 | Accuracy: 98.818% \n",
      "Waiting Test!\n",
      "EPOCH=007, Loss: 1.701, Accuracy= 51.316%\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 8\n",
      "[epoch:8, iter:526] Loss: 0.921 | Accuracy: 68.750% \n",
      "[epoch:8, iter:527] Loss: 0.747 | Accuracy: 84.375% \n",
      "[epoch:8, iter:528] Loss: 0.670 | Accuracy: 89.583% \n",
      "[epoch:8, iter:529] Loss: 0.635 | Accuracy: 92.188% \n",
      "[epoch:8, iter:530] Loss: 0.617 | Accuracy: 93.750% \n",
      "[epoch:8, iter:531] Loss: 0.608 | Accuracy: 94.271% \n",
      "[epoch:8, iter:532] Loss: 0.594 | Accuracy: 95.089% \n",
      "[epoch:8, iter:533] Loss: 0.583 | Accuracy: 95.703% \n",
      "[epoch:8, iter:534] Loss: 0.574 | Accuracy: 96.181% \n",
      "[epoch:8, iter:535] Loss: 0.575 | Accuracy: 96.250% \n",
      "[epoch:8, iter:536] Loss: 0.571 | Accuracy: 96.591% \n",
      "[epoch:8, iter:537] Loss: 0.575 | Accuracy: 96.615% \n",
      "[epoch:8, iter:538] Loss: 0.572 | Accuracy: 96.635% \n",
      "[epoch:8, iter:539] Loss: 0.567 | Accuracy: 96.875% \n",
      "[epoch:8, iter:540] Loss: 0.563 | Accuracy: 97.083% \n",
      "[epoch:8, iter:541] Loss: 0.560 | Accuracy: 97.266% \n",
      "[epoch:8, iter:542] Loss: 0.557 | Accuracy: 97.426% \n",
      "[epoch:8, iter:543] Loss: 0.556 | Accuracy: 97.396% \n",
      "[epoch:8, iter:544] Loss: 0.555 | Accuracy: 97.368% \n",
      "[epoch:8, iter:545] Loss: 0.553 | Accuracy: 97.500% \n",
      "[epoch:8, iter:546] Loss: 0.550 | Accuracy: 97.619% \n",
      "[epoch:8, iter:547] Loss: 0.548 | Accuracy: 97.727% \n",
      "[epoch:8, iter:548] Loss: 0.547 | Accuracy: 97.826% \n",
      "[epoch:8, iter:549] Loss: 0.545 | Accuracy: 97.917% \n",
      "[epoch:8, iter:550] Loss: 0.544 | Accuracy: 98.000% \n",
      "[epoch:8, iter:551] Loss: 0.542 | Accuracy: 98.077% \n",
      "[epoch:8, iter:552] Loss: 0.543 | Accuracy: 98.032% \n",
      "[epoch:8, iter:553] Loss: 0.542 | Accuracy: 98.103% \n",
      "[epoch:8, iter:554] Loss: 0.541 | Accuracy: 98.168% \n",
      "[epoch:8, iter:555] Loss: 0.540 | Accuracy: 98.229% \n",
      "[epoch:8, iter:556] Loss: 0.540 | Accuracy: 98.286% \n",
      "[epoch:8, iter:557] Loss: 0.541 | Accuracy: 98.242% \n",
      "[epoch:8, iter:558] Loss: 0.540 | Accuracy: 98.295% \n",
      "[epoch:8, iter:559] Loss: 0.540 | Accuracy: 98.346% \n",
      "[epoch:8, iter:560] Loss: 0.539 | Accuracy: 98.393% \n",
      "[epoch:8, iter:561] Loss: 0.538 | Accuracy: 98.438% \n",
      "[epoch:8, iter:562] Loss: 0.538 | Accuracy: 98.395% \n",
      "[epoch:8, iter:563] Loss: 0.538 | Accuracy: 98.355% \n",
      "[epoch:8, iter:564] Loss: 0.537 | Accuracy: 98.397% \n",
      "[epoch:8, iter:565] Loss: 0.536 | Accuracy: 98.438% \n",
      "[epoch:8, iter:566] Loss: 0.536 | Accuracy: 98.476% \n",
      "[epoch:8, iter:567] Loss: 0.536 | Accuracy: 98.438% \n",
      "[epoch:8, iter:568] Loss: 0.536 | Accuracy: 98.401% \n",
      "[epoch:8, iter:569] Loss: 0.535 | Accuracy: 98.438% \n",
      "[epoch:8, iter:570] Loss: 0.535 | Accuracy: 98.472% \n",
      "[epoch:8, iter:571] Loss: 0.534 | Accuracy: 98.505% \n",
      "[epoch:8, iter:572] Loss: 0.535 | Accuracy: 98.471% \n",
      "[epoch:8, iter:573] Loss: 0.534 | Accuracy: 98.503% \n",
      "[epoch:8, iter:574] Loss: 0.534 | Accuracy: 98.533% \n",
      "[epoch:8, iter:575] Loss: 0.533 | Accuracy: 98.562% \n",
      "[epoch:8, iter:576] Loss: 0.533 | Accuracy: 98.591% \n",
      "[epoch:8, iter:577] Loss: 0.533 | Accuracy: 98.558% \n",
      "[epoch:8, iter:578] Loss: 0.534 | Accuracy: 98.526% \n",
      "[epoch:8, iter:579] Loss: 0.533 | Accuracy: 98.553% \n",
      "[epoch:8, iter:580] Loss: 0.533 | Accuracy: 98.580% \n",
      "[epoch:8, iter:581] Loss: 0.532 | Accuracy: 98.605% \n",
      "[epoch:8, iter:582] Loss: 0.531 | Accuracy: 98.629% \n",
      "[epoch:8, iter:583] Loss: 0.531 | Accuracy: 98.653% \n",
      "[epoch:8, iter:584] Loss: 0.531 | Accuracy: 98.676% \n",
      "[epoch:8, iter:585] Loss: 0.530 | Accuracy: 98.698% \n",
      "[epoch:8, iter:586] Loss: 0.532 | Accuracy: 98.566% \n",
      "[epoch:8, iter:587] Loss: 0.533 | Accuracy: 98.488% \n",
      "[epoch:8, iter:588] Loss: 0.532 | Accuracy: 98.512% \n",
      "[epoch:8, iter:589] Loss: 0.532 | Accuracy: 98.486% \n",
      "[epoch:8, iter:590] Loss: 0.532 | Accuracy: 98.462% \n",
      "[epoch:8, iter:591] Loss: 0.532 | Accuracy: 98.485% \n",
      "[epoch:8, iter:592] Loss: 0.531 | Accuracy: 98.507% \n",
      "[epoch:8, iter:593] Loss: 0.531 | Accuracy: 98.529% \n",
      "[epoch:8, iter:594] Loss: 0.532 | Accuracy: 98.505% \n",
      "[epoch:8, iter:595] Loss: 0.531 | Accuracy: 98.527% \n",
      "[epoch:8, iter:596] Loss: 0.531 | Accuracy: 98.548% \n",
      "[epoch:8, iter:597] Loss: 0.531 | Accuracy: 98.568% \n",
      "[epoch:8, iter:598] Loss: 0.530 | Accuracy: 98.587% \n",
      "[epoch:8, iter:599] Loss: 0.530 | Accuracy: 98.564% \n",
      "[epoch:8, iter:600] Loss: 0.531 | Accuracy: 98.565% \n",
      "Waiting Test!\n",
      "EPOCH=008, Loss: 0.902, Accuracy= 81.250%\n",
      "Training complete in 0m 14s\n",
      "Validation accuracy increased (75.657895 --> 81.250000).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9\n",
      "[epoch:9, iter:601] Loss: 0.614 | Accuracy: 93.750% \n",
      "[epoch:9, iter:602] Loss: 0.560 | Accuracy: 96.875% \n",
      "[epoch:9, iter:603] Loss: 0.543 | Accuracy: 97.917% \n",
      "[epoch:9, iter:604] Loss: 0.535 | Accuracy: 98.438% \n",
      "[epoch:9, iter:605] Loss: 0.538 | Accuracy: 98.125% \n",
      "[epoch:9, iter:606] Loss: 0.542 | Accuracy: 97.917% \n",
      "[epoch:9, iter:607] Loss: 0.539 | Accuracy: 98.214% \n",
      "[epoch:9, iter:608] Loss: 0.535 | Accuracy: 98.438% \n",
      "[epoch:9, iter:609] Loss: 0.531 | Accuracy: 98.611% \n",
      "[epoch:9, iter:610] Loss: 0.538 | Accuracy: 98.125% \n",
      "[epoch:9, iter:611] Loss: 0.534 | Accuracy: 98.295% \n",
      "[epoch:9, iter:612] Loss: 0.532 | Accuracy: 98.438% \n",
      "[epoch:9, iter:613] Loss: 0.530 | Accuracy: 98.558% \n",
      "[epoch:9, iter:614] Loss: 0.535 | Accuracy: 98.438% \n",
      "[epoch:9, iter:615] Loss: 0.533 | Accuracy: 98.542% \n",
      "[epoch:9, iter:616] Loss: 0.531 | Accuracy: 98.633% \n",
      "[epoch:9, iter:617] Loss: 0.532 | Accuracy: 98.529% \n",
      "[epoch:9, iter:618] Loss: 0.530 | Accuracy: 98.611% \n",
      "[epoch:9, iter:619] Loss: 0.529 | Accuracy: 98.684% \n",
      "[epoch:9, iter:620] Loss: 0.528 | Accuracy: 98.750% \n",
      "[epoch:9, iter:621] Loss: 0.527 | Accuracy: 98.810% \n",
      "[epoch:9, iter:622] Loss: 0.530 | Accuracy: 98.580% \n",
      "[epoch:9, iter:623] Loss: 0.530 | Accuracy: 98.505% \n",
      "[epoch:9, iter:624] Loss: 0.529 | Accuracy: 98.568% \n",
      "[epoch:9, iter:625] Loss: 0.528 | Accuracy: 98.625% \n",
      "[epoch:9, iter:626] Loss: 0.527 | Accuracy: 98.678% \n",
      "[epoch:9, iter:627] Loss: 0.526 | Accuracy: 98.727% \n",
      "[epoch:9, iter:628] Loss: 0.526 | Accuracy: 98.772% \n",
      "[epoch:9, iter:629] Loss: 0.526 | Accuracy: 98.707% \n",
      "[epoch:9, iter:630] Loss: 0.527 | Accuracy: 98.542% \n",
      "[epoch:9, iter:631] Loss: 0.526 | Accuracy: 98.589% \n",
      "[epoch:9, iter:632] Loss: 0.527 | Accuracy: 98.535% \n",
      "[epoch:9, iter:633] Loss: 0.526 | Accuracy: 98.580% \n",
      "[epoch:9, iter:634] Loss: 0.525 | Accuracy: 98.621% \n",
      "[epoch:9, iter:635] Loss: 0.525 | Accuracy: 98.571% \n",
      "[epoch:9, iter:636] Loss: 0.525 | Accuracy: 98.611% \n",
      "[epoch:9, iter:637] Loss: 0.527 | Accuracy: 98.564% \n",
      "[epoch:9, iter:638] Loss: 0.526 | Accuracy: 98.602% \n",
      "[epoch:9, iter:639] Loss: 0.525 | Accuracy: 98.638% \n",
      "[epoch:9, iter:640] Loss: 0.525 | Accuracy: 98.672% \n",
      "[epoch:9, iter:641] Loss: 0.525 | Accuracy: 98.628% \n",
      "[epoch:9, iter:642] Loss: 0.524 | Accuracy: 98.661% \n",
      "[epoch:9, iter:643] Loss: 0.524 | Accuracy: 98.692% \n",
      "[epoch:9, iter:644] Loss: 0.523 | Accuracy: 98.722% \n",
      "[epoch:9, iter:645] Loss: 0.523 | Accuracy: 98.681% \n",
      "[epoch:9, iter:646] Loss: 0.524 | Accuracy: 98.573% \n",
      "[epoch:9, iter:647] Loss: 0.523 | Accuracy: 98.604% \n",
      "[epoch:9, iter:648] Loss: 0.523 | Accuracy: 98.633% \n",
      "[epoch:9, iter:649] Loss: 0.522 | Accuracy: 98.661% \n",
      "[epoch:9, iter:650] Loss: 0.522 | Accuracy: 98.688% \n",
      "[epoch:9, iter:651] Loss: 0.521 | Accuracy: 98.713% \n",
      "[epoch:9, iter:652] Loss: 0.524 | Accuracy: 98.618% \n",
      "[epoch:9, iter:653] Loss: 0.524 | Accuracy: 98.644% \n",
      "[epoch:9, iter:654] Loss: 0.525 | Accuracy: 98.611% \n",
      "[epoch:9, iter:655] Loss: 0.525 | Accuracy: 98.636% \n",
      "[epoch:9, iter:656] Loss: 0.525 | Accuracy: 98.605% \n",
      "[epoch:9, iter:657] Loss: 0.527 | Accuracy: 98.575% \n",
      "[epoch:9, iter:658] Loss: 0.527 | Accuracy: 98.599% \n",
      "[epoch:9, iter:659] Loss: 0.528 | Accuracy: 98.570% \n",
      "[epoch:9, iter:660] Loss: 0.528 | Accuracy: 98.542% \n",
      "[epoch:9, iter:661] Loss: 0.529 | Accuracy: 98.514% \n",
      "[epoch:9, iter:662] Loss: 0.528 | Accuracy: 98.538% \n",
      "[epoch:9, iter:663] Loss: 0.528 | Accuracy: 98.562% \n",
      "[epoch:9, iter:664] Loss: 0.527 | Accuracy: 98.584% \n",
      "[epoch:9, iter:665] Loss: 0.527 | Accuracy: 98.606% \n",
      "[epoch:9, iter:666] Loss: 0.526 | Accuracy: 98.627% \n",
      "[epoch:9, iter:667] Loss: 0.526 | Accuracy: 98.647% \n",
      "[epoch:9, iter:668] Loss: 0.527 | Accuracy: 98.621% \n",
      "[epoch:9, iter:669] Loss: 0.527 | Accuracy: 98.551% \n",
      "[epoch:9, iter:670] Loss: 0.529 | Accuracy: 98.482% \n",
      "[epoch:9, iter:671] Loss: 0.529 | Accuracy: 98.504% \n",
      "[epoch:9, iter:672] Loss: 0.528 | Accuracy: 98.524% \n",
      "[epoch:9, iter:673] Loss: 0.528 | Accuracy: 98.545% \n",
      "[epoch:9, iter:674] Loss: 0.528 | Accuracy: 98.564% \n",
      "[epoch:9, iter:675] Loss: 0.541 | Accuracy: 98.523% \n",
      "Waiting Test!\n",
      "EPOCH=009, Loss: 1.314, Accuracy= 66.118%\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 10\n",
      "[epoch:10, iter:676] Loss: 0.656 | Accuracy: 96.875% \n",
      "[epoch:10, iter:677] Loss: 0.686 | Accuracy: 93.750% \n",
      "[epoch:10, iter:678] Loss: 0.626 | Accuracy: 95.833% \n",
      "[epoch:10, iter:679] Loss: 0.599 | Accuracy: 96.875% \n",
      "[epoch:10, iter:680] Loss: 0.579 | Accuracy: 97.500% \n",
      "[epoch:10, iter:681] Loss: 0.566 | Accuracy: 97.917% \n",
      "[epoch:10, iter:682] Loss: 0.558 | Accuracy: 98.214% \n",
      "[epoch:10, iter:683] Loss: 0.554 | Accuracy: 98.438% \n",
      "[epoch:10, iter:684] Loss: 0.549 | Accuracy: 98.611% \n",
      "[epoch:10, iter:685] Loss: 0.546 | Accuracy: 98.750% \n",
      "[epoch:10, iter:686] Loss: 0.545 | Accuracy: 98.580% \n",
      "[epoch:10, iter:687] Loss: 0.542 | Accuracy: 98.698% \n",
      "[epoch:10, iter:688] Loss: 0.539 | Accuracy: 98.798% \n",
      "[epoch:10, iter:689] Loss: 0.537 | Accuracy: 98.884% \n",
      "[epoch:10, iter:690] Loss: 0.534 | Accuracy: 98.958% \n",
      "[epoch:10, iter:691] Loss: 0.532 | Accuracy: 99.023% \n",
      "[epoch:10, iter:692] Loss: 0.530 | Accuracy: 99.081% \n",
      "[epoch:10, iter:693] Loss: 0.538 | Accuracy: 98.958% \n",
      "[epoch:10, iter:694] Loss: 0.539 | Accuracy: 98.849% \n",
      "[epoch:10, iter:695] Loss: 0.537 | Accuracy: 98.906% \n",
      "[epoch:10, iter:696] Loss: 0.536 | Accuracy: 98.958% \n",
      "[epoch:10, iter:697] Loss: 0.534 | Accuracy: 99.006% \n",
      "[epoch:10, iter:698] Loss: 0.536 | Accuracy: 98.913% \n",
      "[epoch:10, iter:699] Loss: 0.537 | Accuracy: 98.698% \n",
      "[epoch:10, iter:700] Loss: 0.536 | Accuracy: 98.750% \n",
      "[epoch:10, iter:701] Loss: 0.535 | Accuracy: 98.798% \n",
      "[epoch:10, iter:702] Loss: 0.534 | Accuracy: 98.843% \n",
      "[epoch:10, iter:703] Loss: 0.534 | Accuracy: 98.772% \n",
      "[epoch:10, iter:704] Loss: 0.533 | Accuracy: 98.815% \n",
      "[epoch:10, iter:705] Loss: 0.532 | Accuracy: 98.854% \n",
      "[epoch:10, iter:706] Loss: 0.531 | Accuracy: 98.891% \n",
      "[epoch:10, iter:707] Loss: 0.530 | Accuracy: 98.926% \n",
      "[epoch:10, iter:708] Loss: 0.530 | Accuracy: 98.958% \n",
      "[epoch:10, iter:709] Loss: 0.529 | Accuracy: 98.989% \n",
      "[epoch:10, iter:710] Loss: 0.528 | Accuracy: 99.018% \n",
      "[epoch:10, iter:711] Loss: 0.527 | Accuracy: 99.045% \n",
      "[epoch:10, iter:712] Loss: 0.527 | Accuracy: 99.071% \n",
      "[epoch:10, iter:713] Loss: 0.526 | Accuracy: 99.095% \n",
      "[epoch:10, iter:714] Loss: 0.525 | Accuracy: 99.119% \n",
      "[epoch:10, iter:715] Loss: 0.525 | Accuracy: 99.141% \n",
      "[epoch:10, iter:716] Loss: 0.524 | Accuracy: 99.162% \n",
      "[epoch:10, iter:717] Loss: 0.524 | Accuracy: 99.182% \n",
      "[epoch:10, iter:718] Loss: 0.524 | Accuracy: 99.128% \n",
      "[epoch:10, iter:719] Loss: 0.523 | Accuracy: 99.148% \n",
      "[epoch:10, iter:720] Loss: 0.523 | Accuracy: 99.167% \n",
      "[epoch:10, iter:721] Loss: 0.522 | Accuracy: 99.185% \n",
      "[epoch:10, iter:722] Loss: 0.522 | Accuracy: 99.136% \n",
      "[epoch:10, iter:723] Loss: 0.521 | Accuracy: 99.154% \n",
      "[epoch:10, iter:724] Loss: 0.521 | Accuracy: 99.171% \n",
      "[epoch:10, iter:725] Loss: 0.521 | Accuracy: 99.125% \n",
      "[epoch:10, iter:726] Loss: 0.520 | Accuracy: 99.142% \n",
      "[epoch:10, iter:727] Loss: 0.520 | Accuracy: 99.159% \n",
      "[epoch:10, iter:728] Loss: 0.520 | Accuracy: 99.116% \n",
      "[epoch:10, iter:729] Loss: 0.519 | Accuracy: 99.132% \n",
      "[epoch:10, iter:730] Loss: 0.519 | Accuracy: 99.148% \n",
      "[epoch:10, iter:731] Loss: 0.519 | Accuracy: 99.107% \n",
      "[epoch:10, iter:732] Loss: 0.519 | Accuracy: 99.123% \n",
      "[epoch:10, iter:733] Loss: 0.518 | Accuracy: 99.138% \n",
      "[epoch:10, iter:734] Loss: 0.518 | Accuracy: 99.153% \n",
      "[epoch:10, iter:735] Loss: 0.518 | Accuracy: 99.167% \n",
      "[epoch:10, iter:736] Loss: 0.517 | Accuracy: 99.180% \n",
      "[epoch:10, iter:737] Loss: 0.517 | Accuracy: 99.194% \n",
      "[epoch:10, iter:738] Loss: 0.517 | Accuracy: 99.206% \n",
      "[epoch:10, iter:739] Loss: 0.516 | Accuracy: 99.219% \n",
      "[epoch:10, iter:740] Loss: 0.516 | Accuracy: 99.231% \n",
      "[epoch:10, iter:741] Loss: 0.516 | Accuracy: 99.242% \n",
      "[epoch:10, iter:742] Loss: 0.516 | Accuracy: 99.207% \n",
      "[epoch:10, iter:743] Loss: 0.516 | Accuracy: 99.219% \n",
      "[epoch:10, iter:744] Loss: 0.516 | Accuracy: 99.230% \n",
      "[epoch:10, iter:745] Loss: 0.516 | Accuracy: 99.152% \n",
      "[epoch:10, iter:746] Loss: 0.517 | Accuracy: 99.120% \n",
      "[epoch:10, iter:747] Loss: 0.516 | Accuracy: 99.132% \n",
      "[epoch:10, iter:748] Loss: 0.516 | Accuracy: 99.144% \n",
      "[epoch:10, iter:749] Loss: 0.516 | Accuracy: 99.155% \n",
      "[epoch:10, iter:750] Loss: 0.516 | Accuracy: 99.156% \n",
      "Waiting Test!\n",
      "EPOCH=010, Loss: 0.647, Accuracy= 93.092%\n",
      "Training complete in 0m 13s\n",
      "Validation accuracy increased (81.250000 --> 93.092105).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11\n",
      "[epoch:11, iter:751] Loss: 0.498 | Accuracy: 100.000% \n",
      "[epoch:11, iter:752] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:11, iter:753] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:11, iter:754] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:11, iter:755] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:11, iter:756] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:11, iter:757] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:11, iter:758] Loss: 0.497 | Accuracy: 100.000% \n",
      "[epoch:11, iter:759] Loss: 0.497 | Accuracy: 100.000% \n",
      "[epoch:11, iter:760] Loss: 0.500 | Accuracy: 99.688% \n",
      "[epoch:11, iter:761] Loss: 0.499 | Accuracy: 99.716% \n",
      "[epoch:11, iter:762] Loss: 0.500 | Accuracy: 99.740% \n",
      "[epoch:11, iter:763] Loss: 0.504 | Accuracy: 99.519% \n",
      "[epoch:11, iter:764] Loss: 0.503 | Accuracy: 99.554% \n",
      "[epoch:11, iter:765] Loss: 0.507 | Accuracy: 99.375% \n",
      "[epoch:11, iter:766] Loss: 0.507 | Accuracy: 99.414% \n",
      "[epoch:11, iter:767] Loss: 0.506 | Accuracy: 99.449% \n",
      "[epoch:11, iter:768] Loss: 0.506 | Accuracy: 99.479% \n",
      "[epoch:11, iter:769] Loss: 0.505 | Accuracy: 99.507% \n",
      "[epoch:11, iter:770] Loss: 0.504 | Accuracy: 99.531% \n",
      "[epoch:11, iter:771] Loss: 0.504 | Accuracy: 99.554% \n",
      "[epoch:11, iter:772] Loss: 0.503 | Accuracy: 99.574% \n",
      "[epoch:11, iter:773] Loss: 0.503 | Accuracy: 99.592% \n",
      "[epoch:11, iter:774] Loss: 0.503 | Accuracy: 99.609% \n",
      "[epoch:11, iter:775] Loss: 0.503 | Accuracy: 99.625% \n",
      "[epoch:11, iter:776] Loss: 0.503 | Accuracy: 99.639% \n",
      "[epoch:11, iter:777] Loss: 0.502 | Accuracy: 99.653% \n",
      "[epoch:11, iter:778] Loss: 0.502 | Accuracy: 99.665% \n",
      "[epoch:11, iter:779] Loss: 0.502 | Accuracy: 99.677% \n",
      "[epoch:11, iter:780] Loss: 0.502 | Accuracy: 99.688% \n",
      "[epoch:11, iter:781] Loss: 0.501 | Accuracy: 99.698% \n",
      "[epoch:11, iter:782] Loss: 0.501 | Accuracy: 99.707% \n",
      "[epoch:11, iter:783] Loss: 0.501 | Accuracy: 99.716% \n",
      "[epoch:11, iter:784] Loss: 0.501 | Accuracy: 99.724% \n",
      "[epoch:11, iter:785] Loss: 0.500 | Accuracy: 99.732% \n",
      "[epoch:11, iter:786] Loss: 0.500 | Accuracy: 99.740% \n",
      "[epoch:11, iter:787] Loss: 0.500 | Accuracy: 99.747% \n",
      "[epoch:11, iter:788] Loss: 0.500 | Accuracy: 99.753% \n",
      "[epoch:11, iter:789] Loss: 0.500 | Accuracy: 99.679% \n",
      "[epoch:11, iter:790] Loss: 0.500 | Accuracy: 99.688% \n",
      "[epoch:11, iter:791] Loss: 0.502 | Accuracy: 99.619% \n",
      "[epoch:11, iter:792] Loss: 0.503 | Accuracy: 99.554% \n",
      "[epoch:11, iter:793] Loss: 0.502 | Accuracy: 99.564% \n",
      "[epoch:11, iter:794] Loss: 0.502 | Accuracy: 99.574% \n",
      "[epoch:11, iter:795] Loss: 0.502 | Accuracy: 99.583% \n",
      "[epoch:11, iter:796] Loss: 0.502 | Accuracy: 99.592% \n",
      "[epoch:11, iter:797] Loss: 0.502 | Accuracy: 99.601% \n",
      "[epoch:11, iter:798] Loss: 0.502 | Accuracy: 99.609% \n",
      "[epoch:11, iter:799] Loss: 0.502 | Accuracy: 99.617% \n",
      "[epoch:11, iter:800] Loss: 0.502 | Accuracy: 99.625% \n",
      "[epoch:11, iter:801] Loss: 0.502 | Accuracy: 99.632% \n",
      "[epoch:11, iter:802] Loss: 0.502 | Accuracy: 99.639% \n",
      "[epoch:11, iter:803] Loss: 0.503 | Accuracy: 99.587% \n",
      "[epoch:11, iter:804] Loss: 0.503 | Accuracy: 99.595% \n",
      "[epoch:11, iter:805] Loss: 0.503 | Accuracy: 99.602% \n",
      "[epoch:11, iter:806] Loss: 0.503 | Accuracy: 99.609% \n",
      "[epoch:11, iter:807] Loss: 0.503 | Accuracy: 99.616% \n",
      "[epoch:11, iter:808] Loss: 0.503 | Accuracy: 99.623% \n",
      "[epoch:11, iter:809] Loss: 0.503 | Accuracy: 99.629% \n",
      "[epoch:11, iter:810] Loss: 0.502 | Accuracy: 99.635% \n",
      "[epoch:11, iter:811] Loss: 0.502 | Accuracy: 99.641% \n",
      "[epoch:11, iter:812] Loss: 0.502 | Accuracy: 99.647% \n",
      "[epoch:11, iter:813] Loss: 0.502 | Accuracy: 99.653% \n",
      "[epoch:11, iter:814] Loss: 0.502 | Accuracy: 99.609% \n",
      "[epoch:11, iter:815] Loss: 0.502 | Accuracy: 99.615% \n",
      "[epoch:11, iter:816] Loss: 0.502 | Accuracy: 99.621% \n",
      "[epoch:11, iter:817] Loss: 0.502 | Accuracy: 99.627% \n",
      "[epoch:11, iter:818] Loss: 0.502 | Accuracy: 99.632% \n",
      "[epoch:11, iter:819] Loss: 0.502 | Accuracy: 99.638% \n",
      "[epoch:11, iter:820] Loss: 0.502 | Accuracy: 99.643% \n",
      "[epoch:11, iter:821] Loss: 0.502 | Accuracy: 99.648% \n",
      "[epoch:11, iter:822] Loss: 0.502 | Accuracy: 99.653% \n",
      "[epoch:11, iter:823] Loss: 0.502 | Accuracy: 99.658% \n",
      "[epoch:11, iter:824] Loss: 0.501 | Accuracy: 99.662% \n",
      "[epoch:11, iter:825] Loss: 0.501 | Accuracy: 99.662% \n",
      "Waiting Test!\n",
      "EPOCH=011, Loss: 0.663, Accuracy= 93.421%\n",
      "Training complete in 0m 12s\n",
      "Validation accuracy increased (93.092105 --> 93.421053).  Saving model ...\n",
      "\n",
      "Epoch: 12\n",
      "[epoch:12, iter:826] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:12, iter:827] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:12, iter:828] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:12, iter:829] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:12, iter:830] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:12, iter:831] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:12, iter:832] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:12, iter:833] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:12, iter:834] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:12, iter:835] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:12, iter:836] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:12, iter:837] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:12, iter:838] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:12, iter:839] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:12, iter:840] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:12, iter:841] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:12, iter:842] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:12, iter:843] Loss: 0.496 | Accuracy: 99.826% \n",
      "[epoch:12, iter:844] Loss: 0.496 | Accuracy: 99.836% \n",
      "[epoch:12, iter:845] Loss: 0.496 | Accuracy: 99.844% \n",
      "[epoch:12, iter:846] Loss: 0.496 | Accuracy: 99.851% \n",
      "[epoch:12, iter:847] Loss: 0.496 | Accuracy: 99.858% \n",
      "[epoch:12, iter:848] Loss: 0.496 | Accuracy: 99.864% \n",
      "[epoch:12, iter:849] Loss: 0.496 | Accuracy: 99.870% \n",
      "[epoch:12, iter:850] Loss: 0.495 | Accuracy: 99.875% \n",
      "[epoch:12, iter:851] Loss: 0.496 | Accuracy: 99.880% \n",
      "[epoch:12, iter:852] Loss: 0.496 | Accuracy: 99.884% \n",
      "[epoch:12, iter:853] Loss: 0.496 | Accuracy: 99.888% \n",
      "[epoch:12, iter:854] Loss: 0.496 | Accuracy: 99.892% \n",
      "[epoch:12, iter:855] Loss: 0.496 | Accuracy: 99.896% \n",
      "[epoch:12, iter:856] Loss: 0.496 | Accuracy: 99.899% \n",
      "[epoch:12, iter:857] Loss: 0.496 | Accuracy: 99.902% \n",
      "[epoch:12, iter:858] Loss: 0.496 | Accuracy: 99.905% \n",
      "[epoch:12, iter:859] Loss: 0.496 | Accuracy: 99.908% \n",
      "[epoch:12, iter:860] Loss: 0.496 | Accuracy: 99.911% \n",
      "[epoch:12, iter:861] Loss: 0.496 | Accuracy: 99.913% \n",
      "[epoch:12, iter:862] Loss: 0.496 | Accuracy: 99.916% \n",
      "[epoch:12, iter:863] Loss: 0.496 | Accuracy: 99.918% \n",
      "[epoch:12, iter:864] Loss: 0.496 | Accuracy: 99.920% \n",
      "[epoch:12, iter:865] Loss: 0.496 | Accuracy: 99.922% \n",
      "[epoch:12, iter:866] Loss: 0.496 | Accuracy: 99.924% \n",
      "[epoch:12, iter:867] Loss: 0.496 | Accuracy: 99.926% \n",
      "[epoch:12, iter:868] Loss: 0.495 | Accuracy: 99.927% \n",
      "[epoch:12, iter:869] Loss: 0.496 | Accuracy: 99.929% \n",
      "[epoch:12, iter:870] Loss: 0.496 | Accuracy: 99.931% \n",
      "[epoch:12, iter:871] Loss: 0.496 | Accuracy: 99.932% \n",
      "[epoch:12, iter:872] Loss: 0.497 | Accuracy: 99.867% \n",
      "[epoch:12, iter:873] Loss: 0.497 | Accuracy: 99.805% \n",
      "[epoch:12, iter:874] Loss: 0.497 | Accuracy: 99.809% \n",
      "[epoch:12, iter:875] Loss: 0.497 | Accuracy: 99.812% \n",
      "[epoch:12, iter:876] Loss: 0.497 | Accuracy: 99.816% \n",
      "[epoch:12, iter:877] Loss: 0.497 | Accuracy: 99.820% \n",
      "[epoch:12, iter:878] Loss: 0.497 | Accuracy: 99.823% \n",
      "[epoch:12, iter:879] Loss: 0.497 | Accuracy: 99.826% \n",
      "[epoch:12, iter:880] Loss: 0.497 | Accuracy: 99.830% \n",
      "[epoch:12, iter:881] Loss: 0.497 | Accuracy: 99.833% \n",
      "[epoch:12, iter:882] Loss: 0.497 | Accuracy: 99.836% \n",
      "[epoch:12, iter:883] Loss: 0.497 | Accuracy: 99.784% \n",
      "[epoch:12, iter:884] Loss: 0.497 | Accuracy: 99.788% \n",
      "[epoch:12, iter:885] Loss: 0.498 | Accuracy: 99.740% \n",
      "[epoch:12, iter:886] Loss: 0.498 | Accuracy: 99.744% \n",
      "[epoch:12, iter:887] Loss: 0.498 | Accuracy: 99.748% \n",
      "[epoch:12, iter:888] Loss: 0.498 | Accuracy: 99.752% \n",
      "[epoch:12, iter:889] Loss: 0.498 | Accuracy: 99.756% \n",
      "[epoch:12, iter:890] Loss: 0.498 | Accuracy: 99.760% \n",
      "[epoch:12, iter:891] Loss: 0.499 | Accuracy: 99.716% \n",
      "[epoch:12, iter:892] Loss: 0.499 | Accuracy: 99.720% \n",
      "[epoch:12, iter:893] Loss: 0.498 | Accuracy: 99.724% \n",
      "[epoch:12, iter:894] Loss: 0.498 | Accuracy: 99.728% \n",
      "[epoch:12, iter:895] Loss: 0.498 | Accuracy: 99.732% \n",
      "[epoch:12, iter:896] Loss: 0.498 | Accuracy: 99.736% \n",
      "[epoch:12, iter:897] Loss: 0.499 | Accuracy: 99.696% \n",
      "[epoch:12, iter:898] Loss: 0.499 | Accuracy: 99.700% \n",
      "[epoch:12, iter:899] Loss: 0.499 | Accuracy: 99.704% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:12, iter:900] Loss: 0.515 | Accuracy: 99.662% \n",
      "Waiting Test!\n",
      "EPOCH=012, Loss: 1.041, Accuracy= 77.303%\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 13\n",
      "[epoch:13, iter:901] Loss: 0.659 | Accuracy: 96.875% \n",
      "[epoch:13, iter:902] Loss: 0.588 | Accuracy: 98.438% \n",
      "[epoch:13, iter:903] Loss: 0.565 | Accuracy: 98.958% \n",
      "[epoch:13, iter:904] Loss: 0.553 | Accuracy: 99.219% \n",
      "[epoch:13, iter:905] Loss: 0.542 | Accuracy: 99.375% \n",
      "[epoch:13, iter:906] Loss: 0.535 | Accuracy: 99.479% \n",
      "[epoch:13, iter:907] Loss: 0.530 | Accuracy: 99.554% \n",
      "[epoch:13, iter:908] Loss: 0.526 | Accuracy: 99.609% \n",
      "[epoch:13, iter:909] Loss: 0.523 | Accuracy: 99.653% \n",
      "[epoch:13, iter:910] Loss: 0.521 | Accuracy: 99.688% \n",
      "[epoch:13, iter:911] Loss: 0.519 | Accuracy: 99.716% \n",
      "[epoch:13, iter:912] Loss: 0.518 | Accuracy: 99.740% \n",
      "[epoch:13, iter:913] Loss: 0.517 | Accuracy: 99.760% \n",
      "[epoch:13, iter:914] Loss: 0.515 | Accuracy: 99.777% \n",
      "[epoch:13, iter:915] Loss: 0.514 | Accuracy: 99.792% \n",
      "[epoch:13, iter:916] Loss: 0.513 | Accuracy: 99.805% \n",
      "[epoch:13, iter:917] Loss: 0.512 | Accuracy: 99.816% \n",
      "[epoch:13, iter:918] Loss: 0.511 | Accuracy: 99.826% \n",
      "[epoch:13, iter:919] Loss: 0.510 | Accuracy: 99.836% \n",
      "[epoch:13, iter:920] Loss: 0.509 | Accuracy: 99.844% \n",
      "[epoch:13, iter:921] Loss: 0.509 | Accuracy: 99.851% \n",
      "[epoch:13, iter:922] Loss: 0.508 | Accuracy: 99.858% \n",
      "[epoch:13, iter:923] Loss: 0.508 | Accuracy: 99.864% \n",
      "[epoch:13, iter:924] Loss: 0.511 | Accuracy: 99.740% \n",
      "[epoch:13, iter:925] Loss: 0.511 | Accuracy: 99.750% \n",
      "[epoch:13, iter:926] Loss: 0.511 | Accuracy: 99.760% \n",
      "[epoch:13, iter:927] Loss: 0.511 | Accuracy: 99.653% \n",
      "[epoch:13, iter:928] Loss: 0.510 | Accuracy: 99.665% \n",
      "[epoch:13, iter:929] Loss: 0.510 | Accuracy: 99.677% \n",
      "[epoch:13, iter:930] Loss: 0.509 | Accuracy: 99.688% \n",
      "[epoch:13, iter:931] Loss: 0.509 | Accuracy: 99.698% \n",
      "[epoch:13, iter:932] Loss: 0.508 | Accuracy: 99.707% \n",
      "[epoch:13, iter:933] Loss: 0.508 | Accuracy: 99.716% \n",
      "[epoch:13, iter:934] Loss: 0.508 | Accuracy: 99.724% \n",
      "[epoch:13, iter:935] Loss: 0.507 | Accuracy: 99.732% \n",
      "[epoch:13, iter:936] Loss: 0.507 | Accuracy: 99.740% \n",
      "[epoch:13, iter:937] Loss: 0.507 | Accuracy: 99.747% \n",
      "[epoch:13, iter:938] Loss: 0.507 | Accuracy: 99.753% \n",
      "[epoch:13, iter:939] Loss: 0.506 | Accuracy: 99.760% \n",
      "[epoch:13, iter:940] Loss: 0.506 | Accuracy: 99.766% \n",
      "[epoch:13, iter:941] Loss: 0.505 | Accuracy: 99.771% \n",
      "[epoch:13, iter:942] Loss: 0.505 | Accuracy: 99.777% \n",
      "[epoch:13, iter:943] Loss: 0.505 | Accuracy: 99.782% \n",
      "[epoch:13, iter:944] Loss: 0.505 | Accuracy: 99.787% \n",
      "[epoch:13, iter:945] Loss: 0.504 | Accuracy: 99.792% \n",
      "[epoch:13, iter:946] Loss: 0.504 | Accuracy: 99.796% \n",
      "[epoch:13, iter:947] Loss: 0.504 | Accuracy: 99.801% \n",
      "[epoch:13, iter:948] Loss: 0.504 | Accuracy: 99.805% \n",
      "[epoch:13, iter:949] Loss: 0.504 | Accuracy: 99.809% \n",
      "[epoch:13, iter:950] Loss: 0.504 | Accuracy: 99.812% \n",
      "[epoch:13, iter:951] Loss: 0.503 | Accuracy: 99.816% \n",
      "[epoch:13, iter:952] Loss: 0.503 | Accuracy: 99.820% \n",
      "[epoch:13, iter:953] Loss: 0.503 | Accuracy: 99.823% \n",
      "[epoch:13, iter:954] Loss: 0.503 | Accuracy: 99.826% \n",
      "[epoch:13, iter:955] Loss: 0.502 | Accuracy: 99.830% \n",
      "[epoch:13, iter:956] Loss: 0.502 | Accuracy: 99.833% \n",
      "[epoch:13, iter:957] Loss: 0.502 | Accuracy: 99.836% \n",
      "[epoch:13, iter:958] Loss: 0.502 | Accuracy: 99.838% \n",
      "[epoch:13, iter:959] Loss: 0.502 | Accuracy: 99.841% \n",
      "[epoch:13, iter:960] Loss: 0.502 | Accuracy: 99.844% \n",
      "[epoch:13, iter:961] Loss: 0.501 | Accuracy: 99.846% \n",
      "[epoch:13, iter:962] Loss: 0.501 | Accuracy: 99.849% \n",
      "[epoch:13, iter:963] Loss: 0.501 | Accuracy: 99.851% \n",
      "[epoch:13, iter:964] Loss: 0.501 | Accuracy: 99.854% \n",
      "[epoch:13, iter:965] Loss: 0.502 | Accuracy: 99.808% \n",
      "[epoch:13, iter:966] Loss: 0.503 | Accuracy: 99.763% \n",
      "[epoch:13, iter:967] Loss: 0.503 | Accuracy: 99.767% \n",
      "[epoch:13, iter:968] Loss: 0.503 | Accuracy: 99.770% \n",
      "[epoch:13, iter:969] Loss: 0.502 | Accuracy: 99.774% \n",
      "[epoch:13, iter:970] Loss: 0.502 | Accuracy: 99.777% \n",
      "[epoch:13, iter:971] Loss: 0.502 | Accuracy: 99.780% \n",
      "[epoch:13, iter:972] Loss: 0.504 | Accuracy: 99.696% \n",
      "[epoch:13, iter:973] Loss: 0.504 | Accuracy: 99.700% \n",
      "[epoch:13, iter:974] Loss: 0.503 | Accuracy: 99.704% \n",
      "[epoch:13, iter:975] Loss: 0.504 | Accuracy: 99.705% \n",
      "Waiting Test!\n",
      "EPOCH=013, Loss: 0.723, Accuracy= 90.789%\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "\n",
      "Epoch: 14\n",
      "[epoch:14, iter:976] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:14, iter:977] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:14, iter:978] Loss: 0.500 | Accuracy: 100.000% \n",
      "[epoch:14, iter:979] Loss: 0.497 | Accuracy: 100.000% \n",
      "[epoch:14, iter:980] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:14, iter:981] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:14, iter:982] Loss: 0.509 | Accuracy: 99.554% \n",
      "[epoch:14, iter:983] Loss: 0.508 | Accuracy: 99.609% \n",
      "[epoch:14, iter:984] Loss: 0.506 | Accuracy: 99.653% \n",
      "[epoch:14, iter:985] Loss: 0.505 | Accuracy: 99.688% \n",
      "[epoch:14, iter:986] Loss: 0.504 | Accuracy: 99.716% \n",
      "[epoch:14, iter:987] Loss: 0.504 | Accuracy: 99.740% \n",
      "[epoch:14, iter:988] Loss: 0.503 | Accuracy: 99.760% \n",
      "[epoch:14, iter:989] Loss: 0.502 | Accuracy: 99.777% \n",
      "[epoch:14, iter:990] Loss: 0.501 | Accuracy: 99.792% \n",
      "[epoch:14, iter:991] Loss: 0.500 | Accuracy: 99.805% \n",
      "[epoch:14, iter:992] Loss: 0.500 | Accuracy: 99.816% \n",
      "[epoch:14, iter:993] Loss: 0.500 | Accuracy: 99.826% \n",
      "[epoch:14, iter:994] Loss: 0.499 | Accuracy: 99.836% \n",
      "[epoch:14, iter:995] Loss: 0.499 | Accuracy: 99.844% \n",
      "[epoch:14, iter:996] Loss: 0.498 | Accuracy: 99.851% \n",
      "[epoch:14, iter:997] Loss: 0.498 | Accuracy: 99.858% \n",
      "[epoch:14, iter:998] Loss: 0.500 | Accuracy: 99.728% \n",
      "[epoch:14, iter:999] Loss: 0.499 | Accuracy: 99.740% \n",
      "[epoch:14, iter:1000] Loss: 0.499 | Accuracy: 99.750% \n",
      "[epoch:14, iter:1001] Loss: 0.500 | Accuracy: 99.760% \n",
      "[epoch:14, iter:1002] Loss: 0.500 | Accuracy: 99.769% \n",
      "[epoch:14, iter:1003] Loss: 0.500 | Accuracy: 99.777% \n",
      "[epoch:14, iter:1004] Loss: 0.500 | Accuracy: 99.784% \n",
      "[epoch:14, iter:1005] Loss: 0.500 | Accuracy: 99.792% \n",
      "[epoch:14, iter:1006] Loss: 0.500 | Accuracy: 99.798% \n",
      "[epoch:14, iter:1007] Loss: 0.499 | Accuracy: 99.805% \n",
      "[epoch:14, iter:1008] Loss: 0.499 | Accuracy: 99.811% \n",
      "[epoch:14, iter:1009] Loss: 0.499 | Accuracy: 99.816% \n",
      "[epoch:14, iter:1010] Loss: 0.499 | Accuracy: 99.821% \n",
      "[epoch:14, iter:1011] Loss: 0.499 | Accuracy: 99.826% \n",
      "[epoch:14, iter:1012] Loss: 0.499 | Accuracy: 99.831% \n",
      "[epoch:14, iter:1013] Loss: 0.499 | Accuracy: 99.836% \n",
      "[epoch:14, iter:1014] Loss: 0.498 | Accuracy: 99.840% \n",
      "[epoch:14, iter:1015] Loss: 0.498 | Accuracy: 99.844% \n",
      "[epoch:14, iter:1016] Loss: 0.498 | Accuracy: 99.848% \n",
      "[epoch:14, iter:1017] Loss: 0.498 | Accuracy: 99.851% \n",
      "[epoch:14, iter:1018] Loss: 0.498 | Accuracy: 99.855% \n",
      "[epoch:14, iter:1019] Loss: 0.498 | Accuracy: 99.787% \n",
      "[epoch:14, iter:1020] Loss: 0.499 | Accuracy: 99.722% \n",
      "[epoch:14, iter:1021] Loss: 0.500 | Accuracy: 99.660% \n",
      "[epoch:14, iter:1022] Loss: 0.501 | Accuracy: 99.601% \n",
      "[epoch:14, iter:1023] Loss: 0.501 | Accuracy: 99.609% \n",
      "[epoch:14, iter:1024] Loss: 0.500 | Accuracy: 99.617% \n",
      "[epoch:14, iter:1025] Loss: 0.501 | Accuracy: 99.562% \n",
      "[epoch:14, iter:1026] Loss: 0.501 | Accuracy: 99.571% \n",
      "[epoch:14, iter:1027] Loss: 0.501 | Accuracy: 99.579% \n",
      "[epoch:14, iter:1028] Loss: 0.501 | Accuracy: 99.587% \n",
      "[epoch:14, iter:1029] Loss: 0.502 | Accuracy: 99.595% \n",
      "[epoch:14, iter:1030] Loss: 0.502 | Accuracy: 99.545% \n",
      "[epoch:14, iter:1031] Loss: 0.502 | Accuracy: 99.554% \n",
      "[epoch:14, iter:1032] Loss: 0.501 | Accuracy: 99.561% \n",
      "[epoch:14, iter:1033] Loss: 0.501 | Accuracy: 99.569% \n",
      "[epoch:14, iter:1034] Loss: 0.501 | Accuracy: 99.576% \n",
      "[epoch:14, iter:1035] Loss: 0.501 | Accuracy: 99.583% \n",
      "[epoch:14, iter:1036] Loss: 0.501 | Accuracy: 99.590% \n",
      "[epoch:14, iter:1037] Loss: 0.501 | Accuracy: 99.597% \n",
      "[epoch:14, iter:1038] Loss: 0.501 | Accuracy: 99.554% \n",
      "[epoch:14, iter:1039] Loss: 0.501 | Accuracy: 99.561% \n",
      "[epoch:14, iter:1040] Loss: 0.501 | Accuracy: 99.567% \n",
      "[epoch:14, iter:1041] Loss: 0.501 | Accuracy: 99.574% \n",
      "[epoch:14, iter:1042] Loss: 0.501 | Accuracy: 99.580% \n",
      "[epoch:14, iter:1043] Loss: 0.501 | Accuracy: 99.586% \n",
      "[epoch:14, iter:1044] Loss: 0.501 | Accuracy: 99.592% \n",
      "[epoch:14, iter:1045] Loss: 0.500 | Accuracy: 99.598% \n",
      "[epoch:14, iter:1046] Loss: 0.500 | Accuracy: 99.604% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:14, iter:1047] Loss: 0.500 | Accuracy: 99.609% \n",
      "[epoch:14, iter:1048] Loss: 0.500 | Accuracy: 99.572% \n",
      "[epoch:14, iter:1049] Loss: 0.500 | Accuracy: 99.578% \n",
      "[epoch:14, iter:1050] Loss: 0.500 | Accuracy: 99.578% \n",
      "Waiting Test!\n",
      "EPOCH=014, Loss: 0.665, Accuracy= 94.408%\n",
      "Training complete in 0m 14s\n",
      "Validation accuracy increased (93.421053 --> 94.407895).  Saving model ...\n",
      "\n",
      "Epoch: 15\n",
      "[epoch:15, iter:1051] Loss: 0.524 | Accuracy: 96.875% \n",
      "[epoch:15, iter:1052] Loss: 0.511 | Accuracy: 98.438% \n",
      "[epoch:15, iter:1053] Loss: 0.506 | Accuracy: 98.958% \n",
      "[epoch:15, iter:1054] Loss: 0.516 | Accuracy: 98.438% \n",
      "[epoch:15, iter:1055] Loss: 0.514 | Accuracy: 98.750% \n",
      "[epoch:15, iter:1056] Loss: 0.510 | Accuracy: 98.958% \n",
      "[epoch:15, iter:1057] Loss: 0.507 | Accuracy: 99.107% \n",
      "[epoch:15, iter:1058] Loss: 0.506 | Accuracy: 99.219% \n",
      "[epoch:15, iter:1059] Loss: 0.504 | Accuracy: 99.306% \n",
      "[epoch:15, iter:1060] Loss: 0.503 | Accuracy: 99.375% \n",
      "[epoch:15, iter:1061] Loss: 0.502 | Accuracy: 99.432% \n",
      "[epoch:15, iter:1062] Loss: 0.501 | Accuracy: 99.479% \n",
      "[epoch:15, iter:1063] Loss: 0.500 | Accuracy: 99.519% \n",
      "[epoch:15, iter:1064] Loss: 0.500 | Accuracy: 99.554% \n",
      "[epoch:15, iter:1065] Loss: 0.505 | Accuracy: 99.375% \n",
      "[epoch:15, iter:1066] Loss: 0.505 | Accuracy: 99.414% \n",
      "[epoch:15, iter:1067] Loss: 0.504 | Accuracy: 99.449% \n",
      "[epoch:15, iter:1068] Loss: 0.503 | Accuracy: 99.479% \n",
      "[epoch:15, iter:1069] Loss: 0.503 | Accuracy: 99.507% \n",
      "[epoch:15, iter:1070] Loss: 0.504 | Accuracy: 99.375% \n",
      "[epoch:15, iter:1071] Loss: 0.503 | Accuracy: 99.405% \n",
      "[epoch:15, iter:1072] Loss: 0.502 | Accuracy: 99.432% \n",
      "[epoch:15, iter:1073] Loss: 0.502 | Accuracy: 99.457% \n",
      "[epoch:15, iter:1074] Loss: 0.501 | Accuracy: 99.479% \n",
      "[epoch:15, iter:1075] Loss: 0.501 | Accuracy: 99.500% \n",
      "[epoch:15, iter:1076] Loss: 0.501 | Accuracy: 99.519% \n",
      "[epoch:15, iter:1077] Loss: 0.501 | Accuracy: 99.537% \n",
      "[epoch:15, iter:1078] Loss: 0.501 | Accuracy: 99.554% \n",
      "[epoch:15, iter:1079] Loss: 0.501 | Accuracy: 99.569% \n",
      "[epoch:15, iter:1080] Loss: 0.500 | Accuracy: 99.583% \n",
      "[epoch:15, iter:1081] Loss: 0.500 | Accuracy: 99.597% \n",
      "[epoch:15, iter:1082] Loss: 0.500 | Accuracy: 99.609% \n",
      "[epoch:15, iter:1083] Loss: 0.499 | Accuracy: 99.621% \n",
      "[epoch:15, iter:1084] Loss: 0.499 | Accuracy: 99.632% \n",
      "[epoch:15, iter:1085] Loss: 0.499 | Accuracy: 99.643% \n",
      "[epoch:15, iter:1086] Loss: 0.499 | Accuracy: 99.653% \n",
      "[epoch:15, iter:1087] Loss: 0.499 | Accuracy: 99.662% \n",
      "[epoch:15, iter:1088] Loss: 0.498 | Accuracy: 99.671% \n",
      "[epoch:15, iter:1089] Loss: 0.498 | Accuracy: 99.679% \n",
      "[epoch:15, iter:1090] Loss: 0.498 | Accuracy: 99.688% \n",
      "[epoch:15, iter:1091] Loss: 0.498 | Accuracy: 99.695% \n",
      "[epoch:15, iter:1092] Loss: 0.498 | Accuracy: 99.702% \n",
      "[epoch:15, iter:1093] Loss: 0.498 | Accuracy: 99.709% \n",
      "[epoch:15, iter:1094] Loss: 0.498 | Accuracy: 99.716% \n",
      "[epoch:15, iter:1095] Loss: 0.497 | Accuracy: 99.722% \n",
      "[epoch:15, iter:1096] Loss: 0.497 | Accuracy: 99.728% \n",
      "[epoch:15, iter:1097] Loss: 0.497 | Accuracy: 99.734% \n",
      "[epoch:15, iter:1098] Loss: 0.497 | Accuracy: 99.740% \n",
      "[epoch:15, iter:1099] Loss: 0.497 | Accuracy: 99.745% \n",
      "[epoch:15, iter:1100] Loss: 0.498 | Accuracy: 99.688% \n",
      "[epoch:15, iter:1101] Loss: 0.498 | Accuracy: 99.694% \n",
      "[epoch:15, iter:1102] Loss: 0.498 | Accuracy: 99.700% \n",
      "[epoch:15, iter:1103] Loss: 0.498 | Accuracy: 99.705% \n",
      "[epoch:15, iter:1104] Loss: 0.497 | Accuracy: 99.711% \n",
      "[epoch:15, iter:1105] Loss: 0.497 | Accuracy: 99.716% \n",
      "[epoch:15, iter:1106] Loss: 0.500 | Accuracy: 99.665% \n",
      "[epoch:15, iter:1107] Loss: 0.500 | Accuracy: 99.671% \n",
      "[epoch:15, iter:1108] Loss: 0.500 | Accuracy: 99.677% \n",
      "[epoch:15, iter:1109] Loss: 0.500 | Accuracy: 99.682% \n",
      "[epoch:15, iter:1110] Loss: 0.501 | Accuracy: 99.635% \n",
      "[epoch:15, iter:1111] Loss: 0.501 | Accuracy: 99.641% \n",
      "[epoch:15, iter:1112] Loss: 0.501 | Accuracy: 99.647% \n",
      "[epoch:15, iter:1113] Loss: 0.501 | Accuracy: 99.603% \n",
      "[epoch:15, iter:1114] Loss: 0.501 | Accuracy: 99.609% \n",
      "[epoch:15, iter:1115] Loss: 0.501 | Accuracy: 99.615% \n",
      "[epoch:15, iter:1116] Loss: 0.502 | Accuracy: 99.574% \n",
      "[epoch:15, iter:1117] Loss: 0.502 | Accuracy: 99.534% \n",
      "[epoch:15, iter:1118] Loss: 0.502 | Accuracy: 99.540% \n",
      "[epoch:15, iter:1119] Loss: 0.502 | Accuracy: 99.547% \n",
      "[epoch:15, iter:1120] Loss: 0.502 | Accuracy: 99.554% \n",
      "[epoch:15, iter:1121] Loss: 0.502 | Accuracy: 99.560% \n",
      "[epoch:15, iter:1122] Loss: 0.502 | Accuracy: 99.523% \n",
      "[epoch:15, iter:1123] Loss: 0.502 | Accuracy: 99.529% \n",
      "[epoch:15, iter:1124] Loss: 0.503 | Accuracy: 99.493% \n",
      "[epoch:15, iter:1125] Loss: 0.507 | Accuracy: 99.493% \n",
      "Waiting Test!\n",
      "EPOCH=015, Loss: 0.835, Accuracy= 92.105%\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 16\n",
      "[epoch:16, iter:1126] Loss: 0.540 | Accuracy: 100.000% \n",
      "[epoch:16, iter:1127] Loss: 0.520 | Accuracy: 100.000% \n",
      "[epoch:16, iter:1128] Loss: 0.517 | Accuracy: 100.000% \n",
      "[epoch:16, iter:1129] Loss: 0.512 | Accuracy: 100.000% \n",
      "[epoch:16, iter:1130] Loss: 0.508 | Accuracy: 100.000% \n",
      "[epoch:16, iter:1131] Loss: 0.510 | Accuracy: 99.479% \n",
      "[epoch:16, iter:1132] Loss: 0.517 | Accuracy: 99.107% \n",
      "[epoch:16, iter:1133] Loss: 0.516 | Accuracy: 99.219% \n",
      "[epoch:16, iter:1134] Loss: 0.514 | Accuracy: 99.306% \n",
      "[epoch:16, iter:1135] Loss: 0.513 | Accuracy: 99.375% \n",
      "[epoch:16, iter:1136] Loss: 0.512 | Accuracy: 99.432% \n",
      "[epoch:16, iter:1137] Loss: 0.511 | Accuracy: 99.479% \n",
      "[epoch:16, iter:1138] Loss: 0.510 | Accuracy: 99.519% \n",
      "[epoch:16, iter:1139] Loss: 0.508 | Accuracy: 99.554% \n",
      "[epoch:16, iter:1140] Loss: 0.508 | Accuracy: 99.583% \n",
      "[epoch:16, iter:1141] Loss: 0.508 | Accuracy: 99.609% \n",
      "[epoch:16, iter:1142] Loss: 0.510 | Accuracy: 99.449% \n",
      "[epoch:16, iter:1143] Loss: 0.509 | Accuracy: 99.479% \n",
      "[epoch:16, iter:1144] Loss: 0.508 | Accuracy: 99.507% \n",
      "[epoch:16, iter:1145] Loss: 0.508 | Accuracy: 99.531% \n",
      "[epoch:16, iter:1146] Loss: 0.507 | Accuracy: 99.554% \n",
      "[epoch:16, iter:1147] Loss: 0.507 | Accuracy: 99.574% \n",
      "[epoch:16, iter:1148] Loss: 0.507 | Accuracy: 99.592% \n",
      "[epoch:16, iter:1149] Loss: 0.506 | Accuracy: 99.609% \n",
      "[epoch:16, iter:1150] Loss: 0.506 | Accuracy: 99.625% \n",
      "[epoch:16, iter:1151] Loss: 0.505 | Accuracy: 99.639% \n",
      "[epoch:16, iter:1152] Loss: 0.505 | Accuracy: 99.653% \n",
      "[epoch:16, iter:1153] Loss: 0.505 | Accuracy: 99.665% \n",
      "[epoch:16, iter:1154] Loss: 0.504 | Accuracy: 99.677% \n",
      "[epoch:16, iter:1155] Loss: 0.508 | Accuracy: 99.583% \n",
      "[epoch:16, iter:1156] Loss: 0.508 | Accuracy: 99.597% \n",
      "[epoch:16, iter:1157] Loss: 0.507 | Accuracy: 99.609% \n",
      "[epoch:16, iter:1158] Loss: 0.507 | Accuracy: 99.621% \n",
      "[epoch:16, iter:1159] Loss: 0.507 | Accuracy: 99.632% \n",
      "[epoch:16, iter:1160] Loss: 0.507 | Accuracy: 99.643% \n",
      "[epoch:16, iter:1161] Loss: 0.508 | Accuracy: 99.566% \n",
      "[epoch:16, iter:1162] Loss: 0.510 | Accuracy: 99.493% \n",
      "[epoch:16, iter:1163] Loss: 0.509 | Accuracy: 99.507% \n",
      "[epoch:16, iter:1164] Loss: 0.509 | Accuracy: 99.519% \n",
      "[epoch:16, iter:1165] Loss: 0.509 | Accuracy: 99.531% \n",
      "[epoch:16, iter:1166] Loss: 0.509 | Accuracy: 99.466% \n",
      "[epoch:16, iter:1167] Loss: 0.510 | Accuracy: 99.405% \n",
      "[epoch:16, iter:1168] Loss: 0.510 | Accuracy: 99.419% \n",
      "[epoch:16, iter:1169] Loss: 0.511 | Accuracy: 99.361% \n",
      "[epoch:16, iter:1170] Loss: 0.511 | Accuracy: 99.375% \n",
      "[epoch:16, iter:1171] Loss: 0.511 | Accuracy: 99.321% \n",
      "[epoch:16, iter:1172] Loss: 0.511 | Accuracy: 99.335% \n",
      "[epoch:16, iter:1173] Loss: 0.511 | Accuracy: 99.284% \n",
      "[epoch:16, iter:1174] Loss: 0.511 | Accuracy: 99.298% \n",
      "[epoch:16, iter:1175] Loss: 0.510 | Accuracy: 99.312% \n",
      "[epoch:16, iter:1176] Loss: 0.510 | Accuracy: 99.326% \n",
      "[epoch:16, iter:1177] Loss: 0.511 | Accuracy: 99.279% \n",
      "[epoch:16, iter:1178] Loss: 0.511 | Accuracy: 99.233% \n",
      "[epoch:16, iter:1179] Loss: 0.511 | Accuracy: 99.248% \n",
      "[epoch:16, iter:1180] Loss: 0.511 | Accuracy: 99.205% \n",
      "[epoch:16, iter:1181] Loss: 0.511 | Accuracy: 99.219% \n",
      "[epoch:16, iter:1182] Loss: 0.510 | Accuracy: 99.232% \n",
      "[epoch:16, iter:1183] Loss: 0.511 | Accuracy: 99.192% \n",
      "[epoch:16, iter:1184] Loss: 0.511 | Accuracy: 99.206% \n",
      "[epoch:16, iter:1185] Loss: 0.511 | Accuracy: 99.219% \n",
      "[epoch:16, iter:1186] Loss: 0.511 | Accuracy: 99.232% \n",
      "[epoch:16, iter:1187] Loss: 0.511 | Accuracy: 99.244% \n",
      "[epoch:16, iter:1188] Loss: 0.511 | Accuracy: 99.206% \n",
      "[epoch:16, iter:1189] Loss: 0.511 | Accuracy: 99.219% \n",
      "[epoch:16, iter:1190] Loss: 0.511 | Accuracy: 99.183% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:16, iter:1191] Loss: 0.511 | Accuracy: 99.195% \n",
      "[epoch:16, iter:1192] Loss: 0.511 | Accuracy: 99.207% \n",
      "[epoch:16, iter:1193] Loss: 0.510 | Accuracy: 99.219% \n",
      "[epoch:16, iter:1194] Loss: 0.511 | Accuracy: 99.185% \n",
      "[epoch:16, iter:1195] Loss: 0.511 | Accuracy: 99.196% \n",
      "[epoch:16, iter:1196] Loss: 0.511 | Accuracy: 99.164% \n",
      "[epoch:16, iter:1197] Loss: 0.511 | Accuracy: 99.175% \n",
      "[epoch:16, iter:1198] Loss: 0.511 | Accuracy: 99.187% \n",
      "[epoch:16, iter:1199] Loss: 0.511 | Accuracy: 99.155% \n",
      "[epoch:16, iter:1200] Loss: 0.527 | Accuracy: 99.114% \n",
      "Waiting Test!\n",
      "EPOCH=016, Loss: 0.882, Accuracy= 88.487%\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "\n",
      "Epoch: 17\n",
      "[epoch:17, iter:1201] Loss: 0.647 | Accuracy: 93.750% \n",
      "[epoch:17, iter:1202] Loss: 0.591 | Accuracy: 96.875% \n",
      "[epoch:17, iter:1203] Loss: 0.573 | Accuracy: 96.875% \n",
      "[epoch:17, iter:1204] Loss: 0.573 | Accuracy: 96.875% \n",
      "[epoch:17, iter:1205] Loss: 0.588 | Accuracy: 96.250% \n",
      "[epoch:17, iter:1206] Loss: 0.610 | Accuracy: 95.833% \n",
      "[epoch:17, iter:1207] Loss: 0.609 | Accuracy: 95.982% \n",
      "[epoch:17, iter:1208] Loss: 0.598 | Accuracy: 96.484% \n",
      "[epoch:17, iter:1209] Loss: 0.588 | Accuracy: 96.875% \n",
      "[epoch:17, iter:1210] Loss: 0.587 | Accuracy: 96.875% \n",
      "[epoch:17, iter:1211] Loss: 0.579 | Accuracy: 97.159% \n",
      "[epoch:17, iter:1212] Loss: 0.576 | Accuracy: 97.135% \n",
      "[epoch:17, iter:1213] Loss: 0.571 | Accuracy: 97.356% \n",
      "[epoch:17, iter:1214] Loss: 0.566 | Accuracy: 97.545% \n",
      "[epoch:17, iter:1215] Loss: 0.562 | Accuracy: 97.708% \n",
      "[epoch:17, iter:1216] Loss: 0.559 | Accuracy: 97.852% \n",
      "[epoch:17, iter:1217] Loss: 0.556 | Accuracy: 97.794% \n",
      "[epoch:17, iter:1218] Loss: 0.553 | Accuracy: 97.917% \n",
      "[epoch:17, iter:1219] Loss: 0.560 | Accuracy: 97.533% \n",
      "[epoch:17, iter:1220] Loss: 0.558 | Accuracy: 97.656% \n",
      "[epoch:17, iter:1221] Loss: 0.555 | Accuracy: 97.768% \n",
      "[epoch:17, iter:1222] Loss: 0.552 | Accuracy: 97.869% \n",
      "[epoch:17, iter:1223] Loss: 0.550 | Accuracy: 97.962% \n",
      "[epoch:17, iter:1224] Loss: 0.554 | Accuracy: 97.917% \n",
      "[epoch:17, iter:1225] Loss: 0.553 | Accuracy: 98.000% \n",
      "[epoch:17, iter:1226] Loss: 0.551 | Accuracy: 98.077% \n",
      "[epoch:17, iter:1227] Loss: 0.550 | Accuracy: 98.032% \n",
      "[epoch:17, iter:1228] Loss: 0.550 | Accuracy: 97.991% \n",
      "[epoch:17, iter:1229] Loss: 0.549 | Accuracy: 98.060% \n",
      "[epoch:17, iter:1230] Loss: 0.547 | Accuracy: 98.125% \n",
      "[epoch:17, iter:1231] Loss: 0.546 | Accuracy: 98.185% \n",
      "[epoch:17, iter:1232] Loss: 0.547 | Accuracy: 98.145% \n",
      "[epoch:17, iter:1233] Loss: 0.545 | Accuracy: 98.201% \n",
      "[epoch:17, iter:1234] Loss: 0.544 | Accuracy: 98.254% \n",
      "[epoch:17, iter:1235] Loss: 0.543 | Accuracy: 98.304% \n",
      "[epoch:17, iter:1236] Loss: 0.541 | Accuracy: 98.351% \n",
      "[epoch:17, iter:1237] Loss: 0.541 | Accuracy: 98.311% \n",
      "[epoch:17, iter:1238] Loss: 0.542 | Accuracy: 98.273% \n",
      "[epoch:17, iter:1239] Loss: 0.541 | Accuracy: 98.317% \n",
      "[epoch:17, iter:1240] Loss: 0.540 | Accuracy: 98.359% \n",
      "[epoch:17, iter:1241] Loss: 0.539 | Accuracy: 98.399% \n",
      "[epoch:17, iter:1242] Loss: 0.538 | Accuracy: 98.438% \n",
      "[epoch:17, iter:1243] Loss: 0.537 | Accuracy: 98.474% \n",
      "[epoch:17, iter:1244] Loss: 0.537 | Accuracy: 98.438% \n",
      "[epoch:17, iter:1245] Loss: 0.536 | Accuracy: 98.472% \n",
      "[epoch:17, iter:1246] Loss: 0.535 | Accuracy: 98.505% \n",
      "[epoch:17, iter:1247] Loss: 0.535 | Accuracy: 98.537% \n",
      "[epoch:17, iter:1248] Loss: 0.534 | Accuracy: 98.568% \n",
      "[epoch:17, iter:1249] Loss: 0.533 | Accuracy: 98.597% \n",
      "[epoch:17, iter:1250] Loss: 0.533 | Accuracy: 98.562% \n",
      "[epoch:17, iter:1251] Loss: 0.533 | Accuracy: 98.591% \n",
      "[epoch:17, iter:1252] Loss: 0.532 | Accuracy: 98.618% \n",
      "[epoch:17, iter:1253] Loss: 0.532 | Accuracy: 98.585% \n",
      "[epoch:17, iter:1254] Loss: 0.531 | Accuracy: 98.611% \n",
      "[epoch:17, iter:1255] Loss: 0.532 | Accuracy: 98.580% \n",
      "[epoch:17, iter:1256] Loss: 0.533 | Accuracy: 98.549% \n",
      "[epoch:17, iter:1257] Loss: 0.532 | Accuracy: 98.575% \n",
      "[epoch:17, iter:1258] Loss: 0.532 | Accuracy: 98.599% \n",
      "[epoch:17, iter:1259] Loss: 0.531 | Accuracy: 98.570% \n",
      "[epoch:17, iter:1260] Loss: 0.533 | Accuracy: 98.542% \n",
      "[epoch:17, iter:1261] Loss: 0.533 | Accuracy: 98.514% \n",
      "[epoch:17, iter:1262] Loss: 0.533 | Accuracy: 98.538% \n",
      "[epoch:17, iter:1263] Loss: 0.532 | Accuracy: 98.562% \n",
      "[epoch:17, iter:1264] Loss: 0.531 | Accuracy: 98.584% \n",
      "[epoch:17, iter:1265] Loss: 0.531 | Accuracy: 98.606% \n",
      "[epoch:17, iter:1266] Loss: 0.530 | Accuracy: 98.627% \n",
      "[epoch:17, iter:1267] Loss: 0.530 | Accuracy: 98.647% \n",
      "[epoch:17, iter:1268] Loss: 0.529 | Accuracy: 98.667% \n",
      "[epoch:17, iter:1269] Loss: 0.529 | Accuracy: 98.687% \n",
      "[epoch:17, iter:1270] Loss: 0.528 | Accuracy: 98.705% \n",
      "[epoch:17, iter:1271] Loss: 0.528 | Accuracy: 98.724% \n",
      "[epoch:17, iter:1272] Loss: 0.527 | Accuracy: 98.741% \n",
      "[epoch:17, iter:1273] Loss: 0.527 | Accuracy: 98.759% \n",
      "[epoch:17, iter:1274] Loss: 0.527 | Accuracy: 98.733% \n",
      "[epoch:17, iter:1275] Loss: 0.532 | Accuracy: 98.734% \n",
      "Waiting Test!\n",
      "EPOCH=017, Loss: 1.002, Accuracy= 86.184%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "\n",
      "Epoch: 18\n",
      "[epoch:18, iter:1276] Loss: 0.516 | Accuracy: 100.000% \n",
      "[epoch:18, iter:1277] Loss: 0.572 | Accuracy: 98.438% \n",
      "[epoch:18, iter:1278] Loss: 0.550 | Accuracy: 98.958% \n",
      "[epoch:18, iter:1279] Loss: 0.549 | Accuracy: 98.438% \n",
      "[epoch:18, iter:1280] Loss: 0.538 | Accuracy: 98.750% \n",
      "[epoch:18, iter:1281] Loss: 0.532 | Accuracy: 98.958% \n",
      "[epoch:18, iter:1282] Loss: 0.528 | Accuracy: 99.107% \n",
      "[epoch:18, iter:1283] Loss: 0.529 | Accuracy: 98.828% \n",
      "[epoch:18, iter:1284] Loss: 0.526 | Accuracy: 98.958% \n",
      "[epoch:18, iter:1285] Loss: 0.523 | Accuracy: 99.062% \n",
      "[epoch:18, iter:1286] Loss: 0.521 | Accuracy: 99.148% \n",
      "[epoch:18, iter:1287] Loss: 0.520 | Accuracy: 99.219% \n",
      "[epoch:18, iter:1288] Loss: 0.520 | Accuracy: 99.038% \n",
      "[epoch:18, iter:1289] Loss: 0.518 | Accuracy: 99.107% \n",
      "[epoch:18, iter:1290] Loss: 0.519 | Accuracy: 98.958% \n",
      "[epoch:18, iter:1291] Loss: 0.518 | Accuracy: 99.023% \n",
      "[epoch:18, iter:1292] Loss: 0.516 | Accuracy: 99.081% \n",
      "[epoch:18, iter:1293] Loss: 0.515 | Accuracy: 99.132% \n",
      "[epoch:18, iter:1294] Loss: 0.514 | Accuracy: 99.178% \n",
      "[epoch:18, iter:1295] Loss: 0.513 | Accuracy: 99.219% \n",
      "[epoch:18, iter:1296] Loss: 0.512 | Accuracy: 99.256% \n",
      "[epoch:18, iter:1297] Loss: 0.511 | Accuracy: 99.290% \n",
      "[epoch:18, iter:1298] Loss: 0.510 | Accuracy: 99.321% \n",
      "[epoch:18, iter:1299] Loss: 0.511 | Accuracy: 99.219% \n",
      "[epoch:18, iter:1300] Loss: 0.510 | Accuracy: 99.250% \n",
      "[epoch:18, iter:1301] Loss: 0.509 | Accuracy: 99.279% \n",
      "[epoch:18, iter:1302] Loss: 0.508 | Accuracy: 99.306% \n",
      "[epoch:18, iter:1303] Loss: 0.508 | Accuracy: 99.330% \n",
      "[epoch:18, iter:1304] Loss: 0.507 | Accuracy: 99.353% \n",
      "[epoch:18, iter:1305] Loss: 0.511 | Accuracy: 99.271% \n",
      "[epoch:18, iter:1306] Loss: 0.511 | Accuracy: 99.294% \n",
      "[epoch:18, iter:1307] Loss: 0.511 | Accuracy: 99.316% \n",
      "[epoch:18, iter:1308] Loss: 0.510 | Accuracy: 99.337% \n",
      "[epoch:18, iter:1309] Loss: 0.509 | Accuracy: 99.357% \n",
      "[epoch:18, iter:1310] Loss: 0.509 | Accuracy: 99.375% \n",
      "[epoch:18, iter:1311] Loss: 0.509 | Accuracy: 99.392% \n",
      "[epoch:18, iter:1312] Loss: 0.508 | Accuracy: 99.409% \n",
      "[epoch:18, iter:1313] Loss: 0.508 | Accuracy: 99.424% \n",
      "[epoch:18, iter:1314] Loss: 0.507 | Accuracy: 99.439% \n",
      "[epoch:18, iter:1315] Loss: 0.507 | Accuracy: 99.453% \n",
      "[epoch:18, iter:1316] Loss: 0.507 | Accuracy: 99.466% \n",
      "[epoch:18, iter:1317] Loss: 0.506 | Accuracy: 99.479% \n",
      "[epoch:18, iter:1318] Loss: 0.506 | Accuracy: 99.491% \n",
      "[epoch:18, iter:1319] Loss: 0.506 | Accuracy: 99.503% \n",
      "[epoch:18, iter:1320] Loss: 0.506 | Accuracy: 99.514% \n",
      "[epoch:18, iter:1321] Loss: 0.505 | Accuracy: 99.524% \n",
      "[epoch:18, iter:1322] Loss: 0.505 | Accuracy: 99.535% \n",
      "[epoch:18, iter:1323] Loss: 0.506 | Accuracy: 99.479% \n",
      "[epoch:18, iter:1324] Loss: 0.507 | Accuracy: 99.426% \n",
      "[epoch:18, iter:1325] Loss: 0.507 | Accuracy: 99.438% \n",
      "[epoch:18, iter:1326] Loss: 0.508 | Accuracy: 99.387% \n",
      "[epoch:18, iter:1327] Loss: 0.509 | Accuracy: 99.339% \n",
      "[epoch:18, iter:1328] Loss: 0.509 | Accuracy: 99.351% \n",
      "[epoch:18, iter:1329] Loss: 0.509 | Accuracy: 99.306% \n",
      "[epoch:18, iter:1330] Loss: 0.510 | Accuracy: 99.205% \n",
      "[epoch:18, iter:1331] Loss: 0.510 | Accuracy: 99.219% \n",
      "[epoch:18, iter:1332] Loss: 0.510 | Accuracy: 99.178% \n",
      "[epoch:18, iter:1333] Loss: 0.510 | Accuracy: 99.192% \n",
      "[epoch:18, iter:1334] Loss: 0.510 | Accuracy: 99.206% \n",
      "[epoch:18, iter:1335] Loss: 0.510 | Accuracy: 99.167% \n",
      "[epoch:18, iter:1336] Loss: 0.510 | Accuracy: 99.180% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:18, iter:1337] Loss: 0.510 | Accuracy: 99.194% \n",
      "[epoch:18, iter:1338] Loss: 0.510 | Accuracy: 99.206% \n",
      "[epoch:18, iter:1339] Loss: 0.511 | Accuracy: 99.121% \n",
      "[epoch:18, iter:1340] Loss: 0.511 | Accuracy: 99.135% \n",
      "[epoch:18, iter:1341] Loss: 0.511 | Accuracy: 99.148% \n",
      "[epoch:18, iter:1342] Loss: 0.510 | Accuracy: 99.160% \n",
      "[epoch:18, iter:1343] Loss: 0.510 | Accuracy: 99.173% \n",
      "[epoch:18, iter:1344] Loss: 0.510 | Accuracy: 99.185% \n",
      "[epoch:18, iter:1345] Loss: 0.510 | Accuracy: 99.152% \n",
      "[epoch:18, iter:1346] Loss: 0.510 | Accuracy: 99.164% \n",
      "[epoch:18, iter:1347] Loss: 0.510 | Accuracy: 99.175% \n",
      "[epoch:18, iter:1348] Loss: 0.510 | Accuracy: 99.187% \n",
      "[epoch:18, iter:1349] Loss: 0.509 | Accuracy: 99.198% \n",
      "[epoch:18, iter:1350] Loss: 0.509 | Accuracy: 99.198% \n",
      "Waiting Test!\n",
      "EPOCH=018, Loss: 0.748, Accuracy= 92.105%\n",
      "Epoch 00018: reducing learning rate of group 0 to 2.1000e-04.\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "\n",
      "Epoch: 19\n",
      "[epoch:19, iter:1351] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:19, iter:1352] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:19, iter:1353] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:19, iter:1354] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:19, iter:1355] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:19, iter:1356] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:19, iter:1357] Loss: 0.501 | Accuracy: 99.554% \n",
      "[epoch:19, iter:1358] Loss: 0.499 | Accuracy: 99.609% \n",
      "[epoch:19, iter:1359] Loss: 0.499 | Accuracy: 99.653% \n",
      "[epoch:19, iter:1360] Loss: 0.499 | Accuracy: 99.688% \n",
      "[epoch:19, iter:1361] Loss: 0.498 | Accuracy: 99.716% \n",
      "[epoch:19, iter:1362] Loss: 0.498 | Accuracy: 99.740% \n",
      "[epoch:19, iter:1363] Loss: 0.497 | Accuracy: 99.760% \n",
      "[epoch:19, iter:1364] Loss: 0.497 | Accuracy: 99.777% \n",
      "[epoch:19, iter:1365] Loss: 0.497 | Accuracy: 99.792% \n",
      "[epoch:19, iter:1366] Loss: 0.496 | Accuracy: 99.805% \n",
      "[epoch:19, iter:1367] Loss: 0.496 | Accuracy: 99.816% \n",
      "[epoch:19, iter:1368] Loss: 0.496 | Accuracy: 99.826% \n",
      "[epoch:19, iter:1369] Loss: 0.496 | Accuracy: 99.836% \n",
      "[epoch:19, iter:1370] Loss: 0.496 | Accuracy: 99.844% \n",
      "[epoch:19, iter:1371] Loss: 0.495 | Accuracy: 99.851% \n",
      "[epoch:19, iter:1372] Loss: 0.496 | Accuracy: 99.716% \n",
      "[epoch:19, iter:1373] Loss: 0.496 | Accuracy: 99.728% \n",
      "[epoch:19, iter:1374] Loss: 0.496 | Accuracy: 99.740% \n",
      "[epoch:19, iter:1375] Loss: 0.496 | Accuracy: 99.750% \n",
      "[epoch:19, iter:1376] Loss: 0.495 | Accuracy: 99.760% \n",
      "[epoch:19, iter:1377] Loss: 0.495 | Accuracy: 99.769% \n",
      "[epoch:19, iter:1378] Loss: 0.495 | Accuracy: 99.777% \n",
      "[epoch:19, iter:1379] Loss: 0.495 | Accuracy: 99.784% \n",
      "[epoch:19, iter:1380] Loss: 0.495 | Accuracy: 99.792% \n",
      "[epoch:19, iter:1381] Loss: 0.495 | Accuracy: 99.798% \n",
      "[epoch:19, iter:1382] Loss: 0.495 | Accuracy: 99.805% \n",
      "[epoch:19, iter:1383] Loss: 0.495 | Accuracy: 99.811% \n",
      "[epoch:19, iter:1384] Loss: 0.495 | Accuracy: 99.816% \n",
      "[epoch:19, iter:1385] Loss: 0.495 | Accuracy: 99.821% \n",
      "[epoch:19, iter:1386] Loss: 0.495 | Accuracy: 99.826% \n",
      "[epoch:19, iter:1387] Loss: 0.495 | Accuracy: 99.831% \n",
      "[epoch:19, iter:1388] Loss: 0.495 | Accuracy: 99.836% \n",
      "[epoch:19, iter:1389] Loss: 0.495 | Accuracy: 99.840% \n",
      "[epoch:19, iter:1390] Loss: 0.495 | Accuracy: 99.844% \n",
      "[epoch:19, iter:1391] Loss: 0.495 | Accuracy: 99.848% \n",
      "[epoch:19, iter:1392] Loss: 0.495 | Accuracy: 99.851% \n",
      "[epoch:19, iter:1393] Loss: 0.495 | Accuracy: 99.855% \n",
      "[epoch:19, iter:1394] Loss: 0.495 | Accuracy: 99.858% \n",
      "[epoch:19, iter:1395] Loss: 0.494 | Accuracy: 99.861% \n",
      "[epoch:19, iter:1396] Loss: 0.494 | Accuracy: 99.864% \n",
      "[epoch:19, iter:1397] Loss: 0.496 | Accuracy: 99.801% \n",
      "[epoch:19, iter:1398] Loss: 0.496 | Accuracy: 99.805% \n",
      "[epoch:19, iter:1399] Loss: 0.498 | Accuracy: 99.745% \n",
      "[epoch:19, iter:1400] Loss: 0.498 | Accuracy: 99.750% \n",
      "[epoch:19, iter:1401] Loss: 0.498 | Accuracy: 99.755% \n",
      "[epoch:19, iter:1402] Loss: 0.498 | Accuracy: 99.760% \n",
      "[epoch:19, iter:1403] Loss: 0.498 | Accuracy: 99.764% \n",
      "[epoch:19, iter:1404] Loss: 0.498 | Accuracy: 99.769% \n",
      "[epoch:19, iter:1405] Loss: 0.499 | Accuracy: 99.716% \n",
      "[epoch:19, iter:1406] Loss: 0.499 | Accuracy: 99.721% \n",
      "[epoch:19, iter:1407] Loss: 0.499 | Accuracy: 99.726% \n",
      "[epoch:19, iter:1408] Loss: 0.499 | Accuracy: 99.731% \n",
      "[epoch:19, iter:1409] Loss: 0.499 | Accuracy: 99.735% \n",
      "[epoch:19, iter:1410] Loss: 0.499 | Accuracy: 99.740% \n",
      "[epoch:19, iter:1411] Loss: 0.499 | Accuracy: 99.744% \n",
      "[epoch:19, iter:1412] Loss: 0.499 | Accuracy: 99.748% \n",
      "[epoch:19, iter:1413] Loss: 0.499 | Accuracy: 99.752% \n",
      "[epoch:19, iter:1414] Loss: 0.499 | Accuracy: 99.756% \n",
      "[epoch:19, iter:1415] Loss: 0.499 | Accuracy: 99.760% \n",
      "[epoch:19, iter:1416] Loss: 0.499 | Accuracy: 99.763% \n",
      "[epoch:19, iter:1417] Loss: 0.498 | Accuracy: 99.767% \n",
      "[epoch:19, iter:1418] Loss: 0.498 | Accuracy: 99.770% \n",
      "[epoch:19, iter:1419] Loss: 0.498 | Accuracy: 99.774% \n",
      "[epoch:19, iter:1420] Loss: 0.498 | Accuracy: 99.777% \n",
      "[epoch:19, iter:1421] Loss: 0.498 | Accuracy: 99.780% \n",
      "[epoch:19, iter:1422] Loss: 0.498 | Accuracy: 99.783% \n",
      "[epoch:19, iter:1423] Loss: 0.498 | Accuracy: 99.786% \n",
      "[epoch:19, iter:1424] Loss: 0.498 | Accuracy: 99.789% \n",
      "[epoch:19, iter:1425] Loss: 0.498 | Accuracy: 99.789% \n",
      "Waiting Test!\n",
      "EPOCH=019, Loss: 0.695, Accuracy= 93.092%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 5 out of 30\n",
      "\n",
      "Epoch: 20\n",
      "[epoch:20, iter:1426] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1427] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1428] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1429] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:20, iter:1430] Loss: 0.496 | Accuracy: 99.375% \n",
      "[epoch:20, iter:1431] Loss: 0.496 | Accuracy: 99.479% \n",
      "[epoch:20, iter:1432] Loss: 0.495 | Accuracy: 99.554% \n",
      "[epoch:20, iter:1433] Loss: 0.495 | Accuracy: 99.609% \n",
      "[epoch:20, iter:1434] Loss: 0.495 | Accuracy: 99.653% \n",
      "[epoch:20, iter:1435] Loss: 0.495 | Accuracy: 99.688% \n",
      "[epoch:20, iter:1436] Loss: 0.494 | Accuracy: 99.716% \n",
      "[epoch:20, iter:1437] Loss: 0.494 | Accuracy: 99.740% \n",
      "[epoch:20, iter:1438] Loss: 0.494 | Accuracy: 99.760% \n",
      "[epoch:20, iter:1439] Loss: 0.494 | Accuracy: 99.777% \n",
      "[epoch:20, iter:1440] Loss: 0.494 | Accuracy: 99.792% \n",
      "[epoch:20, iter:1441] Loss: 0.493 | Accuracy: 99.805% \n",
      "[epoch:20, iter:1442] Loss: 0.493 | Accuracy: 99.816% \n",
      "[epoch:20, iter:1443] Loss: 0.493 | Accuracy: 99.826% \n",
      "[epoch:20, iter:1444] Loss: 0.493 | Accuracy: 99.836% \n",
      "[epoch:20, iter:1445] Loss: 0.493 | Accuracy: 99.844% \n",
      "[epoch:20, iter:1446] Loss: 0.492 | Accuracy: 99.851% \n",
      "[epoch:20, iter:1447] Loss: 0.492 | Accuracy: 99.858% \n",
      "[epoch:20, iter:1448] Loss: 0.492 | Accuracy: 99.864% \n",
      "[epoch:20, iter:1449] Loss: 0.492 | Accuracy: 99.870% \n",
      "[epoch:20, iter:1450] Loss: 0.492 | Accuracy: 99.875% \n",
      "[epoch:20, iter:1451] Loss: 0.493 | Accuracy: 99.760% \n",
      "[epoch:20, iter:1452] Loss: 0.493 | Accuracy: 99.769% \n",
      "[epoch:20, iter:1453] Loss: 0.492 | Accuracy: 99.777% \n",
      "[epoch:20, iter:1454] Loss: 0.492 | Accuracy: 99.784% \n",
      "[epoch:20, iter:1455] Loss: 0.492 | Accuracy: 99.792% \n",
      "[epoch:20, iter:1456] Loss: 0.492 | Accuracy: 99.798% \n",
      "[epoch:20, iter:1457] Loss: 0.493 | Accuracy: 99.805% \n",
      "[epoch:20, iter:1458] Loss: 0.493 | Accuracy: 99.811% \n",
      "[epoch:20, iter:1459] Loss: 0.493 | Accuracy: 99.816% \n",
      "[epoch:20, iter:1460] Loss: 0.492 | Accuracy: 99.821% \n",
      "[epoch:20, iter:1461] Loss: 0.492 | Accuracy: 99.826% \n",
      "[epoch:20, iter:1462] Loss: 0.492 | Accuracy: 99.831% \n",
      "[epoch:20, iter:1463] Loss: 0.492 | Accuracy: 99.836% \n",
      "[epoch:20, iter:1464] Loss: 0.492 | Accuracy: 99.840% \n",
      "[epoch:20, iter:1465] Loss: 0.492 | Accuracy: 99.844% \n",
      "[epoch:20, iter:1466] Loss: 0.492 | Accuracy: 99.848% \n",
      "[epoch:20, iter:1467] Loss: 0.492 | Accuracy: 99.851% \n",
      "[epoch:20, iter:1468] Loss: 0.492 | Accuracy: 99.855% \n",
      "[epoch:20, iter:1469] Loss: 0.492 | Accuracy: 99.858% \n",
      "[epoch:20, iter:1470] Loss: 0.492 | Accuracy: 99.861% \n",
      "[epoch:20, iter:1471] Loss: 0.492 | Accuracy: 99.864% \n",
      "[epoch:20, iter:1472] Loss: 0.492 | Accuracy: 99.867% \n",
      "[epoch:20, iter:1473] Loss: 0.492 | Accuracy: 99.870% \n",
      "[epoch:20, iter:1474] Loss: 0.492 | Accuracy: 99.872% \n",
      "[epoch:20, iter:1475] Loss: 0.492 | Accuracy: 99.875% \n",
      "[epoch:20, iter:1476] Loss: 0.492 | Accuracy: 99.877% \n",
      "[epoch:20, iter:1477] Loss: 0.492 | Accuracy: 99.880% \n",
      "[epoch:20, iter:1478] Loss: 0.491 | Accuracy: 99.882% \n",
      "[epoch:20, iter:1479] Loss: 0.491 | Accuracy: 99.884% \n",
      "[epoch:20, iter:1480] Loss: 0.491 | Accuracy: 99.886% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:20, iter:1481] Loss: 0.491 | Accuracy: 99.888% \n",
      "[epoch:20, iter:1482] Loss: 0.491 | Accuracy: 99.890% \n",
      "[epoch:20, iter:1483] Loss: 0.491 | Accuracy: 99.892% \n",
      "[epoch:20, iter:1484] Loss: 0.491 | Accuracy: 99.894% \n",
      "[epoch:20, iter:1485] Loss: 0.491 | Accuracy: 99.896% \n",
      "[epoch:20, iter:1486] Loss: 0.491 | Accuracy: 99.898% \n",
      "[epoch:20, iter:1487] Loss: 0.492 | Accuracy: 99.849% \n",
      "[epoch:20, iter:1488] Loss: 0.492 | Accuracy: 99.851% \n",
      "[epoch:20, iter:1489] Loss: 0.492 | Accuracy: 99.854% \n",
      "[epoch:20, iter:1490] Loss: 0.492 | Accuracy: 99.856% \n",
      "[epoch:20, iter:1491] Loss: 0.492 | Accuracy: 99.858% \n",
      "[epoch:20, iter:1492] Loss: 0.493 | Accuracy: 99.813% \n",
      "[epoch:20, iter:1493] Loss: 0.493 | Accuracy: 99.816% \n",
      "[epoch:20, iter:1494] Loss: 0.493 | Accuracy: 99.819% \n",
      "[epoch:20, iter:1495] Loss: 0.493 | Accuracy: 99.821% \n",
      "[epoch:20, iter:1496] Loss: 0.493 | Accuracy: 99.824% \n",
      "[epoch:20, iter:1497] Loss: 0.493 | Accuracy: 99.826% \n",
      "[epoch:20, iter:1498] Loss: 0.493 | Accuracy: 99.829% \n",
      "[epoch:20, iter:1499] Loss: 0.493 | Accuracy: 99.831% \n",
      "[epoch:20, iter:1500] Loss: 0.500 | Accuracy: 99.831% \n",
      "Waiting Test!\n",
      "EPOCH=020, Loss: 0.698, Accuracy= 94.079%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 6 out of 30\n",
      "\n",
      "Epoch: 21\n",
      "[epoch:21, iter:1501] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1502] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1503] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1504] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1505] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1506] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1507] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1508] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1509] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1510] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1511] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1512] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1513] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1514] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1515] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1516] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:21, iter:1517] Loss: 0.499 | Accuracy: 99.816% \n",
      "[epoch:21, iter:1518] Loss: 0.498 | Accuracy: 99.826% \n",
      "[epoch:21, iter:1519] Loss: 0.498 | Accuracy: 99.836% \n",
      "[epoch:21, iter:1520] Loss: 0.497 | Accuracy: 99.844% \n",
      "[epoch:21, iter:1521] Loss: 0.497 | Accuracy: 99.851% \n",
      "[epoch:21, iter:1522] Loss: 0.497 | Accuracy: 99.858% \n",
      "[epoch:21, iter:1523] Loss: 0.496 | Accuracy: 99.864% \n",
      "[epoch:21, iter:1524] Loss: 0.496 | Accuracy: 99.870% \n",
      "[epoch:21, iter:1525] Loss: 0.496 | Accuracy: 99.875% \n",
      "[epoch:21, iter:1526] Loss: 0.496 | Accuracy: 99.880% \n",
      "[epoch:21, iter:1527] Loss: 0.496 | Accuracy: 99.884% \n",
      "[epoch:21, iter:1528] Loss: 0.496 | Accuracy: 99.888% \n",
      "[epoch:21, iter:1529] Loss: 0.496 | Accuracy: 99.892% \n",
      "[epoch:21, iter:1530] Loss: 0.496 | Accuracy: 99.896% \n",
      "[epoch:21, iter:1531] Loss: 0.496 | Accuracy: 99.899% \n",
      "[epoch:21, iter:1532] Loss: 0.496 | Accuracy: 99.902% \n",
      "[epoch:21, iter:1533] Loss: 0.496 | Accuracy: 99.905% \n",
      "[epoch:21, iter:1534] Loss: 0.495 | Accuracy: 99.908% \n",
      "[epoch:21, iter:1535] Loss: 0.495 | Accuracy: 99.911% \n",
      "[epoch:21, iter:1536] Loss: 0.495 | Accuracy: 99.913% \n",
      "[epoch:21, iter:1537] Loss: 0.495 | Accuracy: 99.916% \n",
      "[epoch:21, iter:1538] Loss: 0.495 | Accuracy: 99.918% \n",
      "[epoch:21, iter:1539] Loss: 0.495 | Accuracy: 99.920% \n",
      "[epoch:21, iter:1540] Loss: 0.495 | Accuracy: 99.922% \n",
      "[epoch:21, iter:1541] Loss: 0.494 | Accuracy: 99.924% \n",
      "[epoch:21, iter:1542] Loss: 0.494 | Accuracy: 99.926% \n",
      "[epoch:21, iter:1543] Loss: 0.495 | Accuracy: 99.855% \n",
      "[epoch:21, iter:1544] Loss: 0.495 | Accuracy: 99.858% \n",
      "[epoch:21, iter:1545] Loss: 0.497 | Accuracy: 99.722% \n",
      "[epoch:21, iter:1546] Loss: 0.497 | Accuracy: 99.728% \n",
      "[epoch:21, iter:1547] Loss: 0.497 | Accuracy: 99.734% \n",
      "[epoch:21, iter:1548] Loss: 0.497 | Accuracy: 99.740% \n",
      "[epoch:21, iter:1549] Loss: 0.496 | Accuracy: 99.745% \n",
      "[epoch:21, iter:1550] Loss: 0.496 | Accuracy: 99.750% \n",
      "[epoch:21, iter:1551] Loss: 0.496 | Accuracy: 99.755% \n",
      "[epoch:21, iter:1552] Loss: 0.497 | Accuracy: 99.700% \n",
      "[epoch:21, iter:1553] Loss: 0.497 | Accuracy: 99.705% \n",
      "[epoch:21, iter:1554] Loss: 0.497 | Accuracy: 99.711% \n",
      "[epoch:21, iter:1555] Loss: 0.497 | Accuracy: 99.716% \n",
      "[epoch:21, iter:1556] Loss: 0.497 | Accuracy: 99.721% \n",
      "[epoch:21, iter:1557] Loss: 0.497 | Accuracy: 99.726% \n",
      "[epoch:21, iter:1558] Loss: 0.497 | Accuracy: 99.731% \n",
      "[epoch:21, iter:1559] Loss: 0.498 | Accuracy: 99.682% \n",
      "[epoch:21, iter:1560] Loss: 0.498 | Accuracy: 99.688% \n",
      "[epoch:21, iter:1561] Loss: 0.498 | Accuracy: 99.693% \n",
      "[epoch:21, iter:1562] Loss: 0.498 | Accuracy: 99.698% \n",
      "[epoch:21, iter:1563] Loss: 0.498 | Accuracy: 99.702% \n",
      "[epoch:21, iter:1564] Loss: 0.498 | Accuracy: 99.707% \n",
      "[epoch:21, iter:1565] Loss: 0.498 | Accuracy: 99.712% \n",
      "[epoch:21, iter:1566] Loss: 0.497 | Accuracy: 99.716% \n",
      "[epoch:21, iter:1567] Loss: 0.497 | Accuracy: 99.720% \n",
      "[epoch:21, iter:1568] Loss: 0.497 | Accuracy: 99.724% \n",
      "[epoch:21, iter:1569] Loss: 0.497 | Accuracy: 99.728% \n",
      "[epoch:21, iter:1570] Loss: 0.497 | Accuracy: 99.732% \n",
      "[epoch:21, iter:1571] Loss: 0.497 | Accuracy: 99.736% \n",
      "[epoch:21, iter:1572] Loss: 0.497 | Accuracy: 99.740% \n",
      "[epoch:21, iter:1573] Loss: 0.497 | Accuracy: 99.743% \n",
      "[epoch:21, iter:1574] Loss: 0.497 | Accuracy: 99.747% \n",
      "[epoch:21, iter:1575] Loss: 0.497 | Accuracy: 99.747% \n",
      "Waiting Test!\n",
      "EPOCH=021, Loss: 0.643, Accuracy= 95.724%\n",
      "Training complete in 0m 14s\n",
      "Validation accuracy increased (94.407895 --> 95.723684).  Saving model ...\n",
      "\n",
      "Epoch: 22\n",
      "[epoch:22, iter:1576] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1577] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1578] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1579] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1580] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1581] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1582] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1583] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1584] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1585] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1586] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1587] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1588] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1589] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1590] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1591] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1592] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1593] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1594] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1595] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1596] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1597] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1598] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1599] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1600] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1601] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1602] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1603] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1604] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1605] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1606] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1607] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1608] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1609] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1610] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1611] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1612] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1613] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1614] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1615] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1616] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1617] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1618] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1619] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1620] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1621] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1622] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1623] Loss: 0.490 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:22, iter:1624] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1625] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1626] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1627] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1628] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1629] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1630] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1631] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1632] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1633] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1634] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1635] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1636] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1637] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1638] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1639] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1640] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1641] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1642] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1643] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1644] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1645] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1646] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1647] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1648] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1649] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:22, iter:1650] Loss: 0.489 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=022, Loss: 0.688, Accuracy= 93.750%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "\n",
      "Epoch: 23\n",
      "[epoch:23, iter:1651] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1652] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1653] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1654] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1655] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:23, iter:1656] Loss: 0.497 | Accuracy: 99.479% \n",
      "[epoch:23, iter:1657] Loss: 0.496 | Accuracy: 99.554% \n",
      "[epoch:23, iter:1658] Loss: 0.495 | Accuracy: 99.609% \n",
      "[epoch:23, iter:1659] Loss: 0.494 | Accuracy: 99.653% \n",
      "[epoch:23, iter:1660] Loss: 0.494 | Accuracy: 99.688% \n",
      "[epoch:23, iter:1661] Loss: 0.493 | Accuracy: 99.716% \n",
      "[epoch:23, iter:1662] Loss: 0.493 | Accuracy: 99.740% \n",
      "[epoch:23, iter:1663] Loss: 0.500 | Accuracy: 99.519% \n",
      "[epoch:23, iter:1664] Loss: 0.499 | Accuracy: 99.554% \n",
      "[epoch:23, iter:1665] Loss: 0.499 | Accuracy: 99.583% \n",
      "[epoch:23, iter:1666] Loss: 0.498 | Accuracy: 99.609% \n",
      "[epoch:23, iter:1667] Loss: 0.498 | Accuracy: 99.632% \n",
      "[epoch:23, iter:1668] Loss: 0.497 | Accuracy: 99.653% \n",
      "[epoch:23, iter:1669] Loss: 0.498 | Accuracy: 99.507% \n",
      "[epoch:23, iter:1670] Loss: 0.498 | Accuracy: 99.531% \n",
      "[epoch:23, iter:1671] Loss: 0.498 | Accuracy: 99.554% \n",
      "[epoch:23, iter:1672] Loss: 0.497 | Accuracy: 99.574% \n",
      "[epoch:23, iter:1673] Loss: 0.497 | Accuracy: 99.592% \n",
      "[epoch:23, iter:1674] Loss: 0.497 | Accuracy: 99.609% \n",
      "[epoch:23, iter:1675] Loss: 0.497 | Accuracy: 99.625% \n",
      "[epoch:23, iter:1676] Loss: 0.496 | Accuracy: 99.639% \n",
      "[epoch:23, iter:1677] Loss: 0.496 | Accuracy: 99.653% \n",
      "[epoch:23, iter:1678] Loss: 0.496 | Accuracy: 99.665% \n",
      "[epoch:23, iter:1679] Loss: 0.496 | Accuracy: 99.677% \n",
      "[epoch:23, iter:1680] Loss: 0.496 | Accuracy: 99.688% \n",
      "[epoch:23, iter:1681] Loss: 0.495 | Accuracy: 99.698% \n",
      "[epoch:23, iter:1682] Loss: 0.496 | Accuracy: 99.707% \n",
      "[epoch:23, iter:1683] Loss: 0.496 | Accuracy: 99.716% \n",
      "[epoch:23, iter:1684] Loss: 0.496 | Accuracy: 99.724% \n",
      "[epoch:23, iter:1685] Loss: 0.496 | Accuracy: 99.732% \n",
      "[epoch:23, iter:1686] Loss: 0.496 | Accuracy: 99.740% \n",
      "[epoch:23, iter:1687] Loss: 0.495 | Accuracy: 99.747% \n",
      "[epoch:23, iter:1688] Loss: 0.495 | Accuracy: 99.753% \n",
      "[epoch:23, iter:1689] Loss: 0.495 | Accuracy: 99.760% \n",
      "[epoch:23, iter:1690] Loss: 0.495 | Accuracy: 99.766% \n",
      "[epoch:23, iter:1691] Loss: 0.495 | Accuracy: 99.771% \n",
      "[epoch:23, iter:1692] Loss: 0.495 | Accuracy: 99.777% \n",
      "[epoch:23, iter:1693] Loss: 0.495 | Accuracy: 99.782% \n",
      "[epoch:23, iter:1694] Loss: 0.495 | Accuracy: 99.787% \n",
      "[epoch:23, iter:1695] Loss: 0.495 | Accuracy: 99.792% \n",
      "[epoch:23, iter:1696] Loss: 0.495 | Accuracy: 99.796% \n",
      "[epoch:23, iter:1697] Loss: 0.495 | Accuracy: 99.801% \n",
      "[epoch:23, iter:1698] Loss: 0.495 | Accuracy: 99.805% \n",
      "[epoch:23, iter:1699] Loss: 0.495 | Accuracy: 99.809% \n",
      "[epoch:23, iter:1700] Loss: 0.495 | Accuracy: 99.812% \n",
      "[epoch:23, iter:1701] Loss: 0.494 | Accuracy: 99.816% \n",
      "[epoch:23, iter:1702] Loss: 0.494 | Accuracy: 99.820% \n",
      "[epoch:23, iter:1703] Loss: 0.494 | Accuracy: 99.823% \n",
      "[epoch:23, iter:1704] Loss: 0.494 | Accuracy: 99.826% \n",
      "[epoch:23, iter:1705] Loss: 0.494 | Accuracy: 99.830% \n",
      "[epoch:23, iter:1706] Loss: 0.494 | Accuracy: 99.833% \n",
      "[epoch:23, iter:1707] Loss: 0.494 | Accuracy: 99.836% \n",
      "[epoch:23, iter:1708] Loss: 0.494 | Accuracy: 99.838% \n",
      "[epoch:23, iter:1709] Loss: 0.494 | Accuracy: 99.841% \n",
      "[epoch:23, iter:1710] Loss: 0.494 | Accuracy: 99.844% \n",
      "[epoch:23, iter:1711] Loss: 0.494 | Accuracy: 99.846% \n",
      "[epoch:23, iter:1712] Loss: 0.494 | Accuracy: 99.849% \n",
      "[epoch:23, iter:1713] Loss: 0.494 | Accuracy: 99.851% \n",
      "[epoch:23, iter:1714] Loss: 0.494 | Accuracy: 99.854% \n",
      "[epoch:23, iter:1715] Loss: 0.493 | Accuracy: 99.856% \n",
      "[epoch:23, iter:1716] Loss: 0.493 | Accuracy: 99.858% \n",
      "[epoch:23, iter:1717] Loss: 0.493 | Accuracy: 99.860% \n",
      "[epoch:23, iter:1718] Loss: 0.493 | Accuracy: 99.862% \n",
      "[epoch:23, iter:1719] Loss: 0.493 | Accuracy: 99.864% \n",
      "[epoch:23, iter:1720] Loss: 0.493 | Accuracy: 99.866% \n",
      "[epoch:23, iter:1721] Loss: 0.493 | Accuracy: 99.868% \n",
      "[epoch:23, iter:1722] Loss: 0.494 | Accuracy: 99.826% \n",
      "[epoch:23, iter:1723] Loss: 0.494 | Accuracy: 99.829% \n",
      "[epoch:23, iter:1724] Loss: 0.494 | Accuracy: 99.831% \n",
      "[epoch:23, iter:1725] Loss: 0.493 | Accuracy: 99.831% \n",
      "Waiting Test!\n",
      "EPOCH=023, Loss: 0.641, Accuracy= 94.408%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "\n",
      "Epoch: 24\n",
      "[epoch:24, iter:1726] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1727] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1728] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1729] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1730] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1731] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1732] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1733] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1734] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1735] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1736] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1737] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1738] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1739] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1740] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1741] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1742] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1743] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1744] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1745] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1746] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1747] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1748] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1749] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1750] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1751] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1752] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1753] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1754] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1755] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1756] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1757] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1758] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1759] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1760] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:24, iter:1761] Loss: 0.489 | Accuracy: 99.913% \n",
      "[epoch:24, iter:1762] Loss: 0.490 | Accuracy: 99.831% \n",
      "[epoch:24, iter:1763] Loss: 0.490 | Accuracy: 99.836% \n",
      "[epoch:24, iter:1764] Loss: 0.490 | Accuracy: 99.840% \n",
      "[epoch:24, iter:1765] Loss: 0.490 | Accuracy: 99.844% \n",
      "[epoch:24, iter:1766] Loss: 0.490 | Accuracy: 99.848% \n",
      "[epoch:24, iter:1767] Loss: 0.490 | Accuracy: 99.851% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:24, iter:1768] Loss: 0.490 | Accuracy: 99.855% \n",
      "[epoch:24, iter:1769] Loss: 0.490 | Accuracy: 99.858% \n",
      "[epoch:24, iter:1770] Loss: 0.490 | Accuracy: 99.861% \n",
      "[epoch:24, iter:1771] Loss: 0.490 | Accuracy: 99.864% \n",
      "[epoch:24, iter:1772] Loss: 0.490 | Accuracy: 99.867% \n",
      "[epoch:24, iter:1773] Loss: 0.491 | Accuracy: 99.870% \n",
      "[epoch:24, iter:1774] Loss: 0.491 | Accuracy: 99.872% \n",
      "[epoch:24, iter:1775] Loss: 0.491 | Accuracy: 99.875% \n",
      "[epoch:24, iter:1776] Loss: 0.491 | Accuracy: 99.877% \n",
      "[epoch:24, iter:1777] Loss: 0.491 | Accuracy: 99.880% \n",
      "[epoch:24, iter:1778] Loss: 0.491 | Accuracy: 99.882% \n",
      "[epoch:24, iter:1779] Loss: 0.491 | Accuracy: 99.884% \n",
      "[epoch:24, iter:1780] Loss: 0.491 | Accuracy: 99.886% \n",
      "[epoch:24, iter:1781] Loss: 0.491 | Accuracy: 99.888% \n",
      "[epoch:24, iter:1782] Loss: 0.491 | Accuracy: 99.890% \n",
      "[epoch:24, iter:1783] Loss: 0.491 | Accuracy: 99.892% \n",
      "[epoch:24, iter:1784] Loss: 0.491 | Accuracy: 99.894% \n",
      "[epoch:24, iter:1785] Loss: 0.491 | Accuracy: 99.896% \n",
      "[epoch:24, iter:1786] Loss: 0.491 | Accuracy: 99.898% \n",
      "[epoch:24, iter:1787] Loss: 0.491 | Accuracy: 99.899% \n",
      "[epoch:24, iter:1788] Loss: 0.491 | Accuracy: 99.901% \n",
      "[epoch:24, iter:1789] Loss: 0.491 | Accuracy: 99.902% \n",
      "[epoch:24, iter:1790] Loss: 0.491 | Accuracy: 99.904% \n",
      "[epoch:24, iter:1791] Loss: 0.491 | Accuracy: 99.905% \n",
      "[epoch:24, iter:1792] Loss: 0.491 | Accuracy: 99.907% \n",
      "[epoch:24, iter:1793] Loss: 0.491 | Accuracy: 99.908% \n",
      "[epoch:24, iter:1794] Loss: 0.491 | Accuracy: 99.909% \n",
      "[epoch:24, iter:1795] Loss: 0.491 | Accuracy: 99.911% \n",
      "[epoch:24, iter:1796] Loss: 0.491 | Accuracy: 99.912% \n",
      "[epoch:24, iter:1797] Loss: 0.491 | Accuracy: 99.913% \n",
      "[epoch:24, iter:1798] Loss: 0.491 | Accuracy: 99.914% \n",
      "[epoch:24, iter:1799] Loss: 0.491 | Accuracy: 99.916% \n",
      "[epoch:24, iter:1800] Loss: 0.491 | Accuracy: 99.916% \n",
      "Waiting Test!\n",
      "EPOCH=024, Loss: 0.674, Accuracy= 93.750%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "\n",
      "Epoch: 25\n",
      "[epoch:25, iter:1801] Loss: 0.530 | Accuracy: 96.875% \n",
      "[epoch:25, iter:1802] Loss: 0.518 | Accuracy: 98.438% \n",
      "[epoch:25, iter:1803] Loss: 0.510 | Accuracy: 98.958% \n",
      "[epoch:25, iter:1804] Loss: 0.505 | Accuracy: 99.219% \n",
      "[epoch:25, iter:1805] Loss: 0.501 | Accuracy: 99.375% \n",
      "[epoch:25, iter:1806] Loss: 0.499 | Accuracy: 99.479% \n",
      "[epoch:25, iter:1807] Loss: 0.498 | Accuracy: 99.554% \n",
      "[epoch:25, iter:1808] Loss: 0.497 | Accuracy: 99.609% \n",
      "[epoch:25, iter:1809] Loss: 0.496 | Accuracy: 99.653% \n",
      "[epoch:25, iter:1810] Loss: 0.502 | Accuracy: 99.375% \n",
      "[epoch:25, iter:1811] Loss: 0.501 | Accuracy: 99.432% \n",
      "[epoch:25, iter:1812] Loss: 0.501 | Accuracy: 99.479% \n",
      "[epoch:25, iter:1813] Loss: 0.500 | Accuracy: 99.519% \n",
      "[epoch:25, iter:1814] Loss: 0.499 | Accuracy: 99.554% \n",
      "[epoch:25, iter:1815] Loss: 0.498 | Accuracy: 99.583% \n",
      "[epoch:25, iter:1816] Loss: 0.498 | Accuracy: 99.609% \n",
      "[epoch:25, iter:1817] Loss: 0.497 | Accuracy: 99.632% \n",
      "[epoch:25, iter:1818] Loss: 0.497 | Accuracy: 99.653% \n",
      "[epoch:25, iter:1819] Loss: 0.496 | Accuracy: 99.671% \n",
      "[epoch:25, iter:1820] Loss: 0.496 | Accuracy: 99.688% \n",
      "[epoch:25, iter:1821] Loss: 0.496 | Accuracy: 99.702% \n",
      "[epoch:25, iter:1822] Loss: 0.496 | Accuracy: 99.716% \n",
      "[epoch:25, iter:1823] Loss: 0.495 | Accuracy: 99.728% \n",
      "[epoch:25, iter:1824] Loss: 0.495 | Accuracy: 99.740% \n",
      "[epoch:25, iter:1825] Loss: 0.497 | Accuracy: 99.500% \n",
      "[epoch:25, iter:1826] Loss: 0.497 | Accuracy: 99.519% \n",
      "[epoch:25, iter:1827] Loss: 0.496 | Accuracy: 99.537% \n",
      "[epoch:25, iter:1828] Loss: 0.496 | Accuracy: 99.554% \n",
      "[epoch:25, iter:1829] Loss: 0.496 | Accuracy: 99.569% \n",
      "[epoch:25, iter:1830] Loss: 0.496 | Accuracy: 99.583% \n",
      "[epoch:25, iter:1831] Loss: 0.495 | Accuracy: 99.597% \n",
      "[epoch:25, iter:1832] Loss: 0.495 | Accuracy: 99.609% \n",
      "[epoch:25, iter:1833] Loss: 0.495 | Accuracy: 99.621% \n",
      "[epoch:25, iter:1834] Loss: 0.495 | Accuracy: 99.632% \n",
      "[epoch:25, iter:1835] Loss: 0.495 | Accuracy: 99.643% \n",
      "[epoch:25, iter:1836] Loss: 0.495 | Accuracy: 99.566% \n",
      "[epoch:25, iter:1837] Loss: 0.495 | Accuracy: 99.578% \n",
      "[epoch:25, iter:1838] Loss: 0.495 | Accuracy: 99.589% \n",
      "[epoch:25, iter:1839] Loss: 0.495 | Accuracy: 99.599% \n",
      "[epoch:25, iter:1840] Loss: 0.495 | Accuracy: 99.609% \n",
      "[epoch:25, iter:1841] Loss: 0.495 | Accuracy: 99.619% \n",
      "[epoch:25, iter:1842] Loss: 0.495 | Accuracy: 99.628% \n",
      "[epoch:25, iter:1843] Loss: 0.494 | Accuracy: 99.637% \n",
      "[epoch:25, iter:1844] Loss: 0.494 | Accuracy: 99.645% \n",
      "[epoch:25, iter:1845] Loss: 0.494 | Accuracy: 99.653% \n",
      "[epoch:25, iter:1846] Loss: 0.495 | Accuracy: 99.592% \n",
      "[epoch:25, iter:1847] Loss: 0.495 | Accuracy: 99.601% \n",
      "[epoch:25, iter:1848] Loss: 0.495 | Accuracy: 99.609% \n",
      "[epoch:25, iter:1849] Loss: 0.495 | Accuracy: 99.617% \n",
      "[epoch:25, iter:1850] Loss: 0.495 | Accuracy: 99.625% \n",
      "[epoch:25, iter:1851] Loss: 0.495 | Accuracy: 99.632% \n",
      "[epoch:25, iter:1852] Loss: 0.495 | Accuracy: 99.639% \n",
      "[epoch:25, iter:1853] Loss: 0.495 | Accuracy: 99.646% \n",
      "[epoch:25, iter:1854] Loss: 0.494 | Accuracy: 99.653% \n",
      "[epoch:25, iter:1855] Loss: 0.494 | Accuracy: 99.659% \n",
      "[epoch:25, iter:1856] Loss: 0.494 | Accuracy: 99.665% \n",
      "[epoch:25, iter:1857] Loss: 0.494 | Accuracy: 99.671% \n",
      "[epoch:25, iter:1858] Loss: 0.494 | Accuracy: 99.677% \n",
      "[epoch:25, iter:1859] Loss: 0.494 | Accuracy: 99.682% \n",
      "[epoch:25, iter:1860] Loss: 0.494 | Accuracy: 99.688% \n",
      "[epoch:25, iter:1861] Loss: 0.494 | Accuracy: 99.693% \n",
      "[epoch:25, iter:1862] Loss: 0.494 | Accuracy: 99.698% \n",
      "[epoch:25, iter:1863] Loss: 0.494 | Accuracy: 99.702% \n",
      "[epoch:25, iter:1864] Loss: 0.494 | Accuracy: 99.707% \n",
      "[epoch:25, iter:1865] Loss: 0.494 | Accuracy: 99.712% \n",
      "[epoch:25, iter:1866] Loss: 0.493 | Accuracy: 99.716% \n",
      "[epoch:25, iter:1867] Loss: 0.493 | Accuracy: 99.720% \n",
      "[epoch:25, iter:1868] Loss: 0.493 | Accuracy: 99.724% \n",
      "[epoch:25, iter:1869] Loss: 0.493 | Accuracy: 99.728% \n",
      "[epoch:25, iter:1870] Loss: 0.493 | Accuracy: 99.732% \n",
      "[epoch:25, iter:1871] Loss: 0.493 | Accuracy: 99.736% \n",
      "[epoch:25, iter:1872] Loss: 0.493 | Accuracy: 99.740% \n",
      "[epoch:25, iter:1873] Loss: 0.493 | Accuracy: 99.743% \n",
      "[epoch:25, iter:1874] Loss: 0.493 | Accuracy: 99.747% \n",
      "[epoch:25, iter:1875] Loss: 0.494 | Accuracy: 99.747% \n",
      "Waiting Test!\n",
      "EPOCH=025, Loss: 0.647, Accuracy= 94.079%\n",
      "Epoch 00025: reducing learning rate of group 0 to 1.4700e-04.\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "\n",
      "Epoch: 26\n",
      "[epoch:26, iter:1876] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1877] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1878] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1879] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1880] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1881] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:26, iter:1882] Loss: 0.493 | Accuracy: 99.554% \n",
      "[epoch:26, iter:1883] Loss: 0.493 | Accuracy: 99.609% \n",
      "[epoch:26, iter:1884] Loss: 0.493 | Accuracy: 99.653% \n",
      "[epoch:26, iter:1885] Loss: 0.492 | Accuracy: 99.688% \n",
      "[epoch:26, iter:1886] Loss: 0.492 | Accuracy: 99.716% \n",
      "[epoch:26, iter:1887] Loss: 0.492 | Accuracy: 99.740% \n",
      "[epoch:26, iter:1888] Loss: 0.491 | Accuracy: 99.760% \n",
      "[epoch:26, iter:1889] Loss: 0.491 | Accuracy: 99.777% \n",
      "[epoch:26, iter:1890] Loss: 0.491 | Accuracy: 99.792% \n",
      "[epoch:26, iter:1891] Loss: 0.491 | Accuracy: 99.805% \n",
      "[epoch:26, iter:1892] Loss: 0.491 | Accuracy: 99.816% \n",
      "[epoch:26, iter:1893] Loss: 0.491 | Accuracy: 99.826% \n",
      "[epoch:26, iter:1894] Loss: 0.491 | Accuracy: 99.836% \n",
      "[epoch:26, iter:1895] Loss: 0.491 | Accuracy: 99.844% \n",
      "[epoch:26, iter:1896] Loss: 0.491 | Accuracy: 99.851% \n",
      "[epoch:26, iter:1897] Loss: 0.491 | Accuracy: 99.858% \n",
      "[epoch:26, iter:1898] Loss: 0.491 | Accuracy: 99.864% \n",
      "[epoch:26, iter:1899] Loss: 0.491 | Accuracy: 99.870% \n",
      "[epoch:26, iter:1900] Loss: 0.491 | Accuracy: 99.875% \n",
      "[epoch:26, iter:1901] Loss: 0.491 | Accuracy: 99.880% \n",
      "[epoch:26, iter:1902] Loss: 0.490 | Accuracy: 99.884% \n",
      "[epoch:26, iter:1903] Loss: 0.490 | Accuracy: 99.888% \n",
      "[epoch:26, iter:1904] Loss: 0.490 | Accuracy: 99.892% \n",
      "[epoch:26, iter:1905] Loss: 0.490 | Accuracy: 99.896% \n",
      "[epoch:26, iter:1906] Loss: 0.490 | Accuracy: 99.899% \n",
      "[epoch:26, iter:1907] Loss: 0.490 | Accuracy: 99.902% \n",
      "[epoch:26, iter:1908] Loss: 0.490 | Accuracy: 99.905% \n",
      "[epoch:26, iter:1909] Loss: 0.490 | Accuracy: 99.908% \n",
      "[epoch:26, iter:1910] Loss: 0.490 | Accuracy: 99.911% \n",
      "[epoch:26, iter:1911] Loss: 0.490 | Accuracy: 99.913% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:26, iter:1912] Loss: 0.490 | Accuracy: 99.916% \n",
      "[epoch:26, iter:1913] Loss: 0.490 | Accuracy: 99.918% \n",
      "[epoch:26, iter:1914] Loss: 0.490 | Accuracy: 99.920% \n",
      "[epoch:26, iter:1915] Loss: 0.490 | Accuracy: 99.922% \n",
      "[epoch:26, iter:1916] Loss: 0.490 | Accuracy: 99.924% \n",
      "[epoch:26, iter:1917] Loss: 0.490 | Accuracy: 99.926% \n",
      "[epoch:26, iter:1918] Loss: 0.490 | Accuracy: 99.927% \n",
      "[epoch:26, iter:1919] Loss: 0.490 | Accuracy: 99.929% \n",
      "[epoch:26, iter:1920] Loss: 0.490 | Accuracy: 99.931% \n",
      "[epoch:26, iter:1921] Loss: 0.490 | Accuracy: 99.932% \n",
      "[epoch:26, iter:1922] Loss: 0.490 | Accuracy: 99.934% \n",
      "[epoch:26, iter:1923] Loss: 0.490 | Accuracy: 99.935% \n",
      "[epoch:26, iter:1924] Loss: 0.490 | Accuracy: 99.936% \n",
      "[epoch:26, iter:1925] Loss: 0.490 | Accuracy: 99.938% \n",
      "[epoch:26, iter:1926] Loss: 0.490 | Accuracy: 99.939% \n",
      "[epoch:26, iter:1927] Loss: 0.490 | Accuracy: 99.940% \n",
      "[epoch:26, iter:1928] Loss: 0.490 | Accuracy: 99.941% \n",
      "[epoch:26, iter:1929] Loss: 0.490 | Accuracy: 99.942% \n",
      "[epoch:26, iter:1930] Loss: 0.490 | Accuracy: 99.943% \n",
      "[epoch:26, iter:1931] Loss: 0.490 | Accuracy: 99.944% \n",
      "[epoch:26, iter:1932] Loss: 0.490 | Accuracy: 99.945% \n",
      "[epoch:26, iter:1933] Loss: 0.490 | Accuracy: 99.946% \n",
      "[epoch:26, iter:1934] Loss: 0.490 | Accuracy: 99.947% \n",
      "[epoch:26, iter:1935] Loss: 0.490 | Accuracy: 99.948% \n",
      "[epoch:26, iter:1936] Loss: 0.489 | Accuracy: 99.949% \n",
      "[epoch:26, iter:1937] Loss: 0.489 | Accuracy: 99.950% \n",
      "[epoch:26, iter:1938] Loss: 0.489 | Accuracy: 99.950% \n",
      "[epoch:26, iter:1939] Loss: 0.489 | Accuracy: 99.951% \n",
      "[epoch:26, iter:1940] Loss: 0.489 | Accuracy: 99.952% \n",
      "[epoch:26, iter:1941] Loss: 0.489 | Accuracy: 99.953% \n",
      "[epoch:26, iter:1942] Loss: 0.489 | Accuracy: 99.953% \n",
      "[epoch:26, iter:1943] Loss: 0.489 | Accuracy: 99.954% \n",
      "[epoch:26, iter:1944] Loss: 0.489 | Accuracy: 99.955% \n",
      "[epoch:26, iter:1945] Loss: 0.489 | Accuracy: 99.955% \n",
      "[epoch:26, iter:1946] Loss: 0.489 | Accuracy: 99.956% \n",
      "[epoch:26, iter:1947] Loss: 0.489 | Accuracy: 99.957% \n",
      "[epoch:26, iter:1948] Loss: 0.489 | Accuracy: 99.957% \n",
      "[epoch:26, iter:1949] Loss: 0.489 | Accuracy: 99.958% \n",
      "[epoch:26, iter:1950] Loss: 0.492 | Accuracy: 99.958% \n",
      "Waiting Test!\n",
      "EPOCH=026, Loss: 0.656, Accuracy= 95.395%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 5 out of 30\n",
      "\n",
      "Epoch: 27\n",
      "[epoch:27, iter:1951] Loss: 0.501 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1952] Loss: 0.498 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1953] Loss: 0.499 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1954] Loss: 0.497 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1955] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1956] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1957] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1958] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1959] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1960] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1961] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1962] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1963] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1964] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1965] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1966] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1967] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1968] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1969] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1970] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1971] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1972] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1973] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1974] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1975] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1976] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1977] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1978] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1979] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1980] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1981] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1982] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1983] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1984] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1985] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1986] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1987] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1988] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1989] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1990] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1991] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1992] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1993] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1994] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1995] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1996] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1997] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1998] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:1999] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2000] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2001] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2002] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2003] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2004] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2005] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2006] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2007] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2008] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2009] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2010] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:27, iter:2011] Loss: 0.490 | Accuracy: 99.949% \n",
      "[epoch:27, iter:2012] Loss: 0.490 | Accuracy: 99.950% \n",
      "[epoch:27, iter:2013] Loss: 0.490 | Accuracy: 99.950% \n",
      "[epoch:27, iter:2014] Loss: 0.491 | Accuracy: 99.902% \n",
      "[epoch:27, iter:2015] Loss: 0.491 | Accuracy: 99.904% \n",
      "[epoch:27, iter:2016] Loss: 0.491 | Accuracy: 99.905% \n",
      "[epoch:27, iter:2017] Loss: 0.491 | Accuracy: 99.907% \n",
      "[epoch:27, iter:2018] Loss: 0.491 | Accuracy: 99.908% \n",
      "[epoch:27, iter:2019] Loss: 0.491 | Accuracy: 99.909% \n",
      "[epoch:27, iter:2020] Loss: 0.491 | Accuracy: 99.911% \n",
      "[epoch:27, iter:2021] Loss: 0.491 | Accuracy: 99.912% \n",
      "[epoch:27, iter:2022] Loss: 0.491 | Accuracy: 99.913% \n",
      "[epoch:27, iter:2023] Loss: 0.491 | Accuracy: 99.914% \n",
      "[epoch:27, iter:2024] Loss: 0.491 | Accuracy: 99.916% \n",
      "[epoch:27, iter:2025] Loss: 0.522 | Accuracy: 99.873% \n",
      "Waiting Test!\n",
      "EPOCH=027, Loss: 0.678, Accuracy= 93.750%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 6 out of 30\n",
      "\n",
      "Epoch: 28\n",
      "[epoch:28, iter:2026] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2027] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2028] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2029] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2030] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2031] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2032] Loss: 0.496 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2033] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2034] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2035] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2036] Loss: 0.495 | Accuracy: 100.000% \n",
      "[epoch:28, iter:2037] Loss: 0.499 | Accuracy: 99.740% \n",
      "[epoch:28, iter:2038] Loss: 0.499 | Accuracy: 99.760% \n",
      "[epoch:28, iter:2039] Loss: 0.498 | Accuracy: 99.777% \n",
      "[epoch:28, iter:2040] Loss: 0.498 | Accuracy: 99.792% \n",
      "[epoch:28, iter:2041] Loss: 0.498 | Accuracy: 99.805% \n",
      "[epoch:28, iter:2042] Loss: 0.498 | Accuracy: 99.816% \n",
      "[epoch:28, iter:2043] Loss: 0.497 | Accuracy: 99.826% \n",
      "[epoch:28, iter:2044] Loss: 0.497 | Accuracy: 99.836% \n",
      "[epoch:28, iter:2045] Loss: 0.500 | Accuracy: 99.688% \n",
      "[epoch:28, iter:2046] Loss: 0.499 | Accuracy: 99.702% \n",
      "[epoch:28, iter:2047] Loss: 0.499 | Accuracy: 99.716% \n",
      "[epoch:28, iter:2048] Loss: 0.499 | Accuracy: 99.728% \n",
      "[epoch:28, iter:2049] Loss: 0.498 | Accuracy: 99.740% \n",
      "[epoch:28, iter:2050] Loss: 0.498 | Accuracy: 99.750% \n",
      "[epoch:28, iter:2051] Loss: 0.499 | Accuracy: 99.639% \n",
      "[epoch:28, iter:2052] Loss: 0.499 | Accuracy: 99.653% \n",
      "[epoch:28, iter:2053] Loss: 0.499 | Accuracy: 99.665% \n",
      "[epoch:28, iter:2054] Loss: 0.499 | Accuracy: 99.677% \n",
      "[epoch:28, iter:2055] Loss: 0.502 | Accuracy: 99.583% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:28, iter:2056] Loss: 0.502 | Accuracy: 99.597% \n",
      "[epoch:28, iter:2057] Loss: 0.501 | Accuracy: 99.609% \n",
      "[epoch:28, iter:2058] Loss: 0.501 | Accuracy: 99.621% \n",
      "[epoch:28, iter:2059] Loss: 0.501 | Accuracy: 99.632% \n",
      "[epoch:28, iter:2060] Loss: 0.500 | Accuracy: 99.643% \n",
      "[epoch:28, iter:2061] Loss: 0.500 | Accuracy: 99.653% \n",
      "[epoch:28, iter:2062] Loss: 0.500 | Accuracy: 99.662% \n",
      "[epoch:28, iter:2063] Loss: 0.499 | Accuracy: 99.671% \n",
      "[epoch:28, iter:2064] Loss: 0.499 | Accuracy: 99.679% \n",
      "[epoch:28, iter:2065] Loss: 0.499 | Accuracy: 99.688% \n",
      "[epoch:28, iter:2066] Loss: 0.499 | Accuracy: 99.695% \n",
      "[epoch:28, iter:2067] Loss: 0.499 | Accuracy: 99.702% \n",
      "[epoch:28, iter:2068] Loss: 0.498 | Accuracy: 99.709% \n",
      "[epoch:28, iter:2069] Loss: 0.498 | Accuracy: 99.716% \n",
      "[epoch:28, iter:2070] Loss: 0.498 | Accuracy: 99.722% \n",
      "[epoch:28, iter:2071] Loss: 0.498 | Accuracy: 99.728% \n",
      "[epoch:28, iter:2072] Loss: 0.498 | Accuracy: 99.734% \n",
      "[epoch:28, iter:2073] Loss: 0.498 | Accuracy: 99.740% \n",
      "[epoch:28, iter:2074] Loss: 0.498 | Accuracy: 99.745% \n",
      "[epoch:28, iter:2075] Loss: 0.497 | Accuracy: 99.750% \n",
      "[epoch:28, iter:2076] Loss: 0.497 | Accuracy: 99.755% \n",
      "[epoch:28, iter:2077] Loss: 0.497 | Accuracy: 99.760% \n",
      "[epoch:28, iter:2078] Loss: 0.497 | Accuracy: 99.764% \n",
      "[epoch:28, iter:2079] Loss: 0.497 | Accuracy: 99.769% \n",
      "[epoch:28, iter:2080] Loss: 0.497 | Accuracy: 99.773% \n",
      "[epoch:28, iter:2081] Loss: 0.497 | Accuracy: 99.777% \n",
      "[epoch:28, iter:2082] Loss: 0.496 | Accuracy: 99.781% \n",
      "[epoch:28, iter:2083] Loss: 0.496 | Accuracy: 99.784% \n",
      "[epoch:28, iter:2084] Loss: 0.496 | Accuracy: 99.788% \n",
      "[epoch:28, iter:2085] Loss: 0.496 | Accuracy: 99.792% \n",
      "[epoch:28, iter:2086] Loss: 0.496 | Accuracy: 99.795% \n",
      "[epoch:28, iter:2087] Loss: 0.496 | Accuracy: 99.798% \n",
      "[epoch:28, iter:2088] Loss: 0.496 | Accuracy: 99.802% \n",
      "[epoch:28, iter:2089] Loss: 0.496 | Accuracy: 99.805% \n",
      "[epoch:28, iter:2090] Loss: 0.496 | Accuracy: 99.808% \n",
      "[epoch:28, iter:2091] Loss: 0.495 | Accuracy: 99.811% \n",
      "[epoch:28, iter:2092] Loss: 0.495 | Accuracy: 99.813% \n",
      "[epoch:28, iter:2093] Loss: 0.496 | Accuracy: 99.770% \n",
      "[epoch:28, iter:2094] Loss: 0.496 | Accuracy: 99.774% \n",
      "[epoch:28, iter:2095] Loss: 0.496 | Accuracy: 99.777% \n",
      "[epoch:28, iter:2096] Loss: 0.496 | Accuracy: 99.780% \n",
      "[epoch:28, iter:2097] Loss: 0.496 | Accuracy: 99.783% \n",
      "[epoch:28, iter:2098] Loss: 0.496 | Accuracy: 99.786% \n",
      "[epoch:28, iter:2099] Loss: 0.496 | Accuracy: 99.789% \n",
      "[epoch:28, iter:2100] Loss: 0.496 | Accuracy: 99.789% \n",
      "Waiting Test!\n",
      "EPOCH=028, Loss: 0.661, Accuracy= 93.750%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 7 out of 30\n",
      "\n",
      "Epoch: 29\n",
      "[epoch:29, iter:2101] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2102] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2103] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2104] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2105] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2106] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2107] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2108] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2109] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2110] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2111] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2112] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2113] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2114] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2115] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2116] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2117] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2118] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2119] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2120] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2121] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2122] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2123] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2124] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2125] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2126] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2127] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:29, iter:2128] Loss: 0.490 | Accuracy: 99.888% \n",
      "[epoch:29, iter:2129] Loss: 0.490 | Accuracy: 99.892% \n",
      "[epoch:29, iter:2130] Loss: 0.490 | Accuracy: 99.896% \n",
      "[epoch:29, iter:2131] Loss: 0.490 | Accuracy: 99.899% \n",
      "[epoch:29, iter:2132] Loss: 0.490 | Accuracy: 99.902% \n",
      "[epoch:29, iter:2133] Loss: 0.490 | Accuracy: 99.905% \n",
      "[epoch:29, iter:2134] Loss: 0.490 | Accuracy: 99.908% \n",
      "[epoch:29, iter:2135] Loss: 0.490 | Accuracy: 99.911% \n",
      "[epoch:29, iter:2136] Loss: 0.490 | Accuracy: 99.913% \n",
      "[epoch:29, iter:2137] Loss: 0.490 | Accuracy: 99.916% \n",
      "[epoch:29, iter:2138] Loss: 0.490 | Accuracy: 99.918% \n",
      "[epoch:29, iter:2139] Loss: 0.490 | Accuracy: 99.920% \n",
      "[epoch:29, iter:2140] Loss: 0.490 | Accuracy: 99.922% \n",
      "[epoch:29, iter:2141] Loss: 0.490 | Accuracy: 99.924% \n",
      "[epoch:29, iter:2142] Loss: 0.492 | Accuracy: 99.851% \n",
      "[epoch:29, iter:2143] Loss: 0.492 | Accuracy: 99.855% \n",
      "[epoch:29, iter:2144] Loss: 0.492 | Accuracy: 99.858% \n",
      "[epoch:29, iter:2145] Loss: 0.491 | Accuracy: 99.861% \n",
      "[epoch:29, iter:2146] Loss: 0.491 | Accuracy: 99.864% \n",
      "[epoch:29, iter:2147] Loss: 0.491 | Accuracy: 99.867% \n",
      "[epoch:29, iter:2148] Loss: 0.491 | Accuracy: 99.870% \n",
      "[epoch:29, iter:2149] Loss: 0.491 | Accuracy: 99.872% \n",
      "[epoch:29, iter:2150] Loss: 0.491 | Accuracy: 99.875% \n",
      "[epoch:29, iter:2151] Loss: 0.491 | Accuracy: 99.877% \n",
      "[epoch:29, iter:2152] Loss: 0.491 | Accuracy: 99.880% \n",
      "[epoch:29, iter:2153] Loss: 0.491 | Accuracy: 99.882% \n",
      "[epoch:29, iter:2154] Loss: 0.491 | Accuracy: 99.884% \n",
      "[epoch:29, iter:2155] Loss: 0.491 | Accuracy: 99.886% \n",
      "[epoch:29, iter:2156] Loss: 0.491 | Accuracy: 99.888% \n",
      "[epoch:29, iter:2157] Loss: 0.491 | Accuracy: 99.890% \n",
      "[epoch:29, iter:2158] Loss: 0.491 | Accuracy: 99.892% \n",
      "[epoch:29, iter:2159] Loss: 0.491 | Accuracy: 99.894% \n",
      "[epoch:29, iter:2160] Loss: 0.491 | Accuracy: 99.896% \n",
      "[epoch:29, iter:2161] Loss: 0.491 | Accuracy: 99.898% \n",
      "[epoch:29, iter:2162] Loss: 0.491 | Accuracy: 99.899% \n",
      "[epoch:29, iter:2163] Loss: 0.491 | Accuracy: 99.901% \n",
      "[epoch:29, iter:2164] Loss: 0.491 | Accuracy: 99.902% \n",
      "[epoch:29, iter:2165] Loss: 0.491 | Accuracy: 99.904% \n",
      "[epoch:29, iter:2166] Loss: 0.491 | Accuracy: 99.905% \n",
      "[epoch:29, iter:2167] Loss: 0.491 | Accuracy: 99.907% \n",
      "[epoch:29, iter:2168] Loss: 0.491 | Accuracy: 99.908% \n",
      "[epoch:29, iter:2169] Loss: 0.491 | Accuracy: 99.909% \n",
      "[epoch:29, iter:2170] Loss: 0.491 | Accuracy: 99.911% \n",
      "[epoch:29, iter:2171] Loss: 0.491 | Accuracy: 99.912% \n",
      "[epoch:29, iter:2172] Loss: 0.491 | Accuracy: 99.913% \n",
      "[epoch:29, iter:2173] Loss: 0.491 | Accuracy: 99.914% \n",
      "[epoch:29, iter:2174] Loss: 0.491 | Accuracy: 99.916% \n",
      "[epoch:29, iter:2175] Loss: 0.493 | Accuracy: 99.916% \n",
      "Waiting Test!\n",
      "EPOCH=029, Loss: 0.661, Accuracy= 95.066%\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0290e-04.\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 8 out of 30\n",
      "\n",
      "Epoch: 30\n",
      "[epoch:30, iter:2176] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2177] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2178] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2179] Loss: 0.494 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2180] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2181] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2182] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2183] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2184] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2185] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2186] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2187] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2188] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2189] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2190] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2191] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2192] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2193] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2194] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2195] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2196] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2197] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2198] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2199] Loss: 0.490 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:30, iter:2200] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2201] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2202] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2203] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2204] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2205] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2206] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2207] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2208] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2209] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2210] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2211] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2212] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2213] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2214] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2215] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2216] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2217] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2218] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2219] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2220] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2221] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2222] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2223] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2224] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2225] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2226] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2227] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2228] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2229] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2230] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2231] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2232] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2233] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2234] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2235] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2236] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2237] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2238] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2239] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2240] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2241] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2242] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2243] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2244] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2245] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2246] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2247] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2248] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2249] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:30, iter:2250] Loss: 0.489 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=030, Loss: 0.665, Accuracy= 94.737%\n",
      "Training complete in 0m 12s\n",
      "EarlyStopping counter: 9 out of 30\n",
      "\n",
      "Epoch: 31\n",
      "[epoch:31, iter:2251] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2252] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2253] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2254] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2255] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2256] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2257] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2258] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2259] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2260] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2261] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2262] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2263] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2264] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2265] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2266] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2267] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2268] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2269] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2270] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2271] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2272] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2273] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2274] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:31, iter:2275] Loss: 0.490 | Accuracy: 99.875% \n",
      "[epoch:31, iter:2276] Loss: 0.490 | Accuracy: 99.880% \n",
      "[epoch:31, iter:2277] Loss: 0.490 | Accuracy: 99.884% \n",
      "[epoch:31, iter:2278] Loss: 0.489 | Accuracy: 99.888% \n",
      "[epoch:31, iter:2279] Loss: 0.489 | Accuracy: 99.892% \n",
      "[epoch:31, iter:2280] Loss: 0.489 | Accuracy: 99.896% \n",
      "[epoch:31, iter:2281] Loss: 0.489 | Accuracy: 99.899% \n",
      "[epoch:31, iter:2282] Loss: 0.489 | Accuracy: 99.902% \n",
      "[epoch:31, iter:2283] Loss: 0.489 | Accuracy: 99.905% \n",
      "[epoch:31, iter:2284] Loss: 0.489 | Accuracy: 99.908% \n",
      "[epoch:31, iter:2285] Loss: 0.489 | Accuracy: 99.911% \n",
      "[epoch:31, iter:2286] Loss: 0.489 | Accuracy: 99.913% \n",
      "[epoch:31, iter:2287] Loss: 0.489 | Accuracy: 99.916% \n",
      "[epoch:31, iter:2288] Loss: 0.489 | Accuracy: 99.918% \n",
      "[epoch:31, iter:2289] Loss: 0.489 | Accuracy: 99.920% \n",
      "[epoch:31, iter:2290] Loss: 0.489 | Accuracy: 99.922% \n",
      "[epoch:31, iter:2291] Loss: 0.489 | Accuracy: 99.924% \n",
      "[epoch:31, iter:2292] Loss: 0.490 | Accuracy: 99.851% \n",
      "[epoch:31, iter:2293] Loss: 0.490 | Accuracy: 99.855% \n",
      "[epoch:31, iter:2294] Loss: 0.490 | Accuracy: 99.858% \n",
      "[epoch:31, iter:2295] Loss: 0.489 | Accuracy: 99.861% \n",
      "[epoch:31, iter:2296] Loss: 0.489 | Accuracy: 99.864% \n",
      "[epoch:31, iter:2297] Loss: 0.489 | Accuracy: 99.867% \n",
      "[epoch:31, iter:2298] Loss: 0.489 | Accuracy: 99.870% \n",
      "[epoch:31, iter:2299] Loss: 0.489 | Accuracy: 99.872% \n",
      "[epoch:31, iter:2300] Loss: 0.489 | Accuracy: 99.875% \n",
      "[epoch:31, iter:2301] Loss: 0.489 | Accuracy: 99.877% \n",
      "[epoch:31, iter:2302] Loss: 0.489 | Accuracy: 99.880% \n",
      "[epoch:31, iter:2303] Loss: 0.489 | Accuracy: 99.882% \n",
      "[epoch:31, iter:2304] Loss: 0.489 | Accuracy: 99.884% \n",
      "[epoch:31, iter:2305] Loss: 0.489 | Accuracy: 99.886% \n",
      "[epoch:31, iter:2306] Loss: 0.489 | Accuracy: 99.888% \n",
      "[epoch:31, iter:2307] Loss: 0.489 | Accuracy: 99.890% \n",
      "[epoch:31, iter:2308] Loss: 0.489 | Accuracy: 99.892% \n",
      "[epoch:31, iter:2309] Loss: 0.489 | Accuracy: 99.894% \n",
      "[epoch:31, iter:2310] Loss: 0.489 | Accuracy: 99.896% \n",
      "[epoch:31, iter:2311] Loss: 0.489 | Accuracy: 99.898% \n",
      "[epoch:31, iter:2312] Loss: 0.489 | Accuracy: 99.899% \n",
      "[epoch:31, iter:2313] Loss: 0.489 | Accuracy: 99.901% \n",
      "[epoch:31, iter:2314] Loss: 0.489 | Accuracy: 99.902% \n",
      "[epoch:31, iter:2315] Loss: 0.489 | Accuracy: 99.904% \n",
      "[epoch:31, iter:2316] Loss: 0.489 | Accuracy: 99.905% \n",
      "[epoch:31, iter:2317] Loss: 0.489 | Accuracy: 99.907% \n",
      "[epoch:31, iter:2318] Loss: 0.489 | Accuracy: 99.908% \n",
      "[epoch:31, iter:2319] Loss: 0.489 | Accuracy: 99.909% \n",
      "[epoch:31, iter:2320] Loss: 0.489 | Accuracy: 99.911% \n",
      "[epoch:31, iter:2321] Loss: 0.489 | Accuracy: 99.912% \n",
      "[epoch:31, iter:2322] Loss: 0.489 | Accuracy: 99.913% \n",
      "[epoch:31, iter:2323] Loss: 0.489 | Accuracy: 99.914% \n",
      "[epoch:31, iter:2324] Loss: 0.489 | Accuracy: 99.916% \n",
      "[epoch:31, iter:2325] Loss: 0.489 | Accuracy: 99.916% \n",
      "Waiting Test!\n",
      "EPOCH=031, Loss: 0.656, Accuracy= 94.737%\n",
      "Training complete in 0m 12s\n",
      "EarlyStopping counter: 10 out of 30\n",
      "\n",
      "Epoch: 32\n",
      "[epoch:32, iter:2326] Loss: 0.533 | Accuracy: 96.875% \n",
      "[epoch:32, iter:2327] Loss: 0.510 | Accuracy: 98.438% \n",
      "[epoch:32, iter:2328] Loss: 0.503 | Accuracy: 98.958% \n",
      "[epoch:32, iter:2329] Loss: 0.499 | Accuracy: 99.219% \n",
      "[epoch:32, iter:2330] Loss: 0.497 | Accuracy: 99.375% \n",
      "[epoch:32, iter:2331] Loss: 0.496 | Accuracy: 99.479% \n",
      "[epoch:32, iter:2332] Loss: 0.495 | Accuracy: 99.554% \n",
      "[epoch:32, iter:2333] Loss: 0.494 | Accuracy: 99.609% \n",
      "[epoch:32, iter:2334] Loss: 0.494 | Accuracy: 99.653% \n",
      "[epoch:32, iter:2335] Loss: 0.493 | Accuracy: 99.688% \n",
      "[epoch:32, iter:2336] Loss: 0.493 | Accuracy: 99.716% \n",
      "[epoch:32, iter:2337] Loss: 0.492 | Accuracy: 99.740% \n",
      "[epoch:32, iter:2338] Loss: 0.492 | Accuracy: 99.760% \n",
      "[epoch:32, iter:2339] Loss: 0.492 | Accuracy: 99.777% \n",
      "[epoch:32, iter:2340] Loss: 0.491 | Accuracy: 99.792% \n",
      "[epoch:32, iter:2341] Loss: 0.491 | Accuracy: 99.805% \n",
      "[epoch:32, iter:2342] Loss: 0.491 | Accuracy: 99.816% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:32, iter:2343] Loss: 0.491 | Accuracy: 99.826% \n",
      "[epoch:32, iter:2344] Loss: 0.491 | Accuracy: 99.836% \n",
      "[epoch:32, iter:2345] Loss: 0.491 | Accuracy: 99.844% \n",
      "[epoch:32, iter:2346] Loss: 0.491 | Accuracy: 99.851% \n",
      "[epoch:32, iter:2347] Loss: 0.491 | Accuracy: 99.858% \n",
      "[epoch:32, iter:2348] Loss: 0.490 | Accuracy: 99.864% \n",
      "[epoch:32, iter:2349] Loss: 0.490 | Accuracy: 99.870% \n",
      "[epoch:32, iter:2350] Loss: 0.490 | Accuracy: 99.875% \n",
      "[epoch:32, iter:2351] Loss: 0.490 | Accuracy: 99.880% \n",
      "[epoch:32, iter:2352] Loss: 0.490 | Accuracy: 99.884% \n",
      "[epoch:32, iter:2353] Loss: 0.490 | Accuracy: 99.888% \n",
      "[epoch:32, iter:2354] Loss: 0.490 | Accuracy: 99.892% \n",
      "[epoch:32, iter:2355] Loss: 0.490 | Accuracy: 99.896% \n",
      "[epoch:32, iter:2356] Loss: 0.490 | Accuracy: 99.899% \n",
      "[epoch:32, iter:2357] Loss: 0.490 | Accuracy: 99.902% \n",
      "[epoch:32, iter:2358] Loss: 0.490 | Accuracy: 99.905% \n",
      "[epoch:32, iter:2359] Loss: 0.490 | Accuracy: 99.908% \n",
      "[epoch:32, iter:2360] Loss: 0.490 | Accuracy: 99.911% \n",
      "[epoch:32, iter:2361] Loss: 0.490 | Accuracy: 99.913% \n",
      "[epoch:32, iter:2362] Loss: 0.490 | Accuracy: 99.916% \n",
      "[epoch:32, iter:2363] Loss: 0.489 | Accuracy: 99.918% \n",
      "[epoch:32, iter:2364] Loss: 0.489 | Accuracy: 99.920% \n",
      "[epoch:32, iter:2365] Loss: 0.489 | Accuracy: 99.922% \n",
      "[epoch:32, iter:2366] Loss: 0.489 | Accuracy: 99.924% \n",
      "[epoch:32, iter:2367] Loss: 0.489 | Accuracy: 99.926% \n",
      "[epoch:32, iter:2368] Loss: 0.489 | Accuracy: 99.927% \n",
      "[epoch:32, iter:2369] Loss: 0.489 | Accuracy: 99.929% \n",
      "[epoch:32, iter:2370] Loss: 0.489 | Accuracy: 99.931% \n",
      "[epoch:32, iter:2371] Loss: 0.489 | Accuracy: 99.932% \n",
      "[epoch:32, iter:2372] Loss: 0.489 | Accuracy: 99.934% \n",
      "[epoch:32, iter:2373] Loss: 0.489 | Accuracy: 99.935% \n",
      "[epoch:32, iter:2374] Loss: 0.489 | Accuracy: 99.936% \n",
      "[epoch:32, iter:2375] Loss: 0.489 | Accuracy: 99.938% \n",
      "[epoch:32, iter:2376] Loss: 0.489 | Accuracy: 99.939% \n",
      "[epoch:32, iter:2377] Loss: 0.489 | Accuracy: 99.940% \n",
      "[epoch:32, iter:2378] Loss: 0.489 | Accuracy: 99.941% \n",
      "[epoch:32, iter:2379] Loss: 0.489 | Accuracy: 99.942% \n",
      "[epoch:32, iter:2380] Loss: 0.489 | Accuracy: 99.943% \n",
      "[epoch:32, iter:2381] Loss: 0.489 | Accuracy: 99.944% \n",
      "[epoch:32, iter:2382] Loss: 0.489 | Accuracy: 99.945% \n",
      "[epoch:32, iter:2383] Loss: 0.489 | Accuracy: 99.946% \n",
      "[epoch:32, iter:2384] Loss: 0.489 | Accuracy: 99.947% \n",
      "[epoch:32, iter:2385] Loss: 0.489 | Accuracy: 99.948% \n",
      "[epoch:32, iter:2386] Loss: 0.489 | Accuracy: 99.949% \n",
      "[epoch:32, iter:2387] Loss: 0.489 | Accuracy: 99.950% \n",
      "[epoch:32, iter:2388] Loss: 0.489 | Accuracy: 99.950% \n",
      "[epoch:32, iter:2389] Loss: 0.489 | Accuracy: 99.951% \n",
      "[epoch:32, iter:2390] Loss: 0.489 | Accuracy: 99.952% \n",
      "[epoch:32, iter:2391] Loss: 0.489 | Accuracy: 99.953% \n",
      "[epoch:32, iter:2392] Loss: 0.489 | Accuracy: 99.953% \n",
      "[epoch:32, iter:2393] Loss: 0.489 | Accuracy: 99.954% \n",
      "[epoch:32, iter:2394] Loss: 0.489 | Accuracy: 99.955% \n",
      "[epoch:32, iter:2395] Loss: 0.489 | Accuracy: 99.955% \n",
      "[epoch:32, iter:2396] Loss: 0.489 | Accuracy: 99.956% \n",
      "[epoch:32, iter:2397] Loss: 0.489 | Accuracy: 99.957% \n",
      "[epoch:32, iter:2398] Loss: 0.489 | Accuracy: 99.957% \n",
      "[epoch:32, iter:2399] Loss: 0.489 | Accuracy: 99.958% \n",
      "[epoch:32, iter:2400] Loss: 0.491 | Accuracy: 99.958% \n",
      "Waiting Test!\n",
      "EPOCH=032, Loss: 0.650, Accuracy= 94.737%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 11 out of 30\n",
      "\n",
      "Epoch: 33\n",
      "[epoch:33, iter:2401] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2402] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2403] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2404] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2405] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2406] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2407] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2408] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2409] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2410] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2411] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2412] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2413] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2414] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:33, iter:2415] Loss: 0.494 | Accuracy: 99.792% \n",
      "[epoch:33, iter:2416] Loss: 0.493 | Accuracy: 99.805% \n",
      "[epoch:33, iter:2417] Loss: 0.493 | Accuracy: 99.816% \n",
      "[epoch:33, iter:2418] Loss: 0.493 | Accuracy: 99.826% \n",
      "[epoch:33, iter:2419] Loss: 0.493 | Accuracy: 99.836% \n",
      "[epoch:33, iter:2420] Loss: 0.493 | Accuracy: 99.844% \n",
      "[epoch:33, iter:2421] Loss: 0.493 | Accuracy: 99.851% \n",
      "[epoch:33, iter:2422] Loss: 0.493 | Accuracy: 99.858% \n",
      "[epoch:33, iter:2423] Loss: 0.493 | Accuracy: 99.864% \n",
      "[epoch:33, iter:2424] Loss: 0.493 | Accuracy: 99.870% \n",
      "[epoch:33, iter:2425] Loss: 0.492 | Accuracy: 99.875% \n",
      "[epoch:33, iter:2426] Loss: 0.492 | Accuracy: 99.880% \n",
      "[epoch:33, iter:2427] Loss: 0.492 | Accuracy: 99.884% \n",
      "[epoch:33, iter:2428] Loss: 0.492 | Accuracy: 99.888% \n",
      "[epoch:33, iter:2429] Loss: 0.492 | Accuracy: 99.892% \n",
      "[epoch:33, iter:2430] Loss: 0.492 | Accuracy: 99.896% \n",
      "[epoch:33, iter:2431] Loss: 0.492 | Accuracy: 99.899% \n",
      "[epoch:33, iter:2432] Loss: 0.491 | Accuracy: 99.902% \n",
      "[epoch:33, iter:2433] Loss: 0.491 | Accuracy: 99.905% \n",
      "[epoch:33, iter:2434] Loss: 0.491 | Accuracy: 99.908% \n",
      "[epoch:33, iter:2435] Loss: 0.491 | Accuracy: 99.911% \n",
      "[epoch:33, iter:2436] Loss: 0.491 | Accuracy: 99.913% \n",
      "[epoch:33, iter:2437] Loss: 0.491 | Accuracy: 99.916% \n",
      "[epoch:33, iter:2438] Loss: 0.491 | Accuracy: 99.918% \n",
      "[epoch:33, iter:2439] Loss: 0.491 | Accuracy: 99.920% \n",
      "[epoch:33, iter:2440] Loss: 0.491 | Accuracy: 99.922% \n",
      "[epoch:33, iter:2441] Loss: 0.491 | Accuracy: 99.924% \n",
      "[epoch:33, iter:2442] Loss: 0.491 | Accuracy: 99.926% \n",
      "[epoch:33, iter:2443] Loss: 0.490 | Accuracy: 99.927% \n",
      "[epoch:33, iter:2444] Loss: 0.490 | Accuracy: 99.929% \n",
      "[epoch:33, iter:2445] Loss: 0.490 | Accuracy: 99.931% \n",
      "[epoch:33, iter:2446] Loss: 0.490 | Accuracy: 99.932% \n",
      "[epoch:33, iter:2447] Loss: 0.490 | Accuracy: 99.934% \n",
      "[epoch:33, iter:2448] Loss: 0.490 | Accuracy: 99.935% \n",
      "[epoch:33, iter:2449] Loss: 0.490 | Accuracy: 99.936% \n",
      "[epoch:33, iter:2450] Loss: 0.490 | Accuracy: 99.938% \n",
      "[epoch:33, iter:2451] Loss: 0.490 | Accuracy: 99.939% \n",
      "[epoch:33, iter:2452] Loss: 0.490 | Accuracy: 99.940% \n",
      "[epoch:33, iter:2453] Loss: 0.490 | Accuracy: 99.941% \n",
      "[epoch:33, iter:2454] Loss: 0.490 | Accuracy: 99.942% \n",
      "[epoch:33, iter:2455] Loss: 0.490 | Accuracy: 99.943% \n",
      "[epoch:33, iter:2456] Loss: 0.490 | Accuracy: 99.944% \n",
      "[epoch:33, iter:2457] Loss: 0.490 | Accuracy: 99.945% \n",
      "[epoch:33, iter:2458] Loss: 0.490 | Accuracy: 99.946% \n",
      "[epoch:33, iter:2459] Loss: 0.490 | Accuracy: 99.947% \n",
      "[epoch:33, iter:2460] Loss: 0.490 | Accuracy: 99.948% \n",
      "[epoch:33, iter:2461] Loss: 0.490 | Accuracy: 99.949% \n",
      "[epoch:33, iter:2462] Loss: 0.490 | Accuracy: 99.950% \n",
      "[epoch:33, iter:2463] Loss: 0.490 | Accuracy: 99.950% \n",
      "[epoch:33, iter:2464] Loss: 0.490 | Accuracy: 99.951% \n",
      "[epoch:33, iter:2465] Loss: 0.490 | Accuracy: 99.952% \n",
      "[epoch:33, iter:2466] Loss: 0.490 | Accuracy: 99.953% \n",
      "[epoch:33, iter:2467] Loss: 0.490 | Accuracy: 99.953% \n",
      "[epoch:33, iter:2468] Loss: 0.490 | Accuracy: 99.908% \n",
      "[epoch:33, iter:2469] Loss: 0.490 | Accuracy: 99.909% \n",
      "[epoch:33, iter:2470] Loss: 0.490 | Accuracy: 99.911% \n",
      "[epoch:33, iter:2471] Loss: 0.490 | Accuracy: 99.912% \n",
      "[epoch:33, iter:2472] Loss: 0.490 | Accuracy: 99.913% \n",
      "[epoch:33, iter:2473] Loss: 0.490 | Accuracy: 99.914% \n",
      "[epoch:33, iter:2474] Loss: 0.490 | Accuracy: 99.916% \n",
      "[epoch:33, iter:2475] Loss: 0.496 | Accuracy: 99.916% \n",
      "Waiting Test!\n",
      "EPOCH=033, Loss: 0.637, Accuracy= 94.737%\n",
      "Epoch 00033: reducing learning rate of group 0 to 7.2030e-05.\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 12 out of 30\n",
      "\n",
      "Epoch: 34\n",
      "[epoch:34, iter:2476] Loss: 0.493 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2477] Loss: 0.492 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2478] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2479] Loss: 0.491 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2480] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2481] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2482] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2483] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:34, iter:2484] Loss: 0.493 | Accuracy: 99.653% \n",
      "[epoch:34, iter:2485] Loss: 0.493 | Accuracy: 99.688% \n",
      "[epoch:34, iter:2486] Loss: 0.493 | Accuracy: 99.716% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:34, iter:2487] Loss: 0.493 | Accuracy: 99.740% \n",
      "[epoch:34, iter:2488] Loss: 0.492 | Accuracy: 99.760% \n",
      "[epoch:34, iter:2489] Loss: 0.492 | Accuracy: 99.777% \n",
      "[epoch:34, iter:2490] Loss: 0.492 | Accuracy: 99.792% \n",
      "[epoch:34, iter:2491] Loss: 0.492 | Accuracy: 99.805% \n",
      "[epoch:34, iter:2492] Loss: 0.491 | Accuracy: 99.816% \n",
      "[epoch:34, iter:2493] Loss: 0.491 | Accuracy: 99.826% \n",
      "[epoch:34, iter:2494] Loss: 0.491 | Accuracy: 99.836% \n",
      "[epoch:34, iter:2495] Loss: 0.491 | Accuracy: 99.844% \n",
      "[epoch:34, iter:2496] Loss: 0.491 | Accuracy: 99.851% \n",
      "[epoch:34, iter:2497] Loss: 0.491 | Accuracy: 99.858% \n",
      "[epoch:34, iter:2498] Loss: 0.491 | Accuracy: 99.864% \n",
      "[epoch:34, iter:2499] Loss: 0.491 | Accuracy: 99.870% \n",
      "[epoch:34, iter:2500] Loss: 0.491 | Accuracy: 99.875% \n",
      "[epoch:34, iter:2501] Loss: 0.491 | Accuracy: 99.880% \n",
      "[epoch:34, iter:2502] Loss: 0.491 | Accuracy: 99.884% \n",
      "[epoch:34, iter:2503] Loss: 0.490 | Accuracy: 99.888% \n",
      "[epoch:34, iter:2504] Loss: 0.491 | Accuracy: 99.892% \n",
      "[epoch:34, iter:2505] Loss: 0.490 | Accuracy: 99.896% \n",
      "[epoch:34, iter:2506] Loss: 0.490 | Accuracy: 99.899% \n",
      "[epoch:34, iter:2507] Loss: 0.490 | Accuracy: 99.902% \n",
      "[epoch:34, iter:2508] Loss: 0.490 | Accuracy: 99.905% \n",
      "[epoch:34, iter:2509] Loss: 0.490 | Accuracy: 99.908% \n",
      "[epoch:34, iter:2510] Loss: 0.490 | Accuracy: 99.911% \n",
      "[epoch:34, iter:2511] Loss: 0.490 | Accuracy: 99.913% \n",
      "[epoch:34, iter:2512] Loss: 0.490 | Accuracy: 99.916% \n",
      "[epoch:34, iter:2513] Loss: 0.490 | Accuracy: 99.918% \n",
      "[epoch:34, iter:2514] Loss: 0.490 | Accuracy: 99.920% \n",
      "[epoch:34, iter:2515] Loss: 0.490 | Accuracy: 99.922% \n",
      "[epoch:34, iter:2516] Loss: 0.490 | Accuracy: 99.924% \n",
      "[epoch:34, iter:2517] Loss: 0.490 | Accuracy: 99.926% \n",
      "[epoch:34, iter:2518] Loss: 0.490 | Accuracy: 99.927% \n",
      "[epoch:34, iter:2519] Loss: 0.490 | Accuracy: 99.929% \n",
      "[epoch:34, iter:2520] Loss: 0.490 | Accuracy: 99.931% \n",
      "[epoch:34, iter:2521] Loss: 0.490 | Accuracy: 99.932% \n",
      "[epoch:34, iter:2522] Loss: 0.490 | Accuracy: 99.934% \n",
      "[epoch:34, iter:2523] Loss: 0.490 | Accuracy: 99.935% \n",
      "[epoch:34, iter:2524] Loss: 0.490 | Accuracy: 99.936% \n",
      "[epoch:34, iter:2525] Loss: 0.491 | Accuracy: 99.875% \n",
      "[epoch:34, iter:2526] Loss: 0.491 | Accuracy: 99.877% \n",
      "[epoch:34, iter:2527] Loss: 0.491 | Accuracy: 99.880% \n",
      "[epoch:34, iter:2528] Loss: 0.491 | Accuracy: 99.882% \n",
      "[epoch:34, iter:2529] Loss: 0.491 | Accuracy: 99.884% \n",
      "[epoch:34, iter:2530] Loss: 0.491 | Accuracy: 99.886% \n",
      "[epoch:34, iter:2531] Loss: 0.491 | Accuracy: 99.888% \n",
      "[epoch:34, iter:2532] Loss: 0.491 | Accuracy: 99.890% \n",
      "[epoch:34, iter:2533] Loss: 0.491 | Accuracy: 99.892% \n",
      "[epoch:34, iter:2534] Loss: 0.491 | Accuracy: 99.894% \n",
      "[epoch:34, iter:2535] Loss: 0.491 | Accuracy: 99.896% \n",
      "[epoch:34, iter:2536] Loss: 0.490 | Accuracy: 99.898% \n",
      "[epoch:34, iter:2537] Loss: 0.490 | Accuracy: 99.899% \n",
      "[epoch:34, iter:2538] Loss: 0.491 | Accuracy: 99.851% \n",
      "[epoch:34, iter:2539] Loss: 0.491 | Accuracy: 99.854% \n",
      "[epoch:34, iter:2540] Loss: 0.491 | Accuracy: 99.856% \n",
      "[epoch:34, iter:2541] Loss: 0.491 | Accuracy: 99.858% \n",
      "[epoch:34, iter:2542] Loss: 0.491 | Accuracy: 99.860% \n",
      "[epoch:34, iter:2543] Loss: 0.491 | Accuracy: 99.862% \n",
      "[epoch:34, iter:2544] Loss: 0.491 | Accuracy: 99.864% \n",
      "[epoch:34, iter:2545] Loss: 0.491 | Accuracy: 99.866% \n",
      "[epoch:34, iter:2546] Loss: 0.491 | Accuracy: 99.868% \n",
      "[epoch:34, iter:2547] Loss: 0.491 | Accuracy: 99.870% \n",
      "[epoch:34, iter:2548] Loss: 0.491 | Accuracy: 99.872% \n",
      "[epoch:34, iter:2549] Loss: 0.491 | Accuracy: 99.873% \n",
      "[epoch:34, iter:2550] Loss: 0.510 | Accuracy: 99.831% \n",
      "Waiting Test!\n",
      "EPOCH=034, Loss: 0.720, Accuracy= 92.763%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 13 out of 30\n",
      "\n",
      "Epoch: 35\n",
      "[epoch:35, iter:2551] Loss: 0.512 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2552] Loss: 0.502 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2553] Loss: 0.499 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2554] Loss: 0.498 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2555] Loss: 0.497 | Accuracy: 100.000% \n",
      "[epoch:35, iter:2556] Loss: 0.509 | Accuracy: 99.479% \n",
      "[epoch:35, iter:2557] Loss: 0.512 | Accuracy: 99.107% \n",
      "[epoch:35, iter:2558] Loss: 0.510 | Accuracy: 99.219% \n",
      "[epoch:35, iter:2559] Loss: 0.507 | Accuracy: 99.306% \n",
      "[epoch:35, iter:2560] Loss: 0.506 | Accuracy: 99.375% \n",
      "[epoch:35, iter:2561] Loss: 0.505 | Accuracy: 99.432% \n",
      "[epoch:35, iter:2562] Loss: 0.504 | Accuracy: 99.479% \n",
      "[epoch:35, iter:2563] Loss: 0.503 | Accuracy: 99.519% \n",
      "[epoch:35, iter:2564] Loss: 0.502 | Accuracy: 99.554% \n",
      "[epoch:35, iter:2565] Loss: 0.502 | Accuracy: 99.583% \n",
      "[epoch:35, iter:2566] Loss: 0.501 | Accuracy: 99.609% \n",
      "[epoch:35, iter:2567] Loss: 0.500 | Accuracy: 99.632% \n",
      "[epoch:35, iter:2568] Loss: 0.500 | Accuracy: 99.653% \n",
      "[epoch:35, iter:2569] Loss: 0.500 | Accuracy: 99.671% \n",
      "[epoch:35, iter:2570] Loss: 0.500 | Accuracy: 99.688% \n",
      "[epoch:35, iter:2571] Loss: 0.499 | Accuracy: 99.702% \n",
      "[epoch:35, iter:2572] Loss: 0.499 | Accuracy: 99.716% \n",
      "[epoch:35, iter:2573] Loss: 0.499 | Accuracy: 99.728% \n",
      "[epoch:35, iter:2574] Loss: 0.498 | Accuracy: 99.740% \n",
      "[epoch:35, iter:2575] Loss: 0.502 | Accuracy: 99.625% \n",
      "[epoch:35, iter:2576] Loss: 0.502 | Accuracy: 99.639% \n",
      "[epoch:35, iter:2577] Loss: 0.501 | Accuracy: 99.653% \n",
      "[epoch:35, iter:2578] Loss: 0.501 | Accuracy: 99.665% \n",
      "[epoch:35, iter:2579] Loss: 0.500 | Accuracy: 99.677% \n",
      "[epoch:35, iter:2580] Loss: 0.500 | Accuracy: 99.688% \n",
      "[epoch:35, iter:2581] Loss: 0.499 | Accuracy: 99.698% \n",
      "[epoch:35, iter:2582] Loss: 0.499 | Accuracy: 99.707% \n",
      "[epoch:35, iter:2583] Loss: 0.499 | Accuracy: 99.716% \n",
      "[epoch:35, iter:2584] Loss: 0.500 | Accuracy: 99.632% \n",
      "[epoch:35, iter:2585] Loss: 0.499 | Accuracy: 99.643% \n",
      "[epoch:35, iter:2586] Loss: 0.499 | Accuracy: 99.653% \n",
      "[epoch:35, iter:2587] Loss: 0.499 | Accuracy: 99.662% \n",
      "[epoch:35, iter:2588] Loss: 0.499 | Accuracy: 99.671% \n",
      "[epoch:35, iter:2589] Loss: 0.499 | Accuracy: 99.679% \n",
      "[epoch:35, iter:2590] Loss: 0.499 | Accuracy: 99.688% \n",
      "[epoch:35, iter:2591] Loss: 0.498 | Accuracy: 99.695% \n",
      "[epoch:35, iter:2592] Loss: 0.498 | Accuracy: 99.702% \n",
      "[epoch:35, iter:2593] Loss: 0.499 | Accuracy: 99.637% \n",
      "[epoch:35, iter:2594] Loss: 0.499 | Accuracy: 99.645% \n",
      "[epoch:35, iter:2595] Loss: 0.499 | Accuracy: 99.653% \n",
      "[epoch:35, iter:2596] Loss: 0.499 | Accuracy: 99.660% \n",
      "[epoch:35, iter:2597] Loss: 0.498 | Accuracy: 99.668% \n",
      "[epoch:35, iter:2598] Loss: 0.498 | Accuracy: 99.674% \n",
      "[epoch:35, iter:2599] Loss: 0.498 | Accuracy: 99.681% \n",
      "[epoch:35, iter:2600] Loss: 0.498 | Accuracy: 99.688% \n",
      "[epoch:35, iter:2601] Loss: 0.498 | Accuracy: 99.694% \n",
      "[epoch:35, iter:2602] Loss: 0.498 | Accuracy: 99.700% \n",
      "[epoch:35, iter:2603] Loss: 0.497 | Accuracy: 99.705% \n",
      "[epoch:35, iter:2604] Loss: 0.497 | Accuracy: 99.711% \n",
      "[epoch:35, iter:2605] Loss: 0.498 | Accuracy: 99.659% \n",
      "[epoch:35, iter:2606] Loss: 0.498 | Accuracy: 99.665% \n",
      "[epoch:35, iter:2607] Loss: 0.498 | Accuracy: 99.671% \n",
      "[epoch:35, iter:2608] Loss: 0.497 | Accuracy: 99.677% \n",
      "[epoch:35, iter:2609] Loss: 0.497 | Accuracy: 99.682% \n",
      "[epoch:35, iter:2610] Loss: 0.497 | Accuracy: 99.688% \n",
      "[epoch:35, iter:2611] Loss: 0.497 | Accuracy: 99.693% \n",
      "[epoch:35, iter:2612] Loss: 0.497 | Accuracy: 99.698% \n",
      "[epoch:35, iter:2613] Loss: 0.497 | Accuracy: 99.702% \n",
      "[epoch:35, iter:2614] Loss: 0.497 | Accuracy: 99.707% \n",
      "[epoch:35, iter:2615] Loss: 0.497 | Accuracy: 99.712% \n",
      "[epoch:35, iter:2616] Loss: 0.496 | Accuracy: 99.716% \n",
      "[epoch:35, iter:2617] Loss: 0.496 | Accuracy: 99.720% \n",
      "[epoch:35, iter:2618] Loss: 0.496 | Accuracy: 99.724% \n",
      "[epoch:35, iter:2619] Loss: 0.496 | Accuracy: 99.728% \n",
      "[epoch:35, iter:2620] Loss: 0.496 | Accuracy: 99.732% \n",
      "[epoch:35, iter:2621] Loss: 0.496 | Accuracy: 99.736% \n",
      "[epoch:35, iter:2622] Loss: 0.496 | Accuracy: 99.740% \n",
      "[epoch:35, iter:2623] Loss: 0.496 | Accuracy: 99.743% \n",
      "[epoch:35, iter:2624] Loss: 0.496 | Accuracy: 99.747% \n",
      "[epoch:35, iter:2625] Loss: 0.505 | Accuracy: 99.747% \n",
      "Waiting Test!\n",
      "EPOCH=035, Loss: 0.660, Accuracy= 93.750%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 14 out of 30\n",
      "\n",
      "Epoch: 36\n",
      "[epoch:36, iter:2626] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2627] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2628] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2629] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2630] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2631] Loss: 0.490 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:36, iter:2632] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:36, iter:2633] Loss: 0.494 | Accuracy: 99.609% \n",
      "[epoch:36, iter:2634] Loss: 0.493 | Accuracy: 99.653% \n",
      "[epoch:36, iter:2635] Loss: 0.493 | Accuracy: 99.688% \n",
      "[epoch:36, iter:2636] Loss: 0.493 | Accuracy: 99.716% \n",
      "[epoch:36, iter:2637] Loss: 0.492 | Accuracy: 99.740% \n",
      "[epoch:36, iter:2638] Loss: 0.493 | Accuracy: 99.760% \n",
      "[epoch:36, iter:2639] Loss: 0.492 | Accuracy: 99.777% \n",
      "[epoch:36, iter:2640] Loss: 0.492 | Accuracy: 99.792% \n",
      "[epoch:36, iter:2641] Loss: 0.492 | Accuracy: 99.805% \n",
      "[epoch:36, iter:2642] Loss: 0.492 | Accuracy: 99.816% \n",
      "[epoch:36, iter:2643] Loss: 0.491 | Accuracy: 99.826% \n",
      "[epoch:36, iter:2644] Loss: 0.491 | Accuracy: 99.836% \n",
      "[epoch:36, iter:2645] Loss: 0.491 | Accuracy: 99.844% \n",
      "[epoch:36, iter:2646] Loss: 0.491 | Accuracy: 99.851% \n",
      "[epoch:36, iter:2647] Loss: 0.491 | Accuracy: 99.858% \n",
      "[epoch:36, iter:2648] Loss: 0.491 | Accuracy: 99.864% \n",
      "[epoch:36, iter:2649] Loss: 0.491 | Accuracy: 99.870% \n",
      "[epoch:36, iter:2650] Loss: 0.491 | Accuracy: 99.875% \n",
      "[epoch:36, iter:2651] Loss: 0.491 | Accuracy: 99.880% \n",
      "[epoch:36, iter:2652] Loss: 0.491 | Accuracy: 99.884% \n",
      "[epoch:36, iter:2653] Loss: 0.491 | Accuracy: 99.888% \n",
      "[epoch:36, iter:2654] Loss: 0.491 | Accuracy: 99.892% \n",
      "[epoch:36, iter:2655] Loss: 0.491 | Accuracy: 99.896% \n",
      "[epoch:36, iter:2656] Loss: 0.490 | Accuracy: 99.899% \n",
      "[epoch:36, iter:2657] Loss: 0.490 | Accuracy: 99.902% \n",
      "[epoch:36, iter:2658] Loss: 0.490 | Accuracy: 99.905% \n",
      "[epoch:36, iter:2659] Loss: 0.490 | Accuracy: 99.908% \n",
      "[epoch:36, iter:2660] Loss: 0.490 | Accuracy: 99.911% \n",
      "[epoch:36, iter:2661] Loss: 0.490 | Accuracy: 99.913% \n",
      "[epoch:36, iter:2662] Loss: 0.490 | Accuracy: 99.916% \n",
      "[epoch:36, iter:2663] Loss: 0.490 | Accuracy: 99.918% \n",
      "[epoch:36, iter:2664] Loss: 0.490 | Accuracy: 99.920% \n",
      "[epoch:36, iter:2665] Loss: 0.491 | Accuracy: 99.844% \n",
      "[epoch:36, iter:2666] Loss: 0.491 | Accuracy: 99.848% \n",
      "[epoch:36, iter:2667] Loss: 0.491 | Accuracy: 99.851% \n",
      "[epoch:36, iter:2668] Loss: 0.491 | Accuracy: 99.855% \n",
      "[epoch:36, iter:2669] Loss: 0.491 | Accuracy: 99.858% \n",
      "[epoch:36, iter:2670] Loss: 0.490 | Accuracy: 99.861% \n",
      "[epoch:36, iter:2671] Loss: 0.490 | Accuracy: 99.864% \n",
      "[epoch:36, iter:2672] Loss: 0.490 | Accuracy: 99.867% \n",
      "[epoch:36, iter:2673] Loss: 0.490 | Accuracy: 99.870% \n",
      "[epoch:36, iter:2674] Loss: 0.490 | Accuracy: 99.872% \n",
      "[epoch:36, iter:2675] Loss: 0.490 | Accuracy: 99.875% \n",
      "[epoch:36, iter:2676] Loss: 0.490 | Accuracy: 99.877% \n",
      "[epoch:36, iter:2677] Loss: 0.490 | Accuracy: 99.880% \n",
      "[epoch:36, iter:2678] Loss: 0.490 | Accuracy: 99.882% \n",
      "[epoch:36, iter:2679] Loss: 0.490 | Accuracy: 99.884% \n",
      "[epoch:36, iter:2680] Loss: 0.490 | Accuracy: 99.886% \n",
      "[epoch:36, iter:2681] Loss: 0.490 | Accuracy: 99.888% \n",
      "[epoch:36, iter:2682] Loss: 0.490 | Accuracy: 99.890% \n",
      "[epoch:36, iter:2683] Loss: 0.490 | Accuracy: 99.892% \n",
      "[epoch:36, iter:2684] Loss: 0.490 | Accuracy: 99.894% \n",
      "[epoch:36, iter:2685] Loss: 0.490 | Accuracy: 99.896% \n",
      "[epoch:36, iter:2686] Loss: 0.490 | Accuracy: 99.898% \n",
      "[epoch:36, iter:2687] Loss: 0.490 | Accuracy: 99.899% \n",
      "[epoch:36, iter:2688] Loss: 0.491 | Accuracy: 99.851% \n",
      "[epoch:36, iter:2689] Loss: 0.491 | Accuracy: 99.854% \n",
      "[epoch:36, iter:2690] Loss: 0.491 | Accuracy: 99.856% \n",
      "[epoch:36, iter:2691] Loss: 0.490 | Accuracy: 99.858% \n",
      "[epoch:36, iter:2692] Loss: 0.490 | Accuracy: 99.860% \n",
      "[epoch:36, iter:2693] Loss: 0.490 | Accuracy: 99.862% \n",
      "[epoch:36, iter:2694] Loss: 0.490 | Accuracy: 99.864% \n",
      "[epoch:36, iter:2695] Loss: 0.490 | Accuracy: 99.866% \n",
      "[epoch:36, iter:2696] Loss: 0.490 | Accuracy: 99.868% \n",
      "[epoch:36, iter:2697] Loss: 0.490 | Accuracy: 99.870% \n",
      "[epoch:36, iter:2698] Loss: 0.490 | Accuracy: 99.872% \n",
      "[epoch:36, iter:2699] Loss: 0.490 | Accuracy: 99.873% \n",
      "[epoch:36, iter:2700] Loss: 0.490 | Accuracy: 99.873% \n",
      "Waiting Test!\n",
      "EPOCH=036, Loss: 0.636, Accuracy= 94.737%\n",
      "Training complete in 0m 12s\n",
      "EarlyStopping counter: 15 out of 30\n",
      "\n",
      "Epoch: 37\n",
      "[epoch:37, iter:2701] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2702] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2703] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2704] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2705] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2706] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2707] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2708] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2709] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2710] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2711] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2712] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2713] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2714] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2715] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2716] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2717] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2718] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2719] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2720] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2721] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2722] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2723] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2724] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2725] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2726] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2727] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2728] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2729] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2730] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2731] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2732] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2733] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2734] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2735] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2736] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2737] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2738] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2739] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2740] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2741] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2742] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2743] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2744] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2745] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2746] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2747] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2748] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2749] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2750] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2751] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2752] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2753] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2754] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2755] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2756] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2757] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2758] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2759] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2760] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2761] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2762] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2763] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2764] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2765] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2766] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2767] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2768] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2769] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2770] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2771] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2772] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2773] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2774] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:37, iter:2775] Loss: 0.488 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=037, Loss: 0.653, Accuracy= 94.408%\n",
      "Epoch 00037: reducing learning rate of group 0 to 5.0421e-05.\n",
      "Training complete in 0m 12s\n",
      "EarlyStopping counter: 16 out of 30\n",
      "\n",
      "Epoch: 38\n",
      "[epoch:38, iter:2776] Loss: 0.488 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:38, iter:2777] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2778] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2779] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2780] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2781] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2782] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2783] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2784] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2785] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2786] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2787] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2788] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2789] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2790] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2791] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2792] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2793] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2794] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2795] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2796] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2797] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2798] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2799] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2800] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2801] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2802] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2803] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2804] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2805] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2806] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2807] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2808] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2809] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2810] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2811] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2812] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2813] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2814] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2815] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2816] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2817] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2818] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2819] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2820] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2821] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2822] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2823] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2824] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2825] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2826] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2827] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2828] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2829] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2830] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2831] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2832] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2833] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2834] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2835] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2836] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2837] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2838] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2839] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2840] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2841] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2842] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2843] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2844] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2845] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2846] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2847] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2848] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2849] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:38, iter:2850] Loss: 0.488 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=038, Loss: 0.640, Accuracy= 94.079%\n",
      "Training complete in 0m 12s\n",
      "EarlyStopping counter: 17 out of 30\n",
      "\n",
      "Epoch: 39\n",
      "[epoch:39, iter:2851] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2852] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2853] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2854] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2855] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2856] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2857] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2858] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2859] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2860] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2861] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2862] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2863] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2864] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2865] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2866] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2867] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2868] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2869] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2870] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2871] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2872] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2873] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2874] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2875] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2876] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2877] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2878] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2879] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2880] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2881] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2882] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2883] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2884] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2885] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2886] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2887] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2888] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2889] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2890] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2891] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2892] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2893] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2894] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2895] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2896] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2897] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2898] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2899] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2900] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2901] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2902] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2903] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2904] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2905] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2906] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2907] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2908] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2909] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2910] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2911] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2912] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2913] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2914] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2915] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2916] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2917] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2918] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2919] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2920] Loss: 0.488 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:39, iter:2921] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2922] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2923] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2924] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:39, iter:2925] Loss: 0.488 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=039, Loss: 0.653, Accuracy= 94.737%\n",
      "Training complete in 0m 12s\n",
      "EarlyStopping counter: 18 out of 30\n",
      "\n",
      "Epoch: 40\n",
      "[epoch:40, iter:2926] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2927] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2928] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2929] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2930] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2931] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2932] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2933] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2934] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2935] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2936] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:40, iter:2937] Loss: 0.490 | Accuracy: 99.740% \n",
      "[epoch:40, iter:2938] Loss: 0.490 | Accuracy: 99.760% \n",
      "[epoch:40, iter:2939] Loss: 0.490 | Accuracy: 99.777% \n",
      "[epoch:40, iter:2940] Loss: 0.490 | Accuracy: 99.792% \n",
      "[epoch:40, iter:2941] Loss: 0.490 | Accuracy: 99.805% \n",
      "[epoch:40, iter:2942] Loss: 0.490 | Accuracy: 99.816% \n",
      "[epoch:40, iter:2943] Loss: 0.489 | Accuracy: 99.826% \n",
      "[epoch:40, iter:2944] Loss: 0.489 | Accuracy: 99.836% \n",
      "[epoch:40, iter:2945] Loss: 0.489 | Accuracy: 99.844% \n",
      "[epoch:40, iter:2946] Loss: 0.489 | Accuracy: 99.851% \n",
      "[epoch:40, iter:2947] Loss: 0.489 | Accuracy: 99.858% \n",
      "[epoch:40, iter:2948] Loss: 0.489 | Accuracy: 99.864% \n",
      "[epoch:40, iter:2949] Loss: 0.492 | Accuracy: 99.740% \n",
      "[epoch:40, iter:2950] Loss: 0.492 | Accuracy: 99.750% \n",
      "[epoch:40, iter:2951] Loss: 0.491 | Accuracy: 99.760% \n",
      "[epoch:40, iter:2952] Loss: 0.491 | Accuracy: 99.769% \n",
      "[epoch:40, iter:2953] Loss: 0.491 | Accuracy: 99.777% \n",
      "[epoch:40, iter:2954] Loss: 0.491 | Accuracy: 99.784% \n",
      "[epoch:40, iter:2955] Loss: 0.491 | Accuracy: 99.792% \n",
      "[epoch:40, iter:2956] Loss: 0.491 | Accuracy: 99.798% \n",
      "[epoch:40, iter:2957] Loss: 0.491 | Accuracy: 99.805% \n",
      "[epoch:40, iter:2958] Loss: 0.491 | Accuracy: 99.811% \n",
      "[epoch:40, iter:2959] Loss: 0.491 | Accuracy: 99.816% \n",
      "[epoch:40, iter:2960] Loss: 0.490 | Accuracy: 99.821% \n",
      "[epoch:40, iter:2961] Loss: 0.490 | Accuracy: 99.826% \n",
      "[epoch:40, iter:2962] Loss: 0.490 | Accuracy: 99.831% \n",
      "[epoch:40, iter:2963] Loss: 0.490 | Accuracy: 99.836% \n",
      "[epoch:40, iter:2964] Loss: 0.490 | Accuracy: 99.840% \n",
      "[epoch:40, iter:2965] Loss: 0.490 | Accuracy: 99.844% \n",
      "[epoch:40, iter:2966] Loss: 0.490 | Accuracy: 99.848% \n",
      "[epoch:40, iter:2967] Loss: 0.490 | Accuracy: 99.851% \n",
      "[epoch:40, iter:2968] Loss: 0.490 | Accuracy: 99.855% \n",
      "[epoch:40, iter:2969] Loss: 0.490 | Accuracy: 99.858% \n",
      "[epoch:40, iter:2970] Loss: 0.490 | Accuracy: 99.861% \n",
      "[epoch:40, iter:2971] Loss: 0.490 | Accuracy: 99.864% \n",
      "[epoch:40, iter:2972] Loss: 0.490 | Accuracy: 99.867% \n",
      "[epoch:40, iter:2973] Loss: 0.490 | Accuracy: 99.870% \n",
      "[epoch:40, iter:2974] Loss: 0.490 | Accuracy: 99.872% \n",
      "[epoch:40, iter:2975] Loss: 0.490 | Accuracy: 99.875% \n",
      "[epoch:40, iter:2976] Loss: 0.490 | Accuracy: 99.877% \n",
      "[epoch:40, iter:2977] Loss: 0.490 | Accuracy: 99.880% \n",
      "[epoch:40, iter:2978] Loss: 0.490 | Accuracy: 99.882% \n",
      "[epoch:40, iter:2979] Loss: 0.489 | Accuracy: 99.884% \n",
      "[epoch:40, iter:2980] Loss: 0.489 | Accuracy: 99.886% \n",
      "[epoch:40, iter:2981] Loss: 0.489 | Accuracy: 99.888% \n",
      "[epoch:40, iter:2982] Loss: 0.489 | Accuracy: 99.890% \n",
      "[epoch:40, iter:2983] Loss: 0.489 | Accuracy: 99.892% \n",
      "[epoch:40, iter:2984] Loss: 0.489 | Accuracy: 99.894% \n",
      "[epoch:40, iter:2985] Loss: 0.489 | Accuracy: 99.896% \n",
      "[epoch:40, iter:2986] Loss: 0.489 | Accuracy: 99.898% \n",
      "[epoch:40, iter:2987] Loss: 0.489 | Accuracy: 99.899% \n",
      "[epoch:40, iter:2988] Loss: 0.489 | Accuracy: 99.901% \n",
      "[epoch:40, iter:2989] Loss: 0.489 | Accuracy: 99.902% \n",
      "[epoch:40, iter:2990] Loss: 0.489 | Accuracy: 99.904% \n",
      "[epoch:40, iter:2991] Loss: 0.489 | Accuracy: 99.905% \n",
      "[epoch:40, iter:2992] Loss: 0.489 | Accuracy: 99.907% \n",
      "[epoch:40, iter:2993] Loss: 0.489 | Accuracy: 99.908% \n",
      "[epoch:40, iter:2994] Loss: 0.489 | Accuracy: 99.909% \n",
      "[epoch:40, iter:2995] Loss: 0.489 | Accuracy: 99.911% \n",
      "[epoch:40, iter:2996] Loss: 0.489 | Accuracy: 99.912% \n",
      "[epoch:40, iter:2997] Loss: 0.489 | Accuracy: 99.913% \n",
      "[epoch:40, iter:2998] Loss: 0.489 | Accuracy: 99.914% \n",
      "[epoch:40, iter:2999] Loss: 0.489 | Accuracy: 99.916% \n",
      "[epoch:40, iter:3000] Loss: 0.489 | Accuracy: 99.916% \n",
      "Waiting Test!\n",
      "EPOCH=040, Loss: 0.640, Accuracy= 94.408%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 19 out of 30\n",
      "\n",
      "Epoch: 41\n",
      "[epoch:41, iter:3001] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3002] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3003] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3004] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3005] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3006] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3007] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3008] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3009] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3010] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3011] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3012] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3013] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3014] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3015] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3016] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3017] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3018] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3019] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3020] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3021] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3022] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3023] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3024] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3025] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3026] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3027] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3028] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3029] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3030] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3031] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3032] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3033] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3034] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:41, iter:3035] Loss: 0.489 | Accuracy: 99.911% \n",
      "[epoch:41, iter:3036] Loss: 0.489 | Accuracy: 99.913% \n",
      "[epoch:41, iter:3037] Loss: 0.489 | Accuracy: 99.916% \n",
      "[epoch:41, iter:3038] Loss: 0.489 | Accuracy: 99.918% \n",
      "[epoch:41, iter:3039] Loss: 0.489 | Accuracy: 99.920% \n",
      "[epoch:41, iter:3040] Loss: 0.489 | Accuracy: 99.922% \n",
      "[epoch:41, iter:3041] Loss: 0.489 | Accuracy: 99.924% \n",
      "[epoch:41, iter:3042] Loss: 0.489 | Accuracy: 99.926% \n",
      "[epoch:41, iter:3043] Loss: 0.489 | Accuracy: 99.927% \n",
      "[epoch:41, iter:3044] Loss: 0.489 | Accuracy: 99.929% \n",
      "[epoch:41, iter:3045] Loss: 0.489 | Accuracy: 99.931% \n",
      "[epoch:41, iter:3046] Loss: 0.489 | Accuracy: 99.932% \n",
      "[epoch:41, iter:3047] Loss: 0.489 | Accuracy: 99.934% \n",
      "[epoch:41, iter:3048] Loss: 0.489 | Accuracy: 99.935% \n",
      "[epoch:41, iter:3049] Loss: 0.489 | Accuracy: 99.936% \n",
      "[epoch:41, iter:3050] Loss: 0.489 | Accuracy: 99.938% \n",
      "[epoch:41, iter:3051] Loss: 0.489 | Accuracy: 99.939% \n",
      "[epoch:41, iter:3052] Loss: 0.489 | Accuracy: 99.940% \n",
      "[epoch:41, iter:3053] Loss: 0.489 | Accuracy: 99.941% \n",
      "[epoch:41, iter:3054] Loss: 0.489 | Accuracy: 99.942% \n",
      "[epoch:41, iter:3055] Loss: 0.489 | Accuracy: 99.943% \n",
      "[epoch:41, iter:3056] Loss: 0.489 | Accuracy: 99.944% \n",
      "[epoch:41, iter:3057] Loss: 0.489 | Accuracy: 99.945% \n",
      "[epoch:41, iter:3058] Loss: 0.489 | Accuracy: 99.946% \n",
      "[epoch:41, iter:3059] Loss: 0.489 | Accuracy: 99.947% \n",
      "[epoch:41, iter:3060] Loss: 0.489 | Accuracy: 99.948% \n",
      "[epoch:41, iter:3061] Loss: 0.489 | Accuracy: 99.949% \n",
      "[epoch:41, iter:3062] Loss: 0.489 | Accuracy: 99.950% \n",
      "[epoch:41, iter:3063] Loss: 0.489 | Accuracy: 99.950% \n",
      "[epoch:41, iter:3064] Loss: 0.489 | Accuracy: 99.951% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:41, iter:3065] Loss: 0.489 | Accuracy: 99.952% \n",
      "[epoch:41, iter:3066] Loss: 0.489 | Accuracy: 99.953% \n",
      "[epoch:41, iter:3067] Loss: 0.489 | Accuracy: 99.953% \n",
      "[epoch:41, iter:3068] Loss: 0.489 | Accuracy: 99.954% \n",
      "[epoch:41, iter:3069] Loss: 0.489 | Accuracy: 99.955% \n",
      "[epoch:41, iter:3070] Loss: 0.489 | Accuracy: 99.955% \n",
      "[epoch:41, iter:3071] Loss: 0.489 | Accuracy: 99.956% \n",
      "[epoch:41, iter:3072] Loss: 0.489 | Accuracy: 99.957% \n",
      "[epoch:41, iter:3073] Loss: 0.489 | Accuracy: 99.957% \n",
      "[epoch:41, iter:3074] Loss: 0.489 | Accuracy: 99.958% \n",
      "[epoch:41, iter:3075] Loss: 0.489 | Accuracy: 99.958% \n",
      "Waiting Test!\n",
      "EPOCH=041, Loss: 0.646, Accuracy= 94.408%\n",
      "Epoch 00041: reducing learning rate of group 0 to 3.5295e-05.\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 20 out of 30\n",
      "\n",
      "Epoch: 42\n",
      "[epoch:42, iter:3076] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3077] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3078] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3079] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3080] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3081] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3082] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3083] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3084] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3085] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3086] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3087] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3088] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3089] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3090] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3091] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3092] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3093] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3094] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3095] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3096] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3097] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3098] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3099] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3100] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3101] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3102] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3103] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3104] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3105] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3106] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3107] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3108] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3109] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3110] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3111] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3112] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3113] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3114] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3115] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3116] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3117] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3118] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3119] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3120] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3121] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3122] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3123] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3124] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3125] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3126] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3127] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3128] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3129] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3130] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3131] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3132] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3133] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3134] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3135] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3136] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3137] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3138] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3139] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3140] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3141] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3142] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3143] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3144] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3145] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3146] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3147] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3148] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3149] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:42, iter:3150] Loss: 0.488 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=042, Loss: 0.657, Accuracy= 94.408%\n",
      "Training complete in 0m 12s\n",
      "EarlyStopping counter: 21 out of 30\n",
      "\n",
      "Epoch: 43\n",
      "[epoch:43, iter:3151] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3152] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3153] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3154] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3155] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3156] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3157] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3158] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3159] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3160] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3161] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:43, iter:3162] Loss: 0.490 | Accuracy: 99.740% \n",
      "[epoch:43, iter:3163] Loss: 0.490 | Accuracy: 99.760% \n",
      "[epoch:43, iter:3164] Loss: 0.490 | Accuracy: 99.777% \n",
      "[epoch:43, iter:3165] Loss: 0.490 | Accuracy: 99.792% \n",
      "[epoch:43, iter:3166] Loss: 0.489 | Accuracy: 99.805% \n",
      "[epoch:43, iter:3167] Loss: 0.489 | Accuracy: 99.816% \n",
      "[epoch:43, iter:3168] Loss: 0.489 | Accuracy: 99.826% \n",
      "[epoch:43, iter:3169] Loss: 0.489 | Accuracy: 99.836% \n",
      "[epoch:43, iter:3170] Loss: 0.489 | Accuracy: 99.844% \n",
      "[epoch:43, iter:3171] Loss: 0.489 | Accuracy: 99.851% \n",
      "[epoch:43, iter:3172] Loss: 0.489 | Accuracy: 99.858% \n",
      "[epoch:43, iter:3173] Loss: 0.489 | Accuracy: 99.864% \n",
      "[epoch:43, iter:3174] Loss: 0.489 | Accuracy: 99.870% \n",
      "[epoch:43, iter:3175] Loss: 0.489 | Accuracy: 99.875% \n",
      "[epoch:43, iter:3176] Loss: 0.489 | Accuracy: 99.880% \n",
      "[epoch:43, iter:3177] Loss: 0.489 | Accuracy: 99.884% \n",
      "[epoch:43, iter:3178] Loss: 0.489 | Accuracy: 99.888% \n",
      "[epoch:43, iter:3179] Loss: 0.489 | Accuracy: 99.892% \n",
      "[epoch:43, iter:3180] Loss: 0.489 | Accuracy: 99.896% \n",
      "[epoch:43, iter:3181] Loss: 0.489 | Accuracy: 99.899% \n",
      "[epoch:43, iter:3182] Loss: 0.489 | Accuracy: 99.902% \n",
      "[epoch:43, iter:3183] Loss: 0.489 | Accuracy: 99.905% \n",
      "[epoch:43, iter:3184] Loss: 0.489 | Accuracy: 99.908% \n",
      "[epoch:43, iter:3185] Loss: 0.489 | Accuracy: 99.911% \n",
      "[epoch:43, iter:3186] Loss: 0.489 | Accuracy: 99.913% \n",
      "[epoch:43, iter:3187] Loss: 0.489 | Accuracy: 99.916% \n",
      "[epoch:43, iter:3188] Loss: 0.489 | Accuracy: 99.918% \n",
      "[epoch:43, iter:3189] Loss: 0.488 | Accuracy: 99.920% \n",
      "[epoch:43, iter:3190] Loss: 0.488 | Accuracy: 99.922% \n",
      "[epoch:43, iter:3191] Loss: 0.488 | Accuracy: 99.924% \n",
      "[epoch:43, iter:3192] Loss: 0.488 | Accuracy: 99.926% \n",
      "[epoch:43, iter:3193] Loss: 0.488 | Accuracy: 99.927% \n",
      "[epoch:43, iter:3194] Loss: 0.488 | Accuracy: 99.929% \n",
      "[epoch:43, iter:3195] Loss: 0.488 | Accuracy: 99.931% \n",
      "[epoch:43, iter:3196] Loss: 0.488 | Accuracy: 99.932% \n",
      "[epoch:43, iter:3197] Loss: 0.488 | Accuracy: 99.934% \n",
      "[epoch:43, iter:3198] Loss: 0.488 | Accuracy: 99.935% \n",
      "[epoch:43, iter:3199] Loss: 0.488 | Accuracy: 99.936% \n",
      "[epoch:43, iter:3200] Loss: 0.488 | Accuracy: 99.938% \n",
      "[epoch:43, iter:3201] Loss: 0.488 | Accuracy: 99.939% \n",
      "[epoch:43, iter:3202] Loss: 0.488 | Accuracy: 99.940% \n",
      "[epoch:43, iter:3203] Loss: 0.488 | Accuracy: 99.941% \n",
      "[epoch:43, iter:3204] Loss: 0.488 | Accuracy: 99.942% \n",
      "[epoch:43, iter:3205] Loss: 0.488 | Accuracy: 99.943% \n",
      "[epoch:43, iter:3206] Loss: 0.488 | Accuracy: 99.944% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:43, iter:3207] Loss: 0.488 | Accuracy: 99.945% \n",
      "[epoch:43, iter:3208] Loss: 0.488 | Accuracy: 99.946% \n",
      "[epoch:43, iter:3209] Loss: 0.488 | Accuracy: 99.947% \n",
      "[epoch:43, iter:3210] Loss: 0.488 | Accuracy: 99.948% \n",
      "[epoch:43, iter:3211] Loss: 0.488 | Accuracy: 99.949% \n",
      "[epoch:43, iter:3212] Loss: 0.488 | Accuracy: 99.950% \n",
      "[epoch:43, iter:3213] Loss: 0.488 | Accuracy: 99.950% \n",
      "[epoch:43, iter:3214] Loss: 0.488 | Accuracy: 99.951% \n",
      "[epoch:43, iter:3215] Loss: 0.488 | Accuracy: 99.952% \n",
      "[epoch:43, iter:3216] Loss: 0.488 | Accuracy: 99.953% \n",
      "[epoch:43, iter:3217] Loss: 0.488 | Accuracy: 99.953% \n",
      "[epoch:43, iter:3218] Loss: 0.488 | Accuracy: 99.954% \n",
      "[epoch:43, iter:3219] Loss: 0.488 | Accuracy: 99.955% \n",
      "[epoch:43, iter:3220] Loss: 0.488 | Accuracy: 99.955% \n",
      "[epoch:43, iter:3221] Loss: 0.488 | Accuracy: 99.956% \n",
      "[epoch:43, iter:3222] Loss: 0.488 | Accuracy: 99.957% \n",
      "[epoch:43, iter:3223] Loss: 0.488 | Accuracy: 99.957% \n",
      "[epoch:43, iter:3224] Loss: 0.488 | Accuracy: 99.958% \n",
      "[epoch:43, iter:3225] Loss: 0.492 | Accuracy: 99.958% \n",
      "Waiting Test!\n",
      "EPOCH=043, Loss: 0.669, Accuracy= 94.408%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 22 out of 30\n",
      "\n",
      "Epoch: 44\n",
      "[epoch:44, iter:3226] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3227] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3228] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3229] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3230] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3231] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3232] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3233] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3234] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3235] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3236] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3237] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3238] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3239] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3240] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3241] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3242] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3243] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3244] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3245] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3246] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3247] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3248] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3249] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3250] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3251] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3252] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3253] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3254] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3255] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3256] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3257] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3258] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3259] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3260] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3261] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3262] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3263] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3264] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3265] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3266] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3267] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3268] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3269] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3270] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3271] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3272] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3273] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3274] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3275] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3276] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3277] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3278] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3279] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3280] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3281] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3282] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3283] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3284] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3285] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3286] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3287] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3288] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3289] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3290] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3291] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3292] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3293] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3294] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3295] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3296] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3297] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3298] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3299] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:44, iter:3300] Loss: 0.499 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=044, Loss: 0.663, Accuracy= 94.079%\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 23 out of 30\n",
      "\n",
      "Epoch: 45\n",
      "[epoch:45, iter:3301] Loss: 0.490 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3302] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3303] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3304] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3305] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3306] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3307] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3308] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3309] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3310] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3311] Loss: 0.489 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3312] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3313] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3314] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3315] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3316] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3317] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3318] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3319] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3320] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3321] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3322] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3323] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3324] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3325] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3326] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3327] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3328] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3329] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3330] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3331] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3332] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3333] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3334] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3335] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3336] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3337] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3338] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3339] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3340] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3341] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3342] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3343] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3344] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3345] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3346] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3347] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3348] Loss: 0.488 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:45, iter:3349] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3350] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3351] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3352] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3353] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3354] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3355] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3356] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3357] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3358] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3359] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3360] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3361] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3362] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3363] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3364] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3365] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3366] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3367] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3368] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3369] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3370] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3371] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3372] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3373] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3374] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:45, iter:3375] Loss: 0.489 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=045, Loss: 0.656, Accuracy= 93.750%\n",
      "Epoch 00045: reducing learning rate of group 0 to 2.4706e-05.\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 24 out of 30\n",
      "\n",
      "Epoch: 46\n",
      "[epoch:46, iter:3376] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3377] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3378] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3379] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3380] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3381] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3382] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3383] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3384] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3385] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3386] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3387] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3388] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3389] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3390] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3391] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3392] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3393] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3394] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3395] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3396] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3397] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3398] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3399] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3400] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3401] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3402] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3403] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3404] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3405] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3406] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3407] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3408] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3409] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3410] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3411] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3412] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3413] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3414] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3415] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3416] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3417] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3418] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3419] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3420] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3421] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3422] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3423] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3424] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3425] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3426] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3427] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3428] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3429] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3430] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3431] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3432] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3433] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3434] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3435] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3436] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3437] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3438] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3439] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3440] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3441] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3442] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3443] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3444] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3445] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3446] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3447] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3448] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3449] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:46, iter:3450] Loss: 0.488 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=046, Loss: 0.665, Accuracy= 94.079%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 25 out of 30\n",
      "\n",
      "Epoch: 47\n",
      "[epoch:47, iter:3451] Loss: 0.486 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3452] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3453] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3454] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3455] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3456] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3457] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3458] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3459] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3460] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3461] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3462] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3463] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3464] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:47, iter:3465] Loss: 0.493 | Accuracy: 99.792% \n",
      "[epoch:47, iter:3466] Loss: 0.492 | Accuracy: 99.805% \n",
      "[epoch:47, iter:3467] Loss: 0.492 | Accuracy: 99.816% \n",
      "[epoch:47, iter:3468] Loss: 0.492 | Accuracy: 99.826% \n",
      "[epoch:47, iter:3469] Loss: 0.491 | Accuracy: 99.836% \n",
      "[epoch:47, iter:3470] Loss: 0.491 | Accuracy: 99.844% \n",
      "[epoch:47, iter:3471] Loss: 0.491 | Accuracy: 99.851% \n",
      "[epoch:47, iter:3472] Loss: 0.491 | Accuracy: 99.858% \n",
      "[epoch:47, iter:3473] Loss: 0.491 | Accuracy: 99.864% \n",
      "[epoch:47, iter:3474] Loss: 0.491 | Accuracy: 99.870% \n",
      "[epoch:47, iter:3475] Loss: 0.491 | Accuracy: 99.875% \n",
      "[epoch:47, iter:3476] Loss: 0.490 | Accuracy: 99.880% \n",
      "[epoch:47, iter:3477] Loss: 0.490 | Accuracy: 99.884% \n",
      "[epoch:47, iter:3478] Loss: 0.490 | Accuracy: 99.888% \n",
      "[epoch:47, iter:3479] Loss: 0.490 | Accuracy: 99.892% \n",
      "[epoch:47, iter:3480] Loss: 0.490 | Accuracy: 99.896% \n",
      "[epoch:47, iter:3481] Loss: 0.490 | Accuracy: 99.899% \n",
      "[epoch:47, iter:3482] Loss: 0.490 | Accuracy: 99.902% \n",
      "[epoch:47, iter:3483] Loss: 0.490 | Accuracy: 99.905% \n",
      "[epoch:47, iter:3484] Loss: 0.490 | Accuracy: 99.908% \n",
      "[epoch:47, iter:3485] Loss: 0.490 | Accuracy: 99.911% \n",
      "[epoch:47, iter:3486] Loss: 0.489 | Accuracy: 99.913% \n",
      "[epoch:47, iter:3487] Loss: 0.489 | Accuracy: 99.916% \n",
      "[epoch:47, iter:3488] Loss: 0.489 | Accuracy: 99.918% \n",
      "[epoch:47, iter:3489] Loss: 0.489 | Accuracy: 99.920% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:47, iter:3490] Loss: 0.489 | Accuracy: 99.922% \n",
      "[epoch:47, iter:3491] Loss: 0.489 | Accuracy: 99.924% \n",
      "[epoch:47, iter:3492] Loss: 0.489 | Accuracy: 99.926% \n",
      "[epoch:47, iter:3493] Loss: 0.489 | Accuracy: 99.927% \n",
      "[epoch:47, iter:3494] Loss: 0.489 | Accuracy: 99.929% \n",
      "[epoch:47, iter:3495] Loss: 0.489 | Accuracy: 99.931% \n",
      "[epoch:47, iter:3496] Loss: 0.489 | Accuracy: 99.932% \n",
      "[epoch:47, iter:3497] Loss: 0.489 | Accuracy: 99.934% \n",
      "[epoch:47, iter:3498] Loss: 0.489 | Accuracy: 99.935% \n",
      "[epoch:47, iter:3499] Loss: 0.489 | Accuracy: 99.936% \n",
      "[epoch:47, iter:3500] Loss: 0.489 | Accuracy: 99.938% \n",
      "[epoch:47, iter:3501] Loss: 0.489 | Accuracy: 99.939% \n",
      "[epoch:47, iter:3502] Loss: 0.489 | Accuracy: 99.940% \n",
      "[epoch:47, iter:3503] Loss: 0.489 | Accuracy: 99.941% \n",
      "[epoch:47, iter:3504] Loss: 0.489 | Accuracy: 99.942% \n",
      "[epoch:47, iter:3505] Loss: 0.489 | Accuracy: 99.943% \n",
      "[epoch:47, iter:3506] Loss: 0.489 | Accuracy: 99.944% \n",
      "[epoch:47, iter:3507] Loss: 0.489 | Accuracy: 99.945% \n",
      "[epoch:47, iter:3508] Loss: 0.489 | Accuracy: 99.946% \n",
      "[epoch:47, iter:3509] Loss: 0.489 | Accuracy: 99.947% \n",
      "[epoch:47, iter:3510] Loss: 0.489 | Accuracy: 99.948% \n",
      "[epoch:47, iter:3511] Loss: 0.489 | Accuracy: 99.949% \n",
      "[epoch:47, iter:3512] Loss: 0.489 | Accuracy: 99.950% \n",
      "[epoch:47, iter:3513] Loss: 0.489 | Accuracy: 99.950% \n",
      "[epoch:47, iter:3514] Loss: 0.489 | Accuracy: 99.951% \n",
      "[epoch:47, iter:3515] Loss: 0.489 | Accuracy: 99.952% \n",
      "[epoch:47, iter:3516] Loss: 0.489 | Accuracy: 99.953% \n",
      "[epoch:47, iter:3517] Loss: 0.489 | Accuracy: 99.953% \n",
      "[epoch:47, iter:3518] Loss: 0.489 | Accuracy: 99.954% \n",
      "[epoch:47, iter:3519] Loss: 0.489 | Accuracy: 99.955% \n",
      "[epoch:47, iter:3520] Loss: 0.488 | Accuracy: 99.955% \n",
      "[epoch:47, iter:3521] Loss: 0.488 | Accuracy: 99.956% \n",
      "[epoch:47, iter:3522] Loss: 0.488 | Accuracy: 99.957% \n",
      "[epoch:47, iter:3523] Loss: 0.488 | Accuracy: 99.957% \n",
      "[epoch:47, iter:3524] Loss: 0.488 | Accuracy: 99.958% \n",
      "[epoch:47, iter:3525] Loss: 0.488 | Accuracy: 99.958% \n",
      "Waiting Test!\n",
      "EPOCH=047, Loss: 0.646, Accuracy= 94.408%\n",
      "Training complete in 0m 12s\n",
      "EarlyStopping counter: 26 out of 30\n",
      "\n",
      "Epoch: 48\n",
      "[epoch:48, iter:3526] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3527] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3528] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3529] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3530] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3531] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3532] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3533] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3534] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3535] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3536] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3537] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3538] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3539] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3540] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3541] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3542] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3543] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3544] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3545] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3546] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3547] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3548] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3549] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3550] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3551] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3552] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3553] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3554] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3555] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3556] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3557] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3558] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3559] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3560] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3561] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3562] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3563] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3564] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3565] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3566] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3567] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3568] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3569] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3570] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3571] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3572] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3573] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3574] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3575] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3576] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3577] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3578] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3579] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3580] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3581] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3582] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3583] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3584] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3585] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3586] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3587] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3588] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3589] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3590] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3591] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3592] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3593] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3594] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3595] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:48, iter:3596] Loss: 0.488 | Accuracy: 99.956% \n",
      "[epoch:48, iter:3597] Loss: 0.488 | Accuracy: 99.957% \n",
      "[epoch:48, iter:3598] Loss: 0.488 | Accuracy: 99.957% \n",
      "[epoch:48, iter:3599] Loss: 0.488 | Accuracy: 99.958% \n",
      "[epoch:48, iter:3600] Loss: 0.488 | Accuracy: 99.958% \n",
      "Waiting Test!\n",
      "EPOCH=048, Loss: 0.651, Accuracy= 94.079%\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 27 out of 30\n",
      "\n",
      "Epoch: 49\n",
      "[epoch:49, iter:3601] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3602] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3603] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3604] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3605] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3606] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3607] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3608] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3609] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3610] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3611] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3612] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3613] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3614] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3615] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3616] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3617] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3618] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:49, iter:3619] Loss: 0.491 | Accuracy: 99.836% \n",
      "[epoch:49, iter:3620] Loss: 0.491 | Accuracy: 99.844% \n",
      "[epoch:49, iter:3621] Loss: 0.491 | Accuracy: 99.851% \n",
      "[epoch:49, iter:3622] Loss: 0.490 | Accuracy: 99.858% \n",
      "[epoch:49, iter:3623] Loss: 0.490 | Accuracy: 99.864% \n",
      "[epoch:49, iter:3624] Loss: 0.490 | Accuracy: 99.870% \n",
      "[epoch:49, iter:3625] Loss: 0.490 | Accuracy: 99.875% \n",
      "[epoch:49, iter:3626] Loss: 0.490 | Accuracy: 99.880% \n",
      "[epoch:49, iter:3627] Loss: 0.490 | Accuracy: 99.884% \n",
      "[epoch:49, iter:3628] Loss: 0.490 | Accuracy: 99.888% \n",
      "[epoch:49, iter:3629] Loss: 0.490 | Accuracy: 99.892% \n",
      "[epoch:49, iter:3630] Loss: 0.490 | Accuracy: 99.896% \n",
      "[epoch:49, iter:3631] Loss: 0.490 | Accuracy: 99.899% \n",
      "[epoch:49, iter:3632] Loss: 0.490 | Accuracy: 99.902% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:49, iter:3633] Loss: 0.490 | Accuracy: 99.905% \n",
      "[epoch:49, iter:3634] Loss: 0.489 | Accuracy: 99.908% \n",
      "[epoch:49, iter:3635] Loss: 0.489 | Accuracy: 99.911% \n",
      "[epoch:49, iter:3636] Loss: 0.489 | Accuracy: 99.913% \n",
      "[epoch:49, iter:3637] Loss: 0.489 | Accuracy: 99.916% \n",
      "[epoch:49, iter:3638] Loss: 0.489 | Accuracy: 99.918% \n",
      "[epoch:49, iter:3639] Loss: 0.489 | Accuracy: 99.920% \n",
      "[epoch:49, iter:3640] Loss: 0.489 | Accuracy: 99.922% \n",
      "[epoch:49, iter:3641] Loss: 0.490 | Accuracy: 99.848% \n",
      "[epoch:49, iter:3642] Loss: 0.490 | Accuracy: 99.851% \n",
      "[epoch:49, iter:3643] Loss: 0.490 | Accuracy: 99.855% \n",
      "[epoch:49, iter:3644] Loss: 0.490 | Accuracy: 99.858% \n",
      "[epoch:49, iter:3645] Loss: 0.490 | Accuracy: 99.861% \n",
      "[epoch:49, iter:3646] Loss: 0.490 | Accuracy: 99.864% \n",
      "[epoch:49, iter:3647] Loss: 0.490 | Accuracy: 99.867% \n",
      "[epoch:49, iter:3648] Loss: 0.490 | Accuracy: 99.870% \n",
      "[epoch:49, iter:3649] Loss: 0.489 | Accuracy: 99.872% \n",
      "[epoch:49, iter:3650] Loss: 0.489 | Accuracy: 99.875% \n",
      "[epoch:49, iter:3651] Loss: 0.489 | Accuracy: 99.877% \n",
      "[epoch:49, iter:3652] Loss: 0.489 | Accuracy: 99.880% \n",
      "[epoch:49, iter:3653] Loss: 0.489 | Accuracy: 99.882% \n",
      "[epoch:49, iter:3654] Loss: 0.489 | Accuracy: 99.884% \n",
      "[epoch:49, iter:3655] Loss: 0.489 | Accuracy: 99.886% \n",
      "[epoch:49, iter:3656] Loss: 0.489 | Accuracy: 99.888% \n",
      "[epoch:49, iter:3657] Loss: 0.489 | Accuracy: 99.890% \n",
      "[epoch:49, iter:3658] Loss: 0.489 | Accuracy: 99.892% \n",
      "[epoch:49, iter:3659] Loss: 0.489 | Accuracy: 99.894% \n",
      "[epoch:49, iter:3660] Loss: 0.489 | Accuracy: 99.896% \n",
      "[epoch:49, iter:3661] Loss: 0.489 | Accuracy: 99.898% \n",
      "[epoch:49, iter:3662] Loss: 0.489 | Accuracy: 99.899% \n",
      "[epoch:49, iter:3663] Loss: 0.490 | Accuracy: 99.851% \n",
      "[epoch:49, iter:3664] Loss: 0.490 | Accuracy: 99.854% \n",
      "[epoch:49, iter:3665] Loss: 0.490 | Accuracy: 99.856% \n",
      "[epoch:49, iter:3666] Loss: 0.490 | Accuracy: 99.858% \n",
      "[epoch:49, iter:3667] Loss: 0.489 | Accuracy: 99.860% \n",
      "[epoch:49, iter:3668] Loss: 0.489 | Accuracy: 99.862% \n",
      "[epoch:49, iter:3669] Loss: 0.489 | Accuracy: 99.864% \n",
      "[epoch:49, iter:3670] Loss: 0.489 | Accuracy: 99.866% \n",
      "[epoch:49, iter:3671] Loss: 0.489 | Accuracy: 99.868% \n",
      "[epoch:49, iter:3672] Loss: 0.489 | Accuracy: 99.870% \n",
      "[epoch:49, iter:3673] Loss: 0.489 | Accuracy: 99.872% \n",
      "[epoch:49, iter:3674] Loss: 0.489 | Accuracy: 99.873% \n",
      "[epoch:49, iter:3675] Loss: 0.507 | Accuracy: 99.873% \n",
      "Waiting Test!\n",
      "EPOCH=049, Loss: 0.646, Accuracy= 94.408%\n",
      "Epoch 00049: reducing learning rate of group 0 to 1.7294e-05.\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 28 out of 30\n",
      "\n",
      "Epoch: 50\n",
      "[epoch:50, iter:3676] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3677] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3678] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3679] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3680] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3681] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3682] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3683] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3684] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3685] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3686] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3687] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3688] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3689] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3690] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3691] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3692] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3693] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3694] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3695] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3696] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3697] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3698] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3699] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3700] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3701] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3702] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3703] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3704] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3705] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3706] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3707] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3708] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3709] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3710] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3711] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3712] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3713] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3714] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3715] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3716] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3717] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3718] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3719] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3720] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3721] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3722] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3723] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3724] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3725] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3726] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3727] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3728] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3729] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3730] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3731] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3732] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3733] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3734] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3735] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3736] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3737] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3738] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3739] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3740] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3741] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3742] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3743] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3744] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3745] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3746] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3747] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3748] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3749] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:50, iter:3750] Loss: 0.487 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=050, Loss: 0.659, Accuracy= 94.079%\n",
      "Training complete in 0m 13s\n",
      "EarlyStopping counter: 29 out of 30\n",
      "\n",
      "Epoch: 51\n",
      "[epoch:51, iter:3751] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3752] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3753] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3754] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3755] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3756] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3757] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3758] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3759] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3760] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3761] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3762] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3763] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3764] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3765] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3766] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3767] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3768] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3769] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3770] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3771] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3772] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3773] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3774] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3775] Loss: 0.488 | Accuracy: 100.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:51, iter:3776] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3777] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3778] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3779] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3780] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3781] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3782] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3783] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3784] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3785] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3786] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3787] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3788] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3789] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3790] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3791] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3792] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3793] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3794] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3795] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3796] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3797] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3798] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3799] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3800] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3801] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3802] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3803] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3804] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3805] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3806] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3807] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3808] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3809] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3810] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3811] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3812] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3813] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3814] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3815] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3816] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3817] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3818] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3819] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3820] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3821] Loss: 0.487 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3822] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3823] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3824] Loss: 0.488 | Accuracy: 100.000% \n",
      "[epoch:51, iter:3825] Loss: 0.488 | Accuracy: 100.000% \n",
      "Waiting Test!\n",
      "EPOCH=051, Loss: 0.663, Accuracy= 94.408%\n",
      "Training complete in 0m 14s\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Early Stopping!\n",
      "Training Finished, TotalEPOCH=51\n",
      "The whole training process complete in 11m 16s\n"
     ]
    }
   ],
   "source": [
    "losses_train, accs_train, losses_val, accs_val = train_net(pre_epoch=0,\n",
    "                                                           EPOCH = 200,\n",
    "                                                           early_patience = 30,\n",
    "                                                           training_loader=training_loader,\n",
    "                                                           validation_loader = validation_loader,\n",
    "                                                           net=net,\n",
    "                                                           optimizer=optimizer,\n",
    "                                                           scheduler=scheduler,\n",
    "                                                           criteria=criteria,\n",
    "                                                           device=device\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bea51d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676.1945205032825\n"
     ]
    }
   ],
   "source": [
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8fad5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABsRUlEQVR4nO3dd3yT1f4H8M+T2XS30AkFCpQhsgTEAg72EAREkHEVFMUBKqD3/uQqMhw4EVGvXu5VuCpDQcEFSgUF2chWoOxZ2lJKd5umyfn98TRpQ1fSZjX5vF+vvPLkyfM8OTlNm2/P+Z5zJCGEABEREZGXUri7AERERETOxGCHiIiIvBqDHSIiIvJqDHaIiIjIqzHYISIiIq/GYIeIiIi8GoMdIiIi8moMdoiIiMirMdghIiIir8Zgh4icRpIkzJ071+7zzp07B0mSsGzZMoeXiYh8D4MdIi+3bNkySJIESZKwbdu2Cs8LIRAXFwdJkjB06FA3lNAx1q9fD0mSEBsbC5PJ5O7iEJEHYbBD5CP8/PywYsWKCvu3bNmCS5cuQavVuqFUjrN8+XI0a9YMV65cwebNm91dHCLyIAx2iHzEkCFDsHr1apSUlFjtX7FiBbp06YLo6Gg3lazu8vPz8e2332LmzJno3Lkzli9f7u4iVSk/P9/dRSDyOQx2iHzEuHHjcO3aNSQlJVn2FRcXY82aNRg/fnyl5+Tn5+PZZ59FXFwctFotWrdujbfffhtCCKvj9Ho9ZsyYgYiICAQFBeGee+7BpUuXKr3m5cuX8fDDDyMqKgparRbt2rXDp59+Wqf3tnbtWhQWFmL06NEYO3YsvvnmGxQVFVU4rqioCHPnzkWrVq3g5+eHmJgY3HvvvTh9+rTlGJPJhPfeew/t27eHn58fIiIiMGjQIPzxxx8Aqs8nujFHae7cuZAkCUePHsX48eMRFhaGXr16AQAOHz6MSZMmoXnz5vDz80N0dDQefvhhXLt2rdI6mzx5MmJjY6HVahEfH48nnngCxcXFOHPmDCRJwrvvvlvhvB07dkCSJKxcudLeKiXyKip3F4CIXKNZs2ZITEzEypUrMXjwYADAhg0bkJ2djbFjx2Lx4sVWxwshcM899+DXX3/F5MmT0alTJ/z888/4+9//jsuXL1t9uT7yyCP44osvMH78ePTo0QObN2/G3XffXaEMaWlpuO222yBJEqZNm4aIiAhs2LABkydPRk5ODqZPn16r97Z8+XL07t0b0dHRGDt2LJ5//nl8//33GD16tOUYo9GIoUOHYtOmTRg7diyeeeYZ5ObmIikpCX/++SdatGgBAJg8eTKWLVuGwYMH45FHHkFJSQl+//137Nq1C127dq1V+UaPHo2EhAS89tprlkAxKSkJZ86cwUMPPYTo6Gj89ddfWLJkCf766y/s2rULkiQBAFJSUnDrrbciKysLU6ZMQZs2bXD58mWsWbMGBQUFaN68OXr27Inly5djxowZFeolKCgIw4cPr1W5ibyGICKvtnTpUgFA7N27V3zwwQciKChIFBQUCCGEGD16tOjdu7cQQoimTZuKu+++23LeunXrBADxyiuvWF3vvvvuE5IkiVOnTgkhhDh48KAAIJ588kmr48aPHy8AiDlz5lj2TZ48WcTExIiMjAyrY8eOHStCQkIs5Tp79qwAIJYuXVrj+0tLSxMqlUr85z//sezr0aOHGD58uNVxn376qQAgFi5cWOEaJpNJCCHE5s2bBQDx9NNPV3lMdWW78f3OmTNHABDjxo2rcKz5vZa3cuVKAUBs3brVsu/BBx8UCoVC7N27t8oy/fvf/xYAxLFjxyzPFRcXi4YNG4qJEydWOI/I17Abi8iHjBkzBoWFhfjhhx+Qm5uLH374ocourPXr10OpVOLpp5+22v/ss89CCIENGzZYjgNQ4bgbW2mEEPj6668xbNgwCCGQkZFhuQ0cOBDZ2dnYv3+/3e9p1apVUCgUGDVqlGXfuHHjsGHDBly/ft2y7+uvv0bDhg3x1FNPVbiGuRXl66+/hiRJmDNnTpXH1Mbjjz9eYZ9Op7NsFxUVISMjA7fddhsAWOrBZDJh3bp1GDZsWKWtSuYyjRkzBn5+fla5Sj///DMyMjLwt7/9rdblJvIWDHaIfEhERAT69euHFStW4JtvvoHRaMR9991X6bHnz59HbGwsgoKCrPa3bdvW8rz5XqFQWLqBzFq3bm31+OrVq8jKysKSJUsQERFhdXvooYcAAOnp6Xa/py+++AK33norrl27hlOnTuHUqVPo3LkziouLsXr1astxp0+fRuvWraFSVd17f/r0acTGxiI8PNzuclQnPj6+wr7MzEw888wziIqKgk6nQ0REhOW47OxsAHKd5eTk4Oabb672+qGhoRg2bJjVaLvly5ejUaNG6NOnjwPfCVH9xJwdIh8zfvx4PProo0hNTcXgwYMRGhrqktc1z33zt7/9DRMnTqz0mA4dOth1zZMnT2Lv3r0AgISEhArPL1++HFOmTLGzpNWrqoXHaDRWeU75VhyzMWPGYMeOHfj73/+OTp06ITAwECaTCYMGDarVPEEPPvggVq9ejR07dqB9+/b47rvv8OSTT0Kh4P+0RAx2iHzMyJEj8dhjj2HXrl348ssvqzyuadOm+OWXX5Cbm2vVunP8+HHL8+Z7k8lkaTkxS05OtrqeeaSW0WhEv379HPJeli9fDrVajc8//xxKpdLquW3btmHx4sW4cOECmjRpghYtWmD37t0wGAxQq9WVXq9Fixb4+eefkZmZWWXrTlhYGAAgKyvLar+5pcsW169fx6ZNmzBv3jy89NJLlv0nT560Oi4iIgLBwcH4888/a7zmoEGDEBERgeXLl6N79+4oKCjAAw88YHOZiLwZQ34iHxMYGIiPPvoIc+fOxbBhw6o8bsiQITAajfjggw+s9r/77ruQJMkyost8f+NorkWLFlk9ViqVGDVqFL7++utKv7yvXr1q93tZvnw5br/9dtx///247777rG5///vfAcAy7HrUqFHIyMio8H4AWEZIjRo1CkIIzJs3r8pjgoOD0bBhQ2zdutXq+X/96182l9scmIkbhvDfWGcKhQIjRozA999/bxn6XlmZAEClUmHcuHH46quvsGzZMrRv397uljIib8WWHSIfVFU3UnnDhg1D79698cILL+DcuXPo2LEjNm7ciG+//RbTp0+35Oh06tQJ48aNw7/+9S9kZ2ejR48e2LRpE06dOlXhmq+//jp+/fVXdO/eHY8++ihuuukmZGZmYv/+/fjll1+QmZlp83vYvXs3Tp06hWnTplX6fKNGjXDLLbdg+fLl+L//+z88+OCD+OyzzzBz5kzs2bMHt99+O/Lz8/HLL7/gySefxPDhw9G7d2888MADWLx4MU6ePGnpUvr999/Ru3dvy2s98sgjeP311/HII4+ga9eu2Lp1K06cOGFz2YODg3HHHXfgzTffhMFgQKNGjbBx40acPXu2wrGvvfYaNm7ciDvvvBNTpkxB27ZtceXKFaxevRrbtm2z6oZ88MEHsXjxYvz666944403bC4Pkddz30AwInKF8kPPq3Pj0HMhhMjNzRUzZswQsbGxQq1Wi4SEBPHWW29ZhjybFRYWiqefflo0aNBABAQEiGHDhomLFy9WGIothDxUfOrUqSIuLk6o1WoRHR0t+vbtK5YsWWI5xpah50899ZQAIE6fPl3lMXPnzhUAxKFDh4QQ8nDvF154QcTHx1te+7777rO6RklJiXjrrbdEmzZthEajEREREWLw4MFi3759lmMKCgrE5MmTRUhIiAgKChJjxowR6enpVQ49v3r1aoWyXbp0SYwcOVKEhoaKkJAQMXr0aJGSklJpnZ0/f148+OCDIiIiQmi1WtG8eXMxdepUodfrK1y3Xbt2QqFQiEuXLlVZL0S+RhLihnZUIiKqtzp37ozw8HBs2rTJ3UUh8hjM2SEi8hJ//PEHDh48iAcffNDdRSHyKGzZISKq5/7880/s27cP77zzDjIyMnDmzBn4+fm5u1hEHoMtO0RE9dyaNWvw0EMPwWAwYOXKlQx0iG7Alh0iIiLyamzZISIiIq/GYIeIiIi8GicVhLxmT0pKCoKCguq0sjERERG5jhACubm5iI2NrXYdOAY7AFJSUhAXF+fuYhAREVEtXLx4EY0bN67yeQY7gGWRw4sXLyI4ONhh1zUYDNi4cSMGDBhQ5cKDVHesZ9dhXbsG69k1WM+u4cx6zsnJQVxcnNVixZVhsANYuq6Cg4MdHuz4+/sjODiYv0hOxHp2Hda1a7CeXYP17BquqOeaUlCYoExERERejcEOEREReTUGO0REROTVGOwQERGRV2OwQ0RERF6NwQ4RERF5NQY7RERE5NUY7BAREZFXY7BDREREXo3BDhEREXk1twY7W7duxbBhwxAbGwtJkrBu3Tqr54UQeOmllxATEwOdTod+/frh5MmTVsdkZmZiwoQJCA4ORmhoKCZPnoy8vDwXvgsiIiLyZG4NdvLz89GxY0d8+OGHlT7/5ptvYvHixfj444+xe/duBAQEYODAgSgqKrIcM2HCBPz1119ISkrCDz/8gK1bt2LKlCmuegtERETk4dy6EOjgwYMxePDgSp8TQmDRokV48cUXMXz4cADAZ599hqioKKxbtw5jx47FsWPH8NNPP2Hv3r3o2rUrAOD999/HkCFD8PbbbyM2NtZl74WIAIPRhMz8YvhrlAjUqmpcnM9XmEwC+hITCg1GFBmMUCkl6NRK+KmVUCu9P5tACIGCYiNyi0pQYjI55JpqpQJ+aiV0aiXUSqnOnzUhBEpMAiVGAYPJhBKjQInRBINJQAKgUkpQKxRQlt6rlBJUioqvW911hBB1KqOZJElQKySolApLuaoqj7MIIX+mc4oMKC6p/mdaUlKCTL3898Fd66167KrnZ8+eRWpqKvr162fZFxISgu7du2Pnzp0YO3Ysdu7cidDQUEugAwD9+vWDQqHA7t27MXLkyEqvrdfrodfrLY9zcnIAyCuzGgwGh70H87UceU2qiPVcvTx9Cf5KyUGhwQijUcBgkv/4lpjK/iiXmEwwmgS0KiX81OYvEfnevK1VKyGZjDifB/x4+DLS80qQml2EK9lFuJJThCtZRbiap4ep9O+5SiEh1F+NMH81Qv01CCvdDvPXIFingtEoUGgwochgRFGJUd4ulreLDCboS0wI1CoRqtMgLECNUF3Z+aH+aoT6qxGiUyOnsAQZeXqk5+qRkVeMq3l6ZOQWIz1Pj4xcPa7lF0OpkCq8Jz+1whJwWG2rSt+/pvR9q+QvVK1agSKDEXn6EuQWybc8femtyIhcvQF5eiMKiuWARr7JAY6+mi8DVbmyac33KgWys5X415kdMFp+TqbSn5388yoxCSgk+QtOZf7iU0hQKyWozF9+Sqm0/KXvW6WETlMWJGhVCug0Ze9bp1bCr/R9+6lKf/YauQ6KjSbklb7n3HL3lm19CfKKyu7LH5enL7F8LpxBIcHy8yv/M5YkwFAabBhNN3z2jQIGownFBiVm7kqCsZaBiFz3EoSA5WflTiqFBGXpraawx/x7Uf7zX/Y5lLeFAHJv+Jmbf6YGoz3vVYXuiblIiHZscG/r332PDXZSU1MBAFFRUVb7o6KiLM+lpqYiMjLS6nmVSoXw8HDLMZVZsGAB5s2bV2H/xo0b4e/vX9eiV5CUlOTwa/o6IYBMPXA2V8LZXAlphQq8/9fmGs8xlt5M5bbL7xMC0CoBPyWgUwF+SiFvKwGtCtCVPtYoALUSUCvkbY1CQK0oe+ynBPzc9NtlNAHn8oAT2QokZ0s4nweYhCP/21MBR/6q8lkJAgISSkwCGXnFyMgrBpDvwNevLc8IhpWSkD9rpV9FJSZR+uVx45ESkO9d+YcSBFQO+CgKyL+z5jo0CSC/2Ij8YmOtSiVfsbJnBBSl5TVW8TtUYkOAY76Oo77mTYDVZ8je8pSXU1RSp7JIEFBKqDGwAoDt27fjpK5OL1dBQUGBTcd5bLDjTLNmzcLMmTMtj3NychAXF4cBAwYgODjYYa9jMBiQlJSE/v37Q+2utjsvUVxiwtErOThwMRv7L2Rh/4UspOdW+HZwiDyr3/3a/2VuGKhBq8hAJEQFyveRgWgZGYggB0dBQgicTM/D9tOZ2HH6Gvaeu17hj36jUD+E+quhUihK//OXoFSYm8DlVgGlJKHYWNbVYmmVMBgtLTD6EhMCVCY0iwhBbKgOMSF+iAn1Q0ywn7wd4ocGARroS0zIKjTgekExsgoMuF5gQFZBMTILDMgqMCCn0ACVUlFlK5KfWgmNUoE8fUnpufK1rhcY5OvmFyOr0IDsQgOC/dSICNSgYZAWEUFaeTtQvo8I0qJBgAZCoLT1SH5fReXeU6HBWNqiVO6xoeJ2kcEEP7UCQX4qBGpVlvtArQqBfioElW77a0tbUNSVt5IpFRKEECguMaGopGJ9FxmMyC8sxoGDB3Frl1ug1agtXRRqpQJKS0uO3Jpg1V1iKm31Kd02GE0otrxGJe/bYEJhaWua3lB5Wcz1olYqEKRVIaDce7e+VyLIT11aJ+Zt+d78vE6tdFg3ixACBqMoey8lcsuguSWt0GCEELDUnUph3eWjVEiAyYhdO7aj9513QKdVV/ydUEhWr2cSqNDCZii9lyBV8loVr+NIxkpa/AxGAaNJ2NRSVVJaf0U31F/53wUACNKqrX7GQaWf+UCtCgEaJRQ1vD9nfheae2Zq4rHBTnR0NAAgLS0NMTExlv1paWno1KmT5Zj09HSr80pKSpCZmWk5vzJarRZarbbCfrVa7ZSgxFnX9WZGk8CRy9n4LTkdO05dw6FLWRW6AlQKCe0ahaBz42CUXD2LW7t0hlJZ/Udapbyhmf+GP4CSBOTf2DxfZLA0z+cWyU30ZV8K8h+EQoMRhcUm6A1GFBiMMFpaNTKx40ymVRkaheqQEBWI1lFBaBUVhNbRQWgZGQg/tdKmuskuNODIpWwcupSFQxezcOBiFq7eEPiFB2jQo0UD9GrZED1bNkRcuGNaLA0GA9avX48hQ26r9jOt1QLBAX5o4pBX9U4aDRBYxXMGgwHF5w/gzjZR/NtRDQ2AgDq0FBgMBpz0Axo3CKyX9VzfSuyM70Jbr+exwU58fDyio6OxadMmS3CTk5OD3bt344knngAAJCYmIisrC/v27UOXLl0AAJs3b4bJZEL37t3dVXSvpi8x4mRaHlKzixAZrEVMiA4NAzUO+W/tWp4eW09exW/JV/H7yQxk5hdbPR/qr0aXJmHo0iwMXZqEoWNcKPzUytIv4DMYfHO0x/zBytOX4FR6Hk6k5iI5LRcnSm9pOXpczirE5axC/JZ81XK8JAFNw/0twU9CVBBaRwUhNtQPJ9LycLg0sDl8KRtnMip2CfmpFbg1vgF6tWyAni0bom10cI3/bRER+Qq3Bjt5eXk4deqU5fHZs2dx8OBBhIeHo0mTJpg+fTpeeeUVJCQkID4+HrNnz0ZsbCxGjBgBAGjbti0GDRqERx99FB9//DEMBgOmTZuGsWPHciSWA2QXGnDsSg7+SsnB0ZQc/JWSjVPpeRX6gzUqhaULIzZEJ3drhOgQGaSFWqWwtJqUb1FRlyZTXi8oxpYTGdiSnI7Dl7NRvuU1SKtCz5YNcWfrCNwaH47mDQPqzeieQK0KneJC0Sku1Gp/doEBJ9JzkZxaFgAlp+bieoEB564V4Ny1Amw8mlbj9ZuE+6ND4xB0igtFh8ah6BgXAq3KtpYhIiJf49Zg548//kDv3r0tj815NBMnTsSyZcvwj3/8A/n5+ZgyZQqysrLQq1cv/PTTT/Dz87Ocs3z5ckybNg19+/aFQqHAqFGjsHjxYpe/F3c7l5GPbacyEOqvRkSgFpHBfogI0iJAU3UfuRACmfnFuJJdhJSsQsv9uWv5OHolBxczCys9L9RfjcZhOqTn6HE1T4/iEhPOXyvA+Wu2JYpVp21MMO5qHYG7WkXglqZhXjcsN8RfjW7NwtGtWbhlnxByl9fJtLJWoOTUXJxMy0OuvgQNA7Xo2DgEHeNC0aFxCDo0DkV4gMaN74KIqH5xa7Bz1113VTvvgCRJmD9/PubPn1/lMeHh4VixYoUzildvrD9yBc9+dciSTFaeTq1ERJAWkaXJm35qZelwYTm4qW5ILAA0DtPhpphgtIsNwU2xwWgXG4yYED9LAFVcYkJaTunw4+xCpGSV3Wfk6WEwmiwJlMZywz3NyZMapQK3NW+AO1tF4M7WEYgK9qu2PN5IkiQ5sTZIix4tG1r2CyGQU1SCYD/OV0NEVBcem7NDNTOZBBb9cgKLN8tdge1igxGgUeFqnh7pOUXIL82sv5BZgAuZVbe6RARpERsidz3FhurQKEyHtjFBaBcTghD/6nNgNCoF4sL9HZYAS2UkSUKIzjNykIiI6jMGO/VUnr4EM748iKTS/I5HesXj+cFtoCrX7ZOvL5ts7WrpraDYiOgQLWJLA5uoYD9oVN7VVURERFQeg5166Py1fDz62R84kZYHjUqBBSPbY1SXxhWOCyidE6NpgwA3lJKIiMgzMNipZ7afysDUFfuRVWBAZJAW/36gCzo3CXN3sYiIiDwWg516QgiBZTvO4ZUfj8FoEugYF4olD3TxyYReIiIiezDYqQf0JUbMXvcnvvrjEgDg3s6N8Nq97W2ecZeIiMiXMdjxcCaTwBNf7Mfm4+lQSMA/h7TF5F7xHIpMRERkIwY7Hu6zneew+Xg6tCoFljzYFXe2inB3kYiIiOoVjjn2YCfScrFgw3EAwAt3t2WgQ0REVAsMdjyUvsSI6asOQl9iwp2tIvDAbU3dXSTydad/hfLL8YjKPuDukhAR2YXdWB5qYdIJHL2Sg/AADd4a3YE5OuQ+xhLgt9eA3xdCAYHuSIJpbxTQ4wl3l6xm+lzg6HdAs15AGP9hIPJVDHY80M7T17Bk6xkAwIJ72yMyiMPLyU2yLgJfPwJc3AUAMEV3hCL1EJQbnwfyU4G+cwCFBzYQCwEcWQ1snA3kpQKaIGDYIqD9fc59XX0eoFQDKq1zX4eI7MJgx8NkFxrw7FcHIQRwf9c4DGwX7e4ika86vh5Y9wRQlAVog4Fh78HYaiiOL30CN11ZA2xfBOSkAMM/BFQetAp76hFg/T+ACzvkxyodUJwLfD0ZOLsFGPQGoHHwWm4FmcCvrwF/fCI/DokDGrQsvbUovbWU9ys4ZQSRqzHY8TBzvv0TKdlFaNrAHy8Nu8ndxSFfVKIHkuYAuz+SH8d2Bu5bCoTHAwYDTkbfg1Zd74Lqx+nAka+AvDTg/s8BvxC3Ftsq4BAmOci541ngtieBbe8CW98G9n8GXNwLjF4KRLat+2uajMCBz4Ff5gGFmWX7s87Lt9ObrI9XaoCweEAbWO1llULgjqwsKNMWAXXpwpYUwE0jgMSpdbtOdUwm4FSSXLemEjmoC29eFuwFxTiu9e/6OeDERrlehaniawU38syWRnI7Bjse5NuDl7HuYAqUCgnv3t8JAVr+eDyOPhc49QuQMADQeOGaY9dOA2seAq4ckh/fNhXoN7dCy43oMBYIiQW+elBuLVk6BJiwBgiOqf76QgDpR4GLe4CINkDjboCyjp/zygKOm0YAA14BQuPkx31elPN2vpkCXD0GLOkNDHkT6PxA7YOAi3uB9c8BVw7KjyPaAIPfACJvAq6dKnc7Ld8yzwBGPZCRXOOlFQDCAKCgdkWzcmmv/J6HLpK72ByluAA4tBLY9RFw7WTVx6n9gfAW1i1c5pt/ePWvYSwBLu0BTvwEnPgZuHrc+vmTG60fq/xKX6s0ANJVf32FyYgWaceh2HWm7i1uutCy9xUQ4bzgsipCAHnpQOZp+XMnTKV10RIIira9PEIA+Rlln19TSdnPLSjGvusUXAOunYaUnoy2KRsBY39A7cDPoB34beohLmcV4sV1fwIApvVuiVu43pXnEQJYNUH+cm/SA/jbGu8KeI6sAb6fLnf56MKAER8DrQdVfXzLvsCkH4EVY4C0P4H/9gP+9jUQ2cb6OEMhcPZ34OTP8hdW9sWy53RhQMv+QKuB8vV0dnzuTSb5i3DD/5ULONrKAUfzOyse3/wu4PFtwNrHgNObge+eAs5sAYa+C/gF2/66eenAL3OBg8vlx9pg4K5ZwK2PlgUTgZFA0x43lNcIZF+Sg54SfbUvUWIswR9//IGuXbtCVZdgMP0osPll4MAXQG4aMHpZja1KNcq5Auz9D/DHp0DhdXmfNhi45UG5leXa6bIvyuvnAEMBkHZEvt1IF1YWIJgDovDmQMZJOcA59YvcjWomKYEmiUCrAfJrWoLJ0tcqKQLS/5JvNlACuBkAUupUIxVpgioGduYArK4toEXZpe/7TMWguji38nPUAZWUp4Uc4JmD8fLX0WdXcR3/0p/RDddSqkuDrNPWZSqSr6MC0AqAIfsC4Nem8ms7GYMdD2AyCTz71UHkFpWgU1wopvVp6e4iUWWOrJEDHUDOB1k5Dhj/JaDWubdcdWEyAsnrgZ3/KstxadIDGPVfIKRRzefHdgImJwFfjJL/u/90ADBuFRDWTA5sTvwMnPkNKCksO0flBzTqAqT9JX9ZHvlKvklKoMltcuCTMBCIaC0fX5Bp/QfU8kf1dNl1Kws4KhMYCUz4Ws432vwK8OcaIGW/3E0X26n692o0AHv+A/y2ANDnyPs6TZBbvgIja64rhVIeEWbDqDBhMCDtpBEiYWDd/hNuPUhucVrzsNzVtOxuYMJq28p7oyuH5M/Jn18DJoO8L6wZ0P0JoPMEQBtU8RyjAbh+vqy1IeNk2c8v57L887+0V75VxdaA2FgCZF+w/sItzq/2LZlMJly6fAmNGzWGoi7dX0IA+Vfl18y6IAcdVw6WBeHlBUSUy+UqFzCExQPq0sEohiLg+tlKWghPya9TJQkIbSJfT1LIdX39PGDIB1IPyzebSHKraIOWgEIlv7Y5cE09It9sFRIHU3hznM9VobHCPa06AIMdj/DfbWew60wm/DVKvHt/J6iV7HP2OIVZwM+z5O32Y+QA4ewWuRvn/uWelaBrC30ucGC5nJdz/Zy8T6ECes0A7nzevq6lsKbA5I3AyrHAxd3AsqGAMFofE9xI/rJqNQhodrucIGzVRbFR7mo5v12+Jb0kn1Ocb/2f/Y0UaqDDGNsDDkDO6bh9JtC0p5y0nHkG+KQ/EHVz9U30eVflL1MAiOkEDHkbiOtm22u6U5shwMTvgZX3y1++n/SXA76GNvxTZTLJLXI7PwTO/V62v0kPIPFJoPWQ6rt/lGr5dRq2BDDQ+rniArnub/wyzzwDBEbJrTetBsldnbZ0MSlVcqtQeHMgoX/NxwMwGgw4sH49YoYMgcJR3SuGIvl3yhKYl763jJNAfrocrORfBS7svOFEqazbNesiAFH1awREAg0TKgmYmlUcCVhSLOePVRY4mYyVdy+WD7zMbgxczbeMU4Cx+IaE/JZlrXRqHYwGAw6vX4/GoU3qVrd1wGDHzY6m5OCtn+U+/JeG3oT4hl7ULeJs+jwg8wyk9GTEXdvj3P7gzS/Lf6AatgKGfyD/J/rFfXLOwJqH5O4BR+ZDOEvWRWDPv4F9n5U1VfuFAl0flltFgmNrd13/cODBb+Vh6sd/ACDJX1LmACeqXcVAQqmSu3qa9gD6z5f/kJ7cKAc/Z3+X//M3C4mrpPm8BRDatPY5P026A49tBb6dBiT/KLfw1Pg+GwB9X5JzferTqKq4bqUtcPfKX8Sf9AfGf1V1sFacDxxcIefjZJ6W9ylUQLuRcsJ3o1vqXiaNPxB9s3zzJmo/uSv3xu5cACjKsW6ZLB806HPkViEzbcgNQUiLst8Be7pdVRo5MGqYULf3VV3gWg8w2HGz+T/8BYNRoF/bKNzfLc7dxfFM104DGScq/leSewWA/CG+BUDJn+2Brg86/vUv7wP2lg4pvvsd+T+nZr2AcSuAFWPlL/e1jwH3/sdzvwAv7QN2fgAc/bas1aVBS+C2J4CO4xyTe6TWAWM+l1t3GiYAAQ3tOz+sqRxw3fqo/GV7eb8cRIXFO36ouJl/ODB2uRy8FmRWf6xCKQdwulDnlMXZGrSQA54VY4CUA8D/hgH3fSq3/JhlXwb2LAH2LStrUfMLAbpMAm6dAoQ0dkPBvYhfsDy6Mbaz9f7yScFAaZJzQ9cnOXsxBjtuZDQJHLiQBQB4fnBrzpJcmd/ekGfvrYp/AwhJCSk/HZKNSYl2MRmBH2YAEECH+4H4O8qea9EHGPMZ8OUEOY9BqZXnnPGUoa8moxyI7fyXZVJAAHI3UuI0eUSZo8uqUABNE+t+HU0AEH973a9jC0kC4m51zWu5W2AkMPEHYPUkOYfnywlyAB/bWf6c/PWNPPoGkLsguj8BdBpf96Rmqp4kAYER8o2cgsGOG52/lg99iQl+agXiG/KPSaXOb5fvw5vLeRLl+4TDmwP+4TDt+jeUP/0Dkjn3xJH2/ldOzPQLkYcy36j1IPm/49UPAYdWyK0+Q991739kRTny6JvdH8t99YCc29L+PrkLIqaD+8pG7qcNBMatBH6YLn9Ofphh/XzTXnI+TqtBnttSSWQnBjtudDxVHibYOioISgVbdSpVcE2+H/IW0LJfpYeIsHgAgHT9rGNfO+cKsOllebvvnKoTYG8aDoz8N/DNo8C+pfJoo0ELXB/wZF0Adv9bntzNPFpIFwZ0nSx3DQVxNm4qpVQD93wABDcGtrwu5+PcPEoOhmsalUZUDzHYcaPjV+QvpDbRdiSb+Zr8DPnev+r8D3Owg6zz8ugRR3XN/PxPeQhpo65Al4eqP7bDaHnCuG+nyiOc1H5ygOSKgOfSH6X5ON+Vy8dJkP877zDWefkuVL9JEtB7FtB2qDwcmsEweTEGO250zNyyE13J/BRUNgMnUH2ya0hjmKCEoqRIXvSxtiOKyju1Sc5fkBTA0IW2BVCd/yZPoLf+OXl5gtAm8ignZzq4Elj3eNnj+DvlfJyW/Twnd4g8W3R7d5eAyOn419CNkkuDnTYxDHYqVZRdNnlZNS07UKhQoGkgb2eeqfvrGorkgAUAbn0MiOlo+7m3Pgr0mS1vJ82RZ611FiGA7e/J222GyrMDT/xOnp+EgQ4RkQX/IrpJnr4EFzLlhW/YjVUFcxeWJqjiBFc3HqqNkjcyHZC3s+1dOWgKigF6/9P+83vNkEe36HOAjS/UvTxVSTkgT8Sn8pNHgfE/dCKiSjHYcRNzq05UsBbhAfVs9l1XKSgNdgIa1HyotjR5uK5JyhmngG0L5e1BC+ybvMtMoSwdkaUAjqwGTv9atzJV5eAK+b7N0Po79wsRkQsw2HGT46lycnJrtupUzYbkZMuh5mCnLt1YQgDrn5WnPm/ZT145u7ZiOwPdHpG3f3xW7hpzpBK9HEgB8jwoRERUJQY7bmJu2WnL5OSqWVp2bAl2HNCN9ddaedFKlZ881L2uI6n6vCiv8ZN5uiy3xlGSN8gz3AbFyqt5ExFRlRjsuMnxK0xOrpE9LTsac8vOWbmFpjb+/Fq+T5wqT1hYV34hwMDS2Z9/f0de5sJRzF1YHcdy4jciohow2HEDIQSOpXKOnRpZhp3XnLNj6cbSZwOF12v3elePy/fNHLhMwc2j5JYXo14e4VXbQKy83FR5qn8A6DSh7tcjIvJyDHbcICW7CLlFJVApJLSI4DIRVbKjZcek0EAExcgPatOVZSgqy/eJbGv/+VWRJODuhfK6Wac3y11ldXX4S0CYgLjupSsQExFRdRjsuEFyaatOi4hAaFT8EVTJjpwdABBhzeSN2ozIunZKDiD8QuQ8G0dq0EIejg4AP82S166qLSHKurCYmExEZBN+07rBMebr2Cb/qnwfYONKwKGly0bUZkSWuQsroo1zlnjoNUPOA8pLBX59tfbXSdkvl1XlB7Qb6bjyERF5MQY7bmBeAJT5OjXIL83Z8a85ZwcARLg52KlFy87VZPk+orX959pC7Qfc/Y68vWcJkHKwdtcxt+q0HSa3QhERUY0Y7LhB2QKgbNmpkhCu7cYq37LjLC36AO3ulbvLfpgBmIz2nW8o4tw6RES1wGDHxfQlRpzJyAfAbqxq6XPlyf0AmxKUAQChzeT7unZjOdPA1wBtsNwdtW+pfecmr5fXCwtuJC/4SURENmGw42Kn0vNgNAmE6NSIDq5+vSefZm7VUfsDGn+bThFhpd1YeWlAcb7tr1VSXDYHjrODneAYebJBAPhlvn0LhVrm1hnHuXWIiOzAYMfFLJMJRgdBckYirLew5OvY2KoDyOtD6cLk7evnbD8v8zQgjPKCo8Gxtp9XW90eAWI6yXMCrRpn2+isnCvA6U3yNruwiIjswmDHxY6nMl/HJnYsAmolrBYjsixdWK2dMxLrRgolMPLfcmB2eR+wYkzNLVGWuXVuk4eyExGRzRjsuJhlJFYMR2JVy44JBa2Yl3mwZ0RWemmwE+nkLqzyItsAD6wDtCHAhZ3AyrGAobDyYzm3DhFRnTDYcbGyYeds2amWZY4de4Od0pYde0ZkuSo5+UaxnYC/fQ1oAoGzW4EvH5BXM7/R5X1ARjKg0nFuHSKiWmCw40IZeXpczdVDkoBWUQx2qmVZF8vOYKdW3VjmOXZcHOwAQFw3YPxXciBzKglY8zBgNFgfc3C5fH/TPYAfWwSJiOzFYMeFkktbdZqE+yNAq3JzaTycq7qxjAZ5qQjAeRMK1qRZT2DcSnn9rOM/AN9MKZuDx1AEHCldjZ1dWEREtcJgx4XYhWUHOycUtDB3Y2VflIeU1yTzDGAyyF1JIXH2vZYjtegN3P85oFADf30DfDsVMJmA5B/lUVvBjYFmd7ivfERE9RibF1yobOZkdkXUqLYtO4FR8tw8hgI54Klp5JI5X6dhK9eMxKpOq4HAfZ8CqycBh1YCKi2QdVF+rtM4QMH/TYiIaoN/PV3I3LLTljMn16y2OTuSVC5vx4auLHfm61TmpnuAe5cAkIB9y8rm1uk4zp2lIiKq1xjsuIjRJHAiTQ52WrNlp2aWlh0759kByrqybElSLj/Hjqdofx8w/MOyx016cG4dIqI6YDeWi5y7lg99iQk6tRJNwm1b/sBnFecDJaVzztjbsgMA9iwI6mktO2adJwCmEmDrW8Dtz7q7NERE9RqDHRcxLxPRKjoISgWXiaiWuVVHqZUTh+1l64gsYwmQcULeduWEgrbqMlG+ERFRnbAby0XMy0S05UismuWXG4lVm6RhW7uxrp+TV1ZX6YCQJva/DhER1QsMdlzk2BVzvg6DnRrVdti5mTlB+fo5efh2VSz5Oq040omIyIvxL7yLJKdx2LnNajvs3CwkDlCoAKMeyL1S9XHuWiaCiIhcisGOC+QWleBippxwywkFbVDXlh2lCggt7ZaqriuLwQ4RkU9gsOMCJ9PzAADRwX4IC9C4uTT1QF1bdoByXVnVJCkz2CEi8gkMdlzAPJkg83VsZJlQsBZz7JjVNCLLZAQyTsrbnjTHDhERORyDHRc4kSa37LThzMm2cUTLTk0jsrLOAyVFgMqvbF4eIiLySgx2XCC5dObktkxOtk1dc3aAmruxzJMJNkwAFMravw4REXk8BjtOJgRwPJUtO3bJvyrf16llx9yNdU7+Idwo/Zh8z3wdIiKvx2DHya4XA3n6EqiVEpo3rMVswL4ov5aLgJYX1lS+12cDBZkVn7csE8F8HSIib8dgx8lSCuQZgFtEBEKjYnXXyFAIGPLl7boEO2odEBQrb1fWlcWRWEREPoPfvk6WUvq9zfl1bGROTlaoAW0dc5yqGpFlMpWticVgh4jI6zHYcTJzy06bGCYn26SgjutilRfeTL6/cURW9gXAUAAoNWWJzERE5LUY7DiZJdhhy45tzPk6dUlONqtqRJY5X6dBgjzbMhEReTUGO06kNxhxVV4lgmti2crSslOHCQXNqurGsuTrMDmZiMgXMNhxolNX82GChFCdGlHBWncXp35wxISCZlVNLGgZicV8HSIiX8Bgx4nMkwm2jg6EVNf8k/qouMD+c8xz7NRlJJaZuRsrPx3Q55XtN8+xE8lgh4jIFzDYcaLk0skEW0f5YL7OL/OA1+OAlAP2nVfgwJYdXSigC5e3r5+T74Vgyw4RkY9hsONEyWnmYMcHJxM8vwMwlQBntth3niMmFCzvxq6s7EvyPD4KVVlODxEReTWPDnaMRiNmz56N+Ph46HQ6tGjRAi+//DJEuen/hRB46aWXEBMTA51Oh379+uHkyZNuLHWZsm4sH2zZKSydtfjaKfvOc8S6WOXdOCLLMhKrJaBUO+Y1iIjIo3l0sPPGG2/go48+wgcffIBjx47hjTfewJtvvon333/fcsybb76JxYsX4+OPP8bu3bsREBCAgQMHoqioyI0ll4Ow/z5wCya0MKJVpA+27BSUttBUtep4VRyZoAxUHJHFkVhERD7HoycZ2bFjB4YPH467774bANCsWTOsXLkSe/bsASAHFIsWLcKLL76I4cOHAwA+++wzREVFYd26dRg7dqzbyi5JEtrFBuN8pIBO42OraptMQOF1edvulh0nd2NdNS8A2tYx1yciIo/n0cFOjx49sGTJEpw4cQKtWrXCoUOHsG3bNixcuBAAcPbsWaSmpqJfv36Wc0JCQtC9e3fs3LmzymBHr9dDr9dbHufk5AAADAYDDAaDw8pvvpYjr1kvFGZBLUzydl4aDHmZgNaGrrwSPdT60p+FJgSwsd6qq2cpOA4qACLzLEoMBijTj0MBoCS8JYSv/VwcwGc/0y7GenYN1rNrOLOebb2mRwc7zz//PHJyctCmTRsolUoYjUa8+uqrmDBhAgAgNTUVABAVFWV1XlRUlOW5yixYsADz5s2rsH/jxo3w9/d34DuQJSUlOfyanixAn4Z+5R5v//5zZPs3q/E8v+JMDARgggLrN28HJPt6WSurZ60hC4MAIPsifvrhWwy68hcUALYeS0fuufV2XZ/K+Npn2l1Yz67BenYNZ9RzQYFtU5x4dLDz1VdfYfny5VixYgXatWuHgwcPYvr06YiNjcXEiRNrfd1Zs2Zh5syZlsc5OTmIi4vDgAEDEBzsuJmODQYDkpKS0L9/f6jVvpMMK13eBxwte9yrbTREuyE1n5h6GPgLkAIaYsjdQ21+vWrrWQiI5FmQDPkYfHM4VIcKISQlbh8+EVBxokd7+epn2tVYz67BenYNZ9azuWemJh4d7Pz973/H888/b+mOat++Pc6fP48FCxZg4sSJiI6OBgCkpaUhJibGcl5aWho6depU5XW1Wi202opfdGq12ikfeGdd12MVW3/4VFnnAFvevz4LgBzs1Ka+qqznsGZA+l9Qnf5Fvn6DFlDrfDBp3IF87jPtJqxn12A9u4Yz6tnW63n0aKyCggIoFNZFVCqVMJnkfJD4+HhER0dj06ZNludzcnKwe/duJCYmurSsVI552LlZ5mnbzjMnJ/s7YF2s8sxJysml3VYciUVE5FM8umVn2LBhePXVV9GkSRO0a9cOBw4cwMKFC/Hwww8DkEc8TZ8+Ha+88goSEhIQHx+P2bNnIzY2FiNGjHBv4X1ZQWmwo9IBJYW2j8gyDzsPiHBsecJvmGuHMycTEfkUjw523n//fcyePRtPPvkk0tPTERsbi8ceewwvvfSS5Zh//OMfyM/Px5QpU5CVlYVevXrhp59+gp+fnxtL7uPMLTuxnYELO+RgRwigpvXBHD2hoJl5YkEzBjtERD7Fo4OdoKAgLFq0CIsWLaryGEmSMH/+fMyfP991BaPqmVt2GneRg52ibHlfQA3dU46eUNDsxmUhGOwQEfkUj87ZoXrK3LIT3AgIbixv29KVZZlQ0Ek5O4A8nL1BS8den4iIPBqDHXI8c8uOLhxo0ELetiVJ2VktO8GN5YU/AblLS80uTiIiX8JghxzP3LLjXy7Ysallx0k5O0oVENpU3mYXFhGRz2GwQ45XULouli68rMvIlmAn/6p87+iWHaCsK4vDzomIfA6DHXI8S8tOWLlgp4bVz40GOZEZcHzLDgB0uB8IbQLcNNzx1yYiIo/m0aOxqB4yFAGG0rVKdOFAeLmcHZMJUFQRX5uTkyEBujDHl6vDGPlGREQ+hy075FjmVh1JCfiFAGFN5W1DAZB7perzLMnJDQCF0vnlJCIin8FghxzLMhIrTJ5EUKmW16YCqh+R5azkZCIi8nkMdsixyo/EMrNlRJazhp0TEZHPY7BD1rIuAn9+LefX1Eb5OXbMLEnK1bXsOGlCQSIi8nkMdsjaj88Cax4GTm+u3fnVtuxUE+ywZYeIiJyEwQ5Zyzgh35tXCLdXZS074bZ0Y5XOscOcHSIicjAGO1RGiLIRU3lptbtGYemEgv7lho+bu7GunwOMJZWfV8CWHSIicg4GO1Sm8DpQUiRv56XX7hqVtewENwJUfoDJAGRfqPy8fObsEBGRczDYoTI5KWXbtQ12KsvZUSiA8ObydlV5O2zZISIiJ2GwQ2XKBzv5DmzZAWpOUjYnKAdE1O51iYiIqsBgh8rklm/ZuVq7a1TWsgNUn6RsMpbl+jBBmYiIHIzBDpWx6sZKkxOW7VVly041q58XZAIQlZ9HRERURwx2qEz5YMeoB/Q59p1vMgFFWfL2jS075mCnsiUjzPk6ujBAybVpiYjIsRjsUJnywQ5gf1dWURYgSmderipnJ+uivDJ6eeY5dpicTERETsBgh8rcuCq5vXPtmPNuNIGASmP9XEAEoA0GICpOWJjPRUCJiMh5GOxQmZzL8r2udEJAe0dkVZWvA8groFc1Isu8LpY/59ghIiLHY7BDsuJ8oChb3o7pJN/bO9eOZSRWWOXPVzUiiy07RETkRAx2SJZT2oWlCSxrgbE32KmuZQeoOkmZEwoSEZETMdghmXmOnaAYIDBK3ra3G6uqOXbMLMPPbwh2OKEgERE5EYMdkplHYgXHAoGR8nZtW3aqyr1pYF4y4oZuLHPODruxiIjICRjskKx8sBNQy2CnsIZuLHPOTl4aoM8t229u2WGCMhEROQGDHZI5tGWnimBHF1rWVVW+K8s8zw5bdoiIyAkY7JDMPMdOUExZsJOfbt+SEebuqOqWfLhxRJbJVC7Xh8EOERE5HoMdkpnn2AluVNaNZSwuG45uC/OkglUNPQfKjcg6U3aOedZldmMREZETMNghmXnoeXAMoPYDtCHyY3u6smoaeg6Um1iwtGXHPOxcG1Jx1mUiIiIHYLBDgNFQtjREcCP5PrA0t8ae4ec1DT0HKgY7lmHnbNUhIiLnYLBDpYGOABTqsrwZy4gsG9fHKi4ASkoX+Ky2Zcc8184pOR+ogHPsEBGRczHYobIurKAYQFH6kbCMyLJx5XNzq45CBWiDqj4uLF6+L8qWu73yOXsyERE5F4MdKpecHFO2r/yILFuUz9eRpKqP0/gDwY3l7czT5SYUZDcWERE5B4Mdsh52bhZoZzeWLfk6ZuXzdsxz7LBlh4iInITBDlkPOzcLsLMby5aRWGZWwQ5XPCciIudSubsA5AHKDzs3c2rLTrkFQTmhIBERORmDHbJeKsLMkrNja8tO6YSCumomFDQrH+yYJxRkzg4RETkJgx0CckuDnaBywU75xUCFqD7pGLCvZce8ZETmaUATWHoeW3aIiMg5mLPj64Qo141VScuOyVC2DER17MnZCWsKSErAUFA22os5O0RE5CQMdnxdQSZg1Mvb5UdjqbSAX+mSEbZ0ZdnTsqNUA2HNrPexZYeIiJyEwY6vM4/ECoiouDZV+a6smtjTsgOUjcgCAE2QvB4XERGREzDY8XWVzbFjFhgl39syIsuelh2gLEkZYHIyERE5FYMdX1fZHDtmlsVAbejGqkvLDruwiIjIiRjs+LrK5tgxs3UxUJNRXusKsL1lJ7xcsMPkZCIiciIGO76usjl2zGxdDLQwC4CQt22ZZwew7sZiyw4RETkRgx1fV9kcO2a2LgZqztfRBssjrWwR3AhQlSYlM2eHiIiciMGOr6u2ZcfGBGVLvo6NrToAoFAA4c3lbbbsEBGREzHY8XWVTShoFlCaoFxjN5adI7HMGneV7yPb2nceERGRHbhchC/T5wH60sTi6nJ28tMBk0lujamMvSOxzAa9AXR7BIjuYN95REREdrC7ZadZs2aYP38+Lly44IzykCuZ59jRBAHaoIrPm1t2TCVAUVbV16lty47GH4jpWPO6W0RERHVgd7Azffp0fPPNN2jevDn69++PVatWQa/XO6Ns5GyWOXYqadUBSpeMCJW3q5tFubYtO0RERC5Qq2Dn4MGD2LNnD9q2bYunnnoKMTExmDZtGvbv3++MMpKzVDfHjpktScq1bdkhIiJygVonKN9yyy1YvHgxUlJSMGfOHPz3v/9Ft27d0KlTJ3z66acQQjiynOQM1c2ebGbJ26kmSZktO0RE5MFqnaBsMBiwdu1aLF26FElJSbjtttswefJkXLp0Cf/85z/xyy+/YMWKFY4sKzladetimVlGZFXXsnNdvmfLDhEReSC7g539+/dj6dKlWLlyJRQKBR588EG8++67aNOmjeWYkSNHolu3bg4tKDlBdXPsmFm6sWzJ2bFjnh0iIiIXsTvY6datG/r374+PPvoII0aMgFpdccbc+Ph4jB071iEFJCeyKdixYTFQ5uwQEZEHszvYOXPmDJo2bVrtMQEBAVi6dGmtC0UuklvNhIJmNSUoC8GcHSIi8mh2Jyinp6dj9+7dFfbv3r0bf/zxh0MKRS5gNJR1TVW2LpaZZeXzKrqxDAWAsXTqAbbsEBGRB7I72Jk6dSouXrxYYf/ly5cxdepUhxSKXCA3FYAAlBrAv5qFOGvqxjK36ijUgCbQoUUkIiJyBLuDnaNHj+KWW26psL9z5844evSoQwpFLmDO1wmKrnoZCMA6Qdlkqvh8+XwdzoRMREQeyO5gR6vVIi2tYv7GlStXoFJxqa16I9ecnFzNHDtA2dBzYSwbYl4e83WIiMjD2R3sDBgwALNmzUJ2drZlX1ZWFv75z3+if//+Di0cOZGlZaeaOXYAQKkuC2QqS1LmSCwiIvJwdjfFvP3227jjjjvQtGlTdO7cGQBw8OBBREVF4fPPP3d4AclJbBl2bhYYKQc1+ekAbrJ+jnPsEBGRh7M72GnUqBEOHz6M5cuX49ChQ9DpdHjooYcwbty4SufcIQ9lT7ATEAFcPQ7kVZKkzNmTiYjIw9UqySYgIABTpkxxdFnIlWyZY8esurl2Cq7J98zZISIiD1XrjOKjR4/iwoULKC4uttp/zz331LlQ5ALmRUCrm2PHzLIYaCVz7RQwZ4eIiDxbrWZQHjlyJI4cOQJJkiyrm0ulw46NRqNjS0iOZzKVzrMD23N2gMonFizkaCwiIvJsdo/GeuaZZxAfH4/09HT4+/vjr7/+wtatW9G1a1f89ttvTigiOVzBNcBYDECS59mpSXWzKLNlh4iIPJzdwc7OnTsxf/58NGzYEAqFAgqFAr169cKCBQvw9NNPO7yAly9fxt/+9jc0aNAAOp0O7du3t1qWQgiBl156CTExMdDpdOjXrx9Onjzp8HJ4FfMcO4GR8tDymlTXjcWWHSIi8nB2BztGoxFBQUEAgIYNGyIlRf7ibNq0KZKTkx1auOvXr6Nnz55Qq9XYsGEDjh49infeeQdhYWXDnN98800sXrwYH3/8MXbv3o2AgAAMHDgQRUVFDi2LV7F1jh2z6rqxCjgai4iIPJvdOTs333wzDh06hPj4eHTv3h1vvvkmNBoNlixZgubNmzu0cG+88Qbi4uKsVlCPj4+3bAshsGjRIrz44osYPnw4AOCzzz5DVFQU1q1bh7Fjxzq0PF4jx8bZk83M3Vj5GYDJCCiU8mNjCaAvnVySLTtEROSh7A52XnzxReTn5wMA5s+fj6FDh+L2229HgwYN8OWXXzq0cN999x0GDhyI0aNHY8uWLWjUqBGefPJJPProowCAs2fPIjU1Ff369bOcExISgu7du2Pnzp1VBjt6vR56vd7yOCcnBwBgMBhgMBgcVn7ztRx5TUdQZF2CEoAxMAomW8qmCYEKEiRhhCEnrWwJifyrMHeCGdSBgJvep6fWszdiXbsG69k1WM+u4cx6tvWakjAPp6qDzMxMhIWFWUZkOYqfnx8AYObMmRg9ejT27t2LZ555Bh9//DEmTpyIHTt2oGfPnkhJSUFMTFmXzJgxYyBJUpXB19y5czFv3rwK+1esWAF/f3+HvgdP1Pn8f9Ak83ccjRmNk9HDbDpn0JGp0JbkYnObV5GriwMABBZdRt9js2BQ+mN9h4+dWWQiIqIKCgoKMH78eGRnZyM4OLjK4+xq2TEYDNDpdDh48CBuvvlmy/7wcOd0YZhMJnTt2hWvvfYaAHll9T///NMS7NTWrFmzMHPmTMvjnJwcxMXFYcCAAdVWlr0MBgOSkpLQv39/j5pdWrniEyATaNX1LiR0GGLTOapLjYCrx3HHLW0g4u8EAEgXdwHHAFVwFIYMse06zuCp9eyNWNeuwXp2Ddazazizns09MzWxK9hRq9Vo0qSJy+bSiYmJwU03Wa/F1LZtW3z99dcAgOhoedh0WlqaVctOWloaOnXqVOV1tVottFpthf1qtdopH3hnXbfWSufYUYXFAbaWKzAKuHocqsJrZecUyx8yyT/cI96fx9WzF2Nduwbr2TVYz67hjHq29Xp2j8Z64YUX8M9//hOZmZl2F8pePXv2rDDC68SJE2jatCkAOVk5OjoamzZtsjyfk5OD3bt3IzEx0enlq7fsWRfLrLLh5wUcdk5ERJ7P7gTlDz74AKdOnUJsbCyaNm2KgIAAq+f379/vsMLNmDEDPXr0wGuvvYYxY8Zgz549WLJkCZYsWQJAnrV5+vTpeOWVV5CQkID4+HjMnj0bsbGxGDFihMPK4VWKcoDiXHnb1qHnQOUTCxZyQkEiIvJ8dgc7rgwiunXrhrVr12LWrFmYP38+4uPjsWjRIkyYMMFyzD/+8Q/k5+djypQpyMrKQq9evfDTTz9ZkpvpBuYFQLUhgDbQ9vMqm2uHLTtERFQP2B3szJkzxxnlqNLQoUMxdOjQKp+XJAnz58/H/PnzXViqeszShWVHqw5QeTcWW3aIiKgesDtnh+q52uTrADW07IRVPJ6IiMhD2N2yo1Aoqp1Ph6ueezjzulhBdgY7lebscKkIIiLyfHYHO2vXrrV6bDAYcODAAfzvf/+rdKI+8jA5pTk7tW3ZKSi3ZARzdoiIqB6wO9gxr0FV3n333Yd27drhyy+/xOTJkx1SMHKS2ubs+DcEIAHCBBRck4Mf5uwQEVE94LCcndtuu81qvhvyULl2LgJqplQB/g3k7bx0QAi27BARUb3gkGCnsLAQixcvRqNGdn6BkuuZW3bsmWPHLDBKvs9LA4rzAFPpAmxs2SEiIg9mdzfWjQt+CiGQm5sLf39/fPHFFw4tHDlYSTGQf1XetrdlBwACI4B0yNcwt+ootYDa+xdPJSKi+svuYOfdd9+1CnYUCgUiIiLQvXt3hIVxCLJHM08oqNTWrjWm/Iis8vk6Dl7tnoiIyJHsDnYmTZrkhGKQS5iDneCY2gUolrl20pivQ0RE9YbdOTtLly7F6tWrK+xfvXo1/ve//zmkUOQkOZfle3vn2DGzzKJ8lXPsEBFRvWF3sLNgwQI0bNiwwv7IyEi89tprDikUOUlt59gxK5+gzNmTiYionrA72Llw4QLi4+Mr7G/atCkuXLjgkEKRk9R2jh2zgAj5Pu8q59ghIqJ6w+5gJzIyEocPH66w/9ChQ2jQoIFDCkVOUts5dszKLwbKnB0iIqon7A52xo0bh6effhq//vorjEYjjEYjNm/ejGeeeQZjx451RhnJUXJT5fug6Nqdb+7Gys8oG8LOlh0iIvJwdo/Gevnll3Hu3Dn07dsXKpV8uslkwoMPPsicHU9nbo3xr2ULnH8DQFLIS0ZknJT3sWWHiIg8nN3BjkajwZdffolXXnkFBw8ehE6nQ/v27dG0aVNnlI8cqShLvvcLrd35CqW8RlZ+OpBxQt7Hlh0iIvJwdgc7ZgkJCUhISHBkWcjZirLle11o7a8RGCkHO0Z96bUY7BARkWezO2dn1KhReOONNyrsf/PNNzF69GiHFIqcwFAElBTJ234htb+OeUSWGVt2iIjIw9kd7GzduhVDhgypsH/w4MHYunWrQwpFTmDuwpIUgCao9tcxJymbsWWHiIg8nN3BTl5eHjQaTYX9arUaOTk5DikUOUFhlnzvFwIo6rDYfWD5lh2pbl1iRERELmD3t1779u3x5ZdfVti/atUq3HTTTQ4pFDlBXZOTzcq37PiFyEnLREREHszuBOXZs2fj3nvvxenTp9GnTx8AwKZNm7BixQqsWbPG4QUkB3FEcjJQtvI5wHwdIiKqF+wOdoYNG4Z169bhtddew5o1a6DT6dCxY0ds3rwZ4eH88vNY5bux6qJ8NxbzdYiIqB6o1dDzu+++G3fffTcAICcnBytXrsRzzz2Hffv2wWg0OrSA5CDO6MZiyw4REdUDtc5U3bp1KyZOnIjY2Fi888476NOnD3bt2uXIspEjmVt2HNmNxZYdIiKqB+xq2UlNTcWyZcvwySefICcnB2PGjIFer8e6deuYnOzpHNWy4x9etmQEW3aIiKgesLllZ9iwYWjdujUOHz6MRYsWISUlBe+//74zy0aO5KgEZYWybGJBtuwQEVE9YHPLzoYNG/D000/jiSee4DIR9ZGjEpQBuSsrLw3wD6v7tYiIiJzM5padbdu2ITc3F126dEH37t3xwQcfICMjw5llI0dyVDcWAES1k+8j2tT9WkRERE5mc7Bz22234T//+Q+uXLmCxx57DKtWrUJsbCxMJhOSkpKQm5vrzHJSXTkqQRkAhi4EHvsdaNqz7tciIiJyMrtHYwUEBODhhx/Gtm3bcOTIETz77LN4/fXXERkZiXvuuccZZSRHcGTLjiYAiOkASFLdr0VERORkdVgkCWjdujXefPNNXLp0CStXrnRUmcgZHNmyQ0REVI/UKdgxUyqVGDFiBL777jtHXI4czWgADPnytiNadoiIiOoRhwQ75OHMw84Bx4zGIiIiqkcY7PgCcxeWNpirlBMRkc9hsOMLHJmcTEREVM8w2PEFluRkdmEREZHvYbDjC9iyQ0REPozBji+wBDts2SEiIt/DYMcXcI4dIiLyYQx2fAG7sYiIyIcx2PEFbNkhIiIfxmDHF5gnFWTLDhER+SAGO76A3VhEROTDGOz4AnZjERGRD2Ow4wvYskNERD6MwY4vKCzN2WHLDhER+SAGO97OZAT0TFAmIiLfxWDH2+lzyrY5gzIREfkgBjvezpycrPYHVBq3FoWIiMgdGOx4OyYnExGRj2Ow4+047JyIiHwcgx1vx5YdIiLycQx2vJ1lqQgmJxMRkW9isOPt2I1FREQ+jsGOt2M3FhER+TgGO96OLTtEROTjGOx4O7bsEBGRj2Ow4+2YoExERD6OwY63YzcWERH5OAY73o7dWERE5OMY7Hg7tuwQEZGPY7DjzYQol7MT6taiEBERuQuDHW+mzwWEUd5mgjIREfkoBjvezNyqo9QAap17y0JEROQmDHa8WfnkZElyZ0mIiIjchsGON2NyMhEREYMdr8Zh50RERAx2vBpbdoiIiBjseDUuFUFERFS/gp3XX38dkiRh+vTpln1FRUWYOnUqGjRogMDAQIwaNQppaWnuK6QnYTcWERFR/Ql29u7di3//+9/o0KGD1f4ZM2bg+++/x+rVq7FlyxakpKTg3nvvdVMpPQy7sYiIiOpHsJOXl4cJEybgP//5D8LCwiz7s7Oz8cknn2DhwoXo06cPunTpgqVLl2LHjh3YtWuXG0vsIdiyQ0REBJW7C2CLqVOn4u6770a/fv3wyiuvWPbv27cPBoMB/fr1s+xr06YNmjRpgp07d+K2226r9Hp6vR56vd7yOCcnBwBgMBhgMBgcVm7ztRx5TXsoC65DAaBEEwThpjK4grvr2Zewrl2D9ewarGfXcGY923pNjw92Vq1ahf3792Pv3r0VnktNTYVGo0FoaKjV/qioKKSmplZ5zQULFmDevHkV9m/cuBH+/v51LvONkpKSHH5NW9yeeg7hAPb/dQpXLq93SxlcyV317ItY167BenYN1rNrOKOeCwoKbDrOo4Odixcv4plnnkFSUhL8/Pwcdt1Zs2Zh5syZlsc5OTmIi4vDgAEDEBwc7LDXMRgMSEpKQv/+/aFWqx12XVupLrwM5AO39OwD0bSXy1/fVdxdz76Ede0arGfXYD27hjPr2dwzUxOPDnb27duH9PR03HLLLZZ9RqMRW7duxQcffICff/4ZxcXFyMrKsmrdSUtLQ3R0dJXX1Wq10Gq1Ffar1WqnfOCddd0alQ49VwU2BHzgF9lt9eyDWNeuwXp2Ddazazijnm29nkcHO3379sWRI0es9j300ENo06YN/u///g9xcXFQq9XYtGkTRo0aBQBITk7GhQsXkJiY6I4iew4hmKBMREQEDw92goKCcPPNN1vtCwgIQIMGDSz7J0+ejJkzZyI8PBzBwcF46qmnkJiYWGVyss8wFALGYnmbQ8+JiMiHeXSwY4t3330XCoUCo0aNgl6vx8CBA/Gvf/3L3cVyP3OrjqQENIFuLQoREZE71btg57fffrN67Ofnhw8//BAffvihewrkqcovFSFJ7i0LERGRG9WLSQWpFjh7MhEREQAGO96LyclEREQAGOx4L7bsEBERAWCw470sLTshbi0GERGRuzHY8VaWBOVQtxaDiIjI3RjseCt2YxEREQFgsOO9mKBMREQEgMGO92LLDhEREQAGO96LLTtEREQAGOx4r/IzKBMREfkwBjveit1YREREABjseC92YxEREQFgsOOdSooBQ4G8zZYdIiLycQx2vJG5VQcSoGXODhER+TYGO97InK+jDQYU/BETEZFv4zehNzKPxNKxVYeIiIjBjjdicjIREZEFgx1vxGHnREREFgx2vBFbdoiIiCwY7Hgjc8sOZ08mIiJisOOVzC077MYiIiJisOOV2I1FRERkwWDHGzFBmYiIyILBjjeyrHge6tZiEBEReQIGO97IkqAc6s5SEBEReQQGO97IMoNyqFuLQURE5AkY7HgjJigTERFZMNjxNiYjoM+Rt9myQ0RExGDH65i7sABOKkhERAQGO96n8Lp8rw4AlGr3loWIiMgDMNjxNpw9mYiIyAqDHW/DOXaIiIisMNjxNpw9mYiIyAqDHW/DYedERERWGOx4G7bsEBERWWGw420sLTscdk5ERAQw2PE+TFAmIiKywmDH27Abi4iIyAqDHW/DBGUiIiIrDHa8DVt2iIiIrDDY8TZMUCYiIrLCYMfbmFt22I1FREQEgMGOdzGZAH2OvM1uLCIiIgAMdrxLcS4gTPI2W3aIiIgAMNjxLuYuLJUfoPZza1GIiIg8BYMdb8LkZCIiogoY7HgTJicTERFVwGDHm5iXimByMhERkQWDHW/C2ZOJiIgqULm7AORAnD2ZiAhGoxEGg6HG4wwGA1QqFYqKimA0Gl1QMt9Ul3pWq9VQKpV1LgODHW/CBGUi8mFCCKSmpiIrK8vm46Ojo3Hx4kVIkuTcwvmwutZzaGgooqOj6/QzYrDjTZigTEQ+zBzoREZGwt/fv8YvR5PJhLy8PAQGBkKhYFaHs9S2noUQKCgoQHp6OgAgJiam1mVgsONNmKBMRD7KaDRaAp0GDRrYdI7JZEJxcTH8/PwY7DhRXepZp9MBANLT0xEZGVnrLi3+dL0JE5SJyEeZc3T8/f3dXBJyNPPP1JY8rKow2PEmTFAmIh/H3Bvv44ifKYMdb8KWHSIin9asWTMsWrTI3cXwOMzZ8SaWBGWOxiIiqi/uuusudOrUySFByt69exEQEFD3QnkZBjveQoiylh12YxEReQ0hBIxGI1Sqmr+yIyIiXFCi+ofdWN7CUACYSuRtdmMREdULkyZNwpYtW/Dee+9BkiRIkoRly5ZBkiRs2LABXbp0gVarxbZt23D69GkMHz4cUVFRCAwMRLdu3fDLL79YXe/GbixJkvDf//4XI0eOhL+/PxISEvDdd9+5+F26H4Mdb2HuwlKoAA2bMImIhBAoKC6p9lZYbKzxGHtvQgiby/jee+8hMTERjz76KK5cuYIrV64gLi4OAPD888/j9ddfx7Fjx9ChQwfk5eVhyJAh2LRpEw4cOIBBgwZh2LBhuHDhQrWvMW/ePIwZMwaHDx/GkCFDMGHCBGRmZtapbusbdmN5i/LJyRyNQESEQoMRN730s8tf9+j8gfDX2Pb1GhISAo1GA39/f0RHRwMAjh8/DgCYP38++vfvbzk2PDwcHTt2tDx++eWXsXbtWnz33XeYNm1ala8xadIkjBs3DgDw2muvYfHixdizZw8GDRpk93urr9iy4y2YnExE5FW6du1q9TgvLw/PPfcc2rZti9DQUAQGBuLYsWM1tux06NDBsh0QEIDg4GDLrMS+gi073oLJyUREVnRqJY7OH1jl8yaTCbk5uQgKDnLoDMo6dd0XrgRQYVTVc889h6SkJLz99tto2bIldDod7rvvPhQXF1d7HbVabfVYkiSYTCaHlLG+YLDjLcxLRTA5mYgIgPylXl13kslkQolGCX+Nyq3LRWg0GptWA9++fTsmTZqEkSNHApBbes6dO+fk0nkHdmN5C86eTERULzVr1gy7d+/GuXPnkJGRUWWrS0JCAr755hscPHgQhw4dwvjx432uhaa2GOx4C86eTERULz333HNQKpW46aabEBERUWUOzsKFCxEWFoYePXpg2LBhGDhwIG655RYXl7Z+YjeWt2CCMhFRvdSqVSvs3LnTat+kSZMqHNesWTNs3rzZat/UqVOtHt/YrVXZMPisrKxalbM+Y8uOu107DRz7QZ4BuS6YoExERFQpBjvuZCgC/ncP8OUE4PCXdbsWE5SJiIgqxWDHnfYtBXIuydu/zAOKC2p3HSGAnMvyNlt2iIiIrHh0sLNgwQJ069YNQUFBiIyMxIgRI5CcnGx1TFFREaZOnYoGDRogMDAQo0aNQlpamptKbAd9HvD7O/K2UgPkpgA7P6jdtY5+C6Qeka8Ty2Q1IiKi8jw62NmyZQumTp2KXbt2ISkpCQaDAQMGDEB+fr7lmBkzZuD777/H6tWrsWXLFqSkpODee+91Y6lttPtjIP8qEBYP3FMa5Gx7F8i5Yt919LnAT8/L271mAKFxji0nERFRPefRo7F++uknq8fLli1DZGQk9u3bhzvuuAPZ2dn45JNPsGLFCvTp0wcAsHTpUrRt2xa7du3Cbbfd5o5i16wwC9ixWN7u/U+g/Whg73+BS3uAza8AIz60/Vq/vgbkXpGDpl4znVJcIiKi+syjg50bZWfLSbjh4eEAgH379sFgMKBfv36WY9q0aYMmTZpg586dVQY7er0eer3e8jgnJwcAYDAYYDAYHFZe87VuvKZi23tQFmVDRLRBSet7gJISSP3mQ7VsEMTB5Sjp8jAQ3aGyS1pLPQzV7o8hASgZ+AYElIADy19fVFXP5Hisa9dgPdvPYDBACAGTyWTzRHvmYdnm88g56lrPJpMJQggYDAYoldZLcdj6O1Jvgh2TyYTp06ejZ8+euPnmmwEAqamp0Gg0CA0NtTo2KioKqampVV5rwYIFmDdvXoX9GzduhL+/v0PLDQBJSUmWbY0hB/2Pyi03ewMH4MpPZSvydgm7DY2v70LWl1Oxo+Xz1a9eLky4/cTLCBcmXA69FX8kFwHJ6x1e9vqkfD2Tc7GuXYP1bDuVSoXo6Gjk5eXVuFbUjXJzc51UKiqvtvVcXFyMwsJCbN26FSUlJVbPFRTYNrCn3gQ7U6dOxZ9//olt27bV+VqzZs3CzJllXT45OTmIi4vDgAEDEBwcXOfrmxkMBiQlJaF///6WhdgUSS9CadLDFNMJncfNRufyAU12e4iPbkNE3jHc3VKCaD2kymsr9i+D8uBpCE0gIh/8BEOCYhxW7vqmsnom52Bduwbr2X5FRUW4ePEiAgMD4efnZ9M5Qgjk5uYiKCgIUnX/XFKd1LWei4qKoNPpcMcdd1T42Zp7ZmpSL4KdadOm4YcffsDWrVvRuHFjy/7o6GgUFxcjKyvLqnUnLS0N0dHRVV5Pq9VCq9VW2K9Wq53yh8Vy3ezL8nBzAIq+L0Gh0Vgf2LA5kDgV2LYQqs3zgDaDAZWm4gXz0oFfXwYASH1mQx3exOFlro+c9fOjiljXrsF6tp3RaIQkSVAoFDYv6mnuUjGfV181a9YM06dPx/Tp0wHI72ft2rUYMWJEpcefO3cO8fHxOHDgADp16lTr17X1OnWtZ4VCAUmSKv19sPX3w6N/ukIITJs2DWvXrsXmzZsRHx9v9XyXLl2gVquxadMmy77k5GRcuHABiYmJri5uzba+CRj1QNOeQIs+lR9z+0wgIALIPA388Unlx2ycLU8iGN0B6PaI88pLRET1zpUrVzB48GCHXnPSpEkVgqe4uDhcuXLFklriyTw62Jk6dSq++OILrFixAkFBQUhNTUVqaioKCwsBACEhIZg8eTJmzpyJX3/9Ffv27cNDDz2ExMREzxuJlXkGOPCFvN1ndtX5ONogoM+L8vZvrwMFmdbPn90KHF4FQAKGLgKU9aJxjoiIXCQ6OrrS3gtHUyqViI6Ohkrl+d9DHh3sfPTRR8jOzsZdd92FmJgYy+3LL8uWVnj33XcxdOhQjBo1CnfccQeio6PxzTffuLHUVfjtdcBUArTsBzStodWp8wNAZDt5vastb5btLykGfnxW3u76MNC4i9OKS0REzrdkyRLExsZWGKU0fPhwPPzwwzh9+jSGDx+OqKgoBAYGolu3bvjll1+qvaYkSVi3bp3l8Z49e9C5c2f4+fmha9euOHDggNXxRqMRkydPRnx8PHQ6HVq3bo333nvP8vzcuXPxv//9D99++y0kSYIkSfjtt99w7tw5SJKEgwcPWo7dsmULbr31Vmi1WsTExOD555+3Siq+66678PTTT+Mf//gHwsPDER0djblz59pfcXby6HCsstVab+Tn54cPP/wQH35ox9w0rnb1OHD4K3nb3GpTHYUSGPgq8PkIYO9/5K6qhi3luXkyTsjdXH1fcmqRiYjqPSEAQzWjdUwm+fliJeDInB21f/WjacsZPXo0nnrqKfz666/o27cvACAzMxM//fQT1q9fj7y8PAwZMgSvvvoqtFotPvvsMwwbNgzJyclo0qTmfM28vDwMHToU/fv3xxdffIGzZ8/imWeesTrGZDKhcePGWL16NRo0aIAdO3ZgypQpiImJwZgxY/Dcc8/h2LFjyMnJwdKlct5peHg4UlJSrK5z+fJlDBkyBJMmTcJnn32G48eP49FHH4VWq8WMGTMsx/3vf//DzJkzsXv3buzcuROTJk1Cz5490b9/f5vqrDY8OtjxFsotCwAIoO09QGxn205q0RtIGAic/BlIekkOfra+JT838DWugUVEVBNDAfBabJVPKwCEOuN1/5kCaAJsOjQsLAyDBw/GihUrLMHOmjVr0LBhQ/Tu3RsKhQIdO3a0HP/yyy9j7dq1+O677zBt2rQar79ixQqYTCZ88skn8PPzQ7t27XDp0iU88cQTlmPUarXVdCzx8fHYuXMnvvrqK4wZMwaBgYHQ6XTQ6/XVDv7517/+hbi4OHzwwQeQJAlt2rRBSkoK/u///s8qwOrQoQPmzJkDAEhISMAHH3yATZs2OTXY8ehuLG8QWnAGiuQfAUhA7xfsO3nAy4CkBJJ/BFaOBUqKgPg75BmXiYjIK0yYMAFff/21ZbLb5cuXY+zYsVAoFMjLy8Nzzz2Htm3bIjQ0FIGBgTh27BguXLhg07WPHTuGDh06WA3ZrmwAz4cffoguXbogIiICgYGBWLJkic2vUf61EhMTrYaX9+zZE3l5ebh8+bJlX4cO1pPmxsTEID093a7XshdbdpysTcrX8kaH+4HINvadHNFazs3Z+x+5K0ypAe5eaHPzKBGRT1P7y60sVTCZTMjJzUVwUJBjh56r7ZucdtiwYRBC4Mcff0S3bt3w+++/49133wUAPPfcc0hKSsLbb7+Nli1bQqfT4b777rN74sTqrFq1Cs899xzeeecdJCYmIigoCG+99RZ2797tsNco78bh4pIkOX0GawY7TiRd2Imo3CMQChWku56v3UXumiXn++izgZ7TgYYJjiwiEZH3kqTqu5NMJkBtlI9x4zw7fn5+uPfee7F8+XKcOnUKrVu3xi233AIA2L59OyZNmoSRI0cCkHNwzp07Z/O127Zti88//xxFRUWW1p1du3ZZHbN9+3b06NEDTz75pGXf6dOnrY7RaDQwGo01vtbXX38NIYSldWf79u0ICgpCo0aNbC6zM7Aby1mEgOK3VwEApk5/A8LjazihCgENgPs/B+58HrjjOQcWkIiIPMWECRPw448/4tNPP8WECRMs+xMSEvDNN9/g4MGDOHToEMaPH29XK8j48eMhSRIeffRRHD16FOvXr8fbb79tdUxCQgL++OMP/Pzzzzhx4gRmz56NvXv3Wh3TrFkzHD58GMnJycjIyKh0Taonn3wSFy9exFNPPYXjx4/j22+/xZw5czBjxgy3T9rIYMdZ9LmAUgOjpIap57N1u1bzO4HeswCV8+dNICIi1+vTpw/Cw8ORnJyM8ePHW/YvXLgQYWFh6NGjB4YNG4aBAwdaWn1sERgYiO+//x5HjhxB586d8cILL+CNN96wOuaxxx7Dvffei/vvvx/du3fHtWvXrFp5AODRRx9F69at0bVrV0RERGD79u0VXqtRo0ZYv3499uzZg44dO+Lxxx/H5MmT8cILduarOoEkbBnf7eVycnIQEhKC7Oxsh6+N9dvaZbhr5CRO+e5EBoMB69evx5AhQ1jPTsa6dg3Ws/2Kiopw9uxZxMfH27w2lslkQk5ODoKDg93e8uDN6lrP1f1sbf3+5k/XyQq0ke4uAhERkU9jsENERERejcEOEREReTUGO0REROTVGOwQERGRV2OwQ0REXoMDjL2PI36mDHaIiKjeMw/RLyioZpVzqpfMP9O6TMPA5SKIiKjeUyqVCA0NtSwo6e/vb7UgZWVMJhOKi4tRVFTEeXacqLb1LIRAQUEB0tPTERoaCqVSWesyMNghIiKvEB0dDQA2r6AthEBhYSF0Ol2NgRHVXl3rOTQ01PKzrS0GO0RE5BUkSUJMTAwiIyMrXbvpRgaDAVu3bsUdd9zBmaqdqC71rFar69SiY8Zgh4iIvIpSqbTpC1KpVKKkpAR+fn4MdpzIE+qZnZRERETk1RjsEBERkVdjsENERERejTk7KJuwKCcnx6HXNRgMKCgoQE5ODvuDnYj17Dqsa9dgPbsG69k1nFnP5u/tmiYeZLADIDc3FwAQFxfn5pIQERGRvXJzcxESElLl85Lg3NowmUxISUlBUFCQQ+dayMnJQVxcHC5evIjg4GCHXZessZ5dh3XtGqxn12A9u4Yz61kIgdzcXMTGxlY7YSFbdgAoFAo0btzYadcPDg7mL5ILsJ5dh3XtGqxn12A9u4az6rm6Fh0zJigTERGRV2OwQ0RERF6NwY4TabVazJkzB1qt1t1F8WqsZ9dhXbsG69k1WM+u4Qn1zARlIiIi8mps2SEiIiKvxmCHiIiIvBqDHSIiIvJqDHaIiIjIqzHYcaIPP/wQzZo1g5+fH7p37449e/a4u0j12tatWzFs2DDExsZCkiSsW7fO6nkhBF566SXExMRAp9OhX79+OHnypHsKW48tWLAA3bp1Q1BQECIjIzFixAgkJydbHVNUVISpU6eiQYMGCAwMxKhRo5CWluamEtdPH330ETp06GCZaC0xMREbNmywPM86do7XX38dkiRh+vTpln2s67qbO3cuJEmyurVp08byvLvrmMGOk3z55ZeYOXMm5syZg/3796Njx44YOHAg0tPT3V20eis/Px8dO3bEhx9+WOnzb775JhYvXoyPP/4Yu3fvRkBAAAYOHIiioiIXl7R+27JlC6ZOnYpdu3YhKSkJBoMBAwYMQH5+vuWYGTNm4Pvvv8fq1auxZcsWpKSk4N5773Vjqeufxo0b4/XXX8e+ffvwxx9/oE+fPhg+fDj++usvAKxjZ9i7dy/+/e9/o0OHDlb7WdeO0a5dO1y5csVy27Ztm+U5t9exIKe49dZbxdSpUy2PjUajiI2NFQsWLHBjqbwHALF27VrLY5PJJKKjo8Vbb71l2ZeVlSW0Wq1YuXKlG0roPdLT0wUAsWXLFiGEXK9qtVqsXr3acsyxY8cEALFz5053FdMrhIWFif/+97+sYyfIzc0VCQkJIikpSdx5553imWeeEULw8+woc+bMER07dqz0OU+oY7bsOEFxcTH27duHfv36WfYpFAr069cPO3fudGPJvNfZs2eRmppqVechISHo3r0767yOsrOzAQDh4eEAgH379sFgMFjVdZs2bdCkSRPWdS0ZjUasWrUK+fn5SExMZB07wdSpU3H33Xdb1SnAz7MjnTx5ErGxsWjevDkmTJiACxcuAPCMOuZCoE6QkZEBo9GIqKgoq/1RUVE4fvy4m0rl3VJTUwGg0jo3P0f2M5lMmD59Onr27Imbb74ZgFzXGo0GoaGhVseyru135MgRJCYmoqioCIGBgVi7di1uuukmHDx4kHXsQKtWrcL+/fuxd+/eCs/x8+wY3bt3x7Jly9C6dWtcuXIF8+bNw+23344///zTI+qYwQ4RVWnq1Kn4888/rfreyXFat26NgwcPIjs7G2vWrMHEiROxZcsWdxfLq1y8eBHPPPMMkpKS4Ofn5+7ieK3Bgwdbtjt06IDu3bujadOm+Oqrr6DT6dxYMhm7sZygYcOGUCqVFTLN09LSEB0d7aZSeTdzvbLOHWfatGn44Ycf8Ouvv6Jx48aW/dHR0SguLkZWVpbV8axr+2k0GrRs2RJdunTBggUL0LFjR7z33nusYwfat28f0tPTccstt0ClUkGlUmHLli1YvHgxVCoVoqKiWNdOEBoailatWuHUqVMe8XlmsOMEGo0GXbp0waZNmyz7TCYTNm3ahMTERDeWzHvFx8cjOjraqs5zcnKwe/du1rmdhBCYNm0a1q5di82bNyM+Pt7q+S5dukCtVlvVdXJyMi5cuMC6riOTyQS9Xs86dqC+ffviyJEjOHjwoOXWtWtXTJgwwbLNuna8vLw8nD59GjExMZ7xeXZJGrQPWrVqldBqtWLZsmXi6NGjYsqUKSI0NFSkpqa6u2j1Vm5urjhw4IA4cOCAACAWLlwoDhw4IM6fPy+EEOL1118XoaGh4ttvvxWHDx8Ww4cPF/Hx8aKwsNDNJa9fnnjiCRESEiJ+++03ceXKFcutoKDAcszjjz8umjRpIjZv3iz++OMPkZiYKBITE91Y6vrn+eefF1u2bBFnz54Vhw8fFs8//7yQJEls3LhRCME6dqbyo7GEYF07wrPPPit+++03cfbsWbF9+3bRr18/0bBhQ5Geni6EcH8dM9hxovfff180adJEaDQaceutt4pdu3a5u0j12q+//ioAVLhNnDhRCCEPP589e7aIiooSWq1W9O3bVyQnJ7u30PVQZXUMQCxdutRyTGFhoXjyySdFWFiY8Pf3FyNHjhRXrlxxX6HroYcfflg0bdpUaDQaERERIfr27WsJdIRgHTvTjcEO67ru7r//fhETEyM0Go1o1KiRuP/++8WpU6csz7u7jiUhhHBNGxIRERGR6zFnh4iIiLwagx0iIiLyagx2iIiIyKsx2CEiIiKvxmCHiIiIvBqDHSIiIvJqDHaIiIjIqzHYISICIEkS1q1b5+5iEJETMNghIrebNGkSJEmqcBs0aJC7i0ZEXkDl7gIQEQHAoEGDsHTpUqt9Wq3WTaUhIm/Clh0i8gharRbR0dFWt7CwMAByF9NHH32EwYMHQ6fToXnz5lizZo3V+UeOHEGfPn2g0+nQoEEDTJkyBXl5eVbHfPrpp2jXrh20Wi1iYmIwbdo0q+czMjIwcuRI+Pv7IyEhAd99953luevXr2PChAmIiIiATqdDQkJCheCMiDwTgx0iqhdmz56NUaNG4dChQ5gwYQLGjh2LY8eOAQDy8/MxcOBAhIWFYe/evVi9ejV++eUXq2Dmo48+wtSpUzFlyhQcOXIE3333HVq2bGn1GvPmzcOYMWNw+PBhDBkyBBMmTEBmZqbl9Y8ePYoNGzbg2LFj+Oijj9CwYUPXVQAR1Z7LlhwlIqrCxIkThVKpFAEBAVa3V199VQghr8T++OOPW53TvXt38cQTTwghhFiyZIkICwsTeXl5lud//PFHoVAoRGpqqhBCiNjYWPHCCy9UWQYA4sUXX7Q8zsvLEwDEhg0bhBBCDBs2TDz00EOOecNE5FLM2SEij9C7d2989NFHVvvCw8Mt24mJiVbPJSYm4uDBgwCAY8eOoWPHjggICLA837NnT5hMJiQnJ0OSJKSkpKBv377VlqFDhw6W7YCAAAQHByM9PR0A8MQTT2DUqFHYv38/BgwYgBEjRqBHjx61eq9E5FoMdojIIwQEBFToVnIUnU5n03FqtdrqsSRJMJlMAIDBgwfj/PnzWL9+PZKSktC3b19MnToVb7/9tsPLS0SOxZwdIqoXdu3aVeFx27ZtAQBt27bFoUOHkJ+fb3l++/btUCgUaN26NYKCgtCsWTNs2rSpTmWIiIjAxIkT8cUXX2DRokVYsmRJna5HRK7Blh0i8gh6vR6pqalW+1QqlSUJePXq1ejatSt69eqF5cuXY8+ePfjkk08AABMmTMCcOXMwceJEzJ07F1evXsVTTz2FBx54AFFRUQCAuXPn4vHHH0dkZCQGDx6M3NxcbN++HU899ZRN5XvppZfQpUsXtGvXDnq9Hj/88IMl2CIiz8Zgh4g8wk8//YSYmBirfa1bt8bx48cByCOlVq1ahSeffBIxMTFYuXIlbrrpJgCAv78/fv75ZzzzzDPo1q0b/P39MWrUKCxcuNByrYkTJ6KoqAjvvvsunnvuOTRs2BD33XefzeXTaDSYNWsWzp07B51Oh9tvvx2rVq1ywDsnImeThBDC3YUgIqqOJElYu3YtRowY4e6iEFE9xJwdIiIi8moMdoiIiMirMWeHiDwee9uJqC7YskNERERejcEOEREReTUGO0REROTVGOwQERGRV2OwQ0RERF6NwQ4RERF5NQY7RERE5NUY7BAREZFXY7BDREREXu3/ASHSfuSyzb4fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accs_train, label='Train_accuracy')\n",
    "plt.plot(accs_val, label='Validation_accuracy')\n",
    "plt.grid()\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "676bc729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses_train, label='Train_loss')\n",
    "plt.plot(losses_val, label='Validation_loss')\n",
    "plt.grid()\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a198b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "class MyTestSet(Dataset):\n",
    "    def __init__(self, img):\n",
    "        self.img = np.load(img)\n",
    "        self.transforms = transforms.Compose([transforms.ToTensor(), ])\n",
    "    def __getitem__(self, index):\n",
    "        img = self.img[index, :, :, :]\n",
    "        img = np.squeeze(img)\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        img = self.transforms(img)\n",
    "        return img\n",
    "    def __len__(self):\n",
    "        return self.img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dd79b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MyTestSet(\"./pretrained/testy_pre.npy\")\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a44fa5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (23): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (_fc): Linear(in_features=1536, out_features=9, bias=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "mod =EfficientNet.from_pretrained('efficientnet-b3', num_classes=classes)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    mod = nn.DataParallel(mod)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name()\n",
    "\n",
    "mod.to(device)\n",
    "mod = mod.to(device)\n",
    "mod.load_state_dict(torch.load((\"./pretrained/checkpoint_model_pre.pth\")))\n",
    "mod.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec05be57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "celltype                \n",
       "type B pancreatic cell      282\n",
       "pancreatic acinar cell      121\n",
       "pancreatic A cell           109\n",
       "pancreatic ductal cell       66\n",
       "endothelial cell             43\n",
       "pancreatic D cell            40\n",
       "leukocyte                    25\n",
       "pancreatic PP cell           15\n",
       "pancreatic stellate cell     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    query = data\n",
    "    query = query.to(device)\n",
    "    pred= mod(query)\n",
    "    _, predicted = torch.max(pred.data, 1)\n",
    "    out.append(predicted)\n",
    "\n",
    "pred = torch.cat(out, dim=0)\n",
    "pr = pred.cpu().numpy()\n",
    "\n",
    "real_label = pd.read_csv(\"./pretrained/testy_pre.csv\", index_col=0)\n",
    "real_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da4262bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type B pancreatic cell      274\n",
       "pancreatic acinar cell      123\n",
       "pancreatic A cell           116\n",
       "pancreatic ductal cell       65\n",
       "pancreatic D cell            44\n",
       "endothelial cell             41\n",
       "leukocyte                    25\n",
       "pancreatic PP cell           13\n",
       "pancreatic stellate cell     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"./pretrained/label_encoder_pre.obj\",'rb')\n",
    "le = pickle.load(file)\n",
    "file.close()\n",
    "pred_label = le.inverse_transform(pr)\n",
    "pred_label = pd.DataFrame(pred_label)\n",
    "pred_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f017e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray: 0.958, ARI = 0.911\n"
     ]
    }
   ],
   "source": [
    "ls = list(set(pd.unique(pred_label[0]).tolist()) | set(pd.unique(real_label[\"celltype\"]).tolist()))\n",
    "acc = accuracy_score(pred_label,real_label)\n",
    "\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(ls)\n",
    "pred_label_2 = le2.transform(pred_label[0])\n",
    "real_label_2 = le2.transform(real_label[\"celltype\"])\n",
    "ari = adjusted_rand_score(real_label_2, pred_label_2)\n",
    "\n",
    "print(\"Accuray: %.03f, ARI = %.03f\" % (acc, ari))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
